<h1> ColumnStore Data Ingestion </h1> <div> <div class="creole"> <p>ColumnStore provides several mechanisms to ingest data:</p> <ul start="1">
<li>
<a href="../columnstore-bulk-data-loading/index">cpimport</a> provides the fastest performance for inserting data and ability to route data to particular PM nodes. <strong> Normally this should be the default choice for loading data </strong>. </li>
<li>
<a href="../columnstore-load-data-infile/index">LOAD DATA INFILE</a> provides another means of bulk inserting data. <ul start="1">
<li>By default with autocommit on it will internally stream the data to an instance of the cpimport process. This requires some memory overhead on the UM server so may be less reliable than cpimport for very large imports. </li>
<li>In transactional mode DML inserts are performed which will be significantly slower plus it will consume both binlog transaction files and ColumnStore VersionBuffer files. </li>
</ul> </li>
<li>DML, i.e. INSERT, UPDATE, and DELETE, provide row level changes. ColumnStore is optimized towards bulk modifications and so these operations are slower than they would be in say InnoDB. <ul start="1">
<li>Currently ColumnStore does not support operating as a replication slave target. </li>
<li>Bulk DML operations will in general perform better than multiple individual statements. <ul start="1">
<li>
<a href="../columnstore-batch-insert-mode/index">INSERT INTO SELECT</a> with autocommit behaves similarly to LOAD DATE INFILE in that internally it is mapped to cpimport for higher performance. </li>
<li>Bulk update operations based on a join with a small staging table can be relatively fast especially if updating a single column. </li>
</ul> </li>
</ul> </li>
<li>Using <a href="../columnstore-bulk-write-sdk/index">ColumnStore Bulk Write SDK</a> or <a href="../columnstore-streaming-data-adapters/index">ColumnStore Streaming Data Adapters</a>
</li>
</ul> </div> <table>
<thead><tr>
<th>Title</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td><a href="../columnstore-bulk-data-loading/index"> ColumnStore Bulk Data Loading</a></td>
<td> Using high-speed bulk load utility cpimport </td>
</tr>
<tr>
<td><a href="../columnstore-load-data-infile/index"> ColumnStore LOAD DATA INFILE</a></td>
<td> Using the LOAD DATA INFILE statement for bulk data loading </td>
</tr>
<tr>
<td><a href="../columnstore-batch-insert-mode/index"> ColumnStore Batch Insert Mode</a></td>
<td> Batch data insert mode with cpimport </td>
</tr>
<tr>
<td><a href="../columnstore-bulk-write-sdk/index"> ColumnStore Bulk Write SDK</a></td>
<td> Introduction Starting with MariaDB ColumnStore 1.1 a C++ SDK is available ... </td>
</tr>
<tr>
<td><a href="../columnstore-remote-bulk-data-import-mcsimport/index"> ColumnStore remote bulk data import: mcsimport</a></td>
<td> Overview mcsimport is a high-speed bulk load utility that imports data int... </td>
</tr>
<tr>
<td><a href="../columnstore-streaming-data-adapters/index"> ColumnStore Streaming Data Adapters</a></td>
<td> The ColumnStore Bulk Data API enables the creation of higher performance a... </td>
</tr>
</tbody>
</table>  <div id="content_disclaimer" class="graybox"> Content reproduced on this site is the property of its respective owners, and this content is not reviewed in advance by MariaDB. The views, information and opinions expressed by this content do not necessarily represent those of MariaDB or any other party. </div> </div><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://mariadb.com/kb/en/columnstore-data-ingestion/" class="_attribution-link" target="_blank">https://mariadb.com/kb/en/columnstore-data-ingestion/</a>
  </p>
</div>
