<h1 class="devsite-page-title">tf.map_fn</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.map_fn"> <meta itemprop="path" content="Stable"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/map_fn">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/map_fn.py#L37-L285">  View source on GitHub </a> </td>
</table>  <p>map on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.map_fn(
    fn,
    elems,
    dtype=None,
    parallel_iterations=None,
    back_prop=True,
    swap_memory=False,
    infer_shape=True,
    name=None
)
</pre>  <p>The simplest version of <code translate="no" dir="ltr">map_fn</code> repeatedly applies the callable <code translate="no" dir="ltr">fn</code> to a sequence of elements from first to last. The elements are made of the tensors unpacked from <code translate="no" dir="ltr">elems</code>. <code translate="no" dir="ltr">dtype</code> is the data type of the return value of <code translate="no" dir="ltr">fn</code>. Users must provide <code translate="no" dir="ltr">dtype</code> if it is different from the data type of <code translate="no" dir="ltr">elems</code>.</p> <p>Suppose that <code translate="no" dir="ltr">elems</code> is unpacked into <code translate="no" dir="ltr">values</code>, a list of tensors. The shape of the result tensor is <code translate="no" dir="ltr">[values.shape[0]] + fn(values[0]).shape</code>.</p> <p>This method also allows multi-arity <code translate="no" dir="ltr">elems</code> and output of <code translate="no" dir="ltr">fn</code>. If <code translate="no" dir="ltr">elems</code> is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The signature of <code translate="no" dir="ltr">fn</code> may match the structure of <code translate="no" dir="ltr">elems</code>. That is, if <code translate="no" dir="ltr">elems</code> is <code translate="no" dir="ltr">(t1, [t2, t3, [t4, t5]])</code>, then an appropriate signature for <code translate="no" dir="ltr">fn</code> is: <code translate="no" dir="ltr">fn = lambda (t1, [t2, t3, [t4, t5]]):</code>.</p> <p>Furthermore, <code translate="no" dir="ltr">fn</code> may emit a different structure than its input. For example, <code translate="no" dir="ltr">fn</code> may look like: <code translate="no" dir="ltr">fn = lambda t1: return (t1 + 1, t1 - 1)</code>. In this case, the <code translate="no" dir="ltr">dtype</code> parameter is not optional: <code translate="no" dir="ltr">dtype</code> must be a type or (possibly nested) tuple of types matching the output of <code translate="no" dir="ltr">fn</code>.</p> <p>To apply a functional operation to the nonzero elements of a SparseTensor one of the following methods is recommended. First, if the function is expressible as TensorFlow ops, use</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = SparseTensor(input.indices, fn(input.values), input.dense_shape)
</pre> <p>If, however, the function is not expressible as a TensorFlow op, then use</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = SparseTensor(
  input.indices, map_fn(fn, input.values), input.dense_shape)
</pre> <p>instead.</p> <p>When executing eagerly, map_fn does not execute in parallel even if <code translate="no" dir="ltr">parallel_iterations</code> is set to a value &gt; 1. You can still get the performance benefits of running a function in parallel by using the <code translate="no" dir="ltr">tf.contrib.eager.defun</code> decorator,</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Assume the function being used in map_fn is fn.
# To ensure map_fn calls fn in parallel, use the defun decorator.
@tf.contrib.eager.defun
def func(tensor):
  return tf.map_fn(fn, tensor)
</pre> <p>Note that if you use the defun decorator, any non-TensorFlow Python code that you may have written in your function won't get executed. See <code translate="no" dir="ltr">tf.contrib.eager.defun</code> for more details. The recommendation would be to debug without defun but switch to defun to get performance benefits of running map_fn in parallel.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">fn</code></b>: The callable to be performed. It accepts one argument, which will have the same (possibly nested) structure as <code translate="no" dir="ltr">elems</code>. Its output must have the same structure as <code translate="no" dir="ltr">dtype</code> if one is provided, otherwise it must have the same structure as <code translate="no" dir="ltr">elems</code>.</li> <li>
<b><code translate="no" dir="ltr">elems</code></b>: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be applied to <code translate="no" dir="ltr">fn</code>.</li> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: (optional) The output type(s) of <code translate="no" dir="ltr">fn</code>. If <code translate="no" dir="ltr">fn</code> returns a structure of Tensors differing from the structure of <code translate="no" dir="ltr">elems</code>, then <code translate="no" dir="ltr">dtype</code> is not optional and must have the same structure as the output of <code translate="no" dir="ltr">fn</code>.</li> <li>
<b><code translate="no" dir="ltr">parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel. When graph building, the default value is 10. While executing eagerly, the default value is set to 1.</li> <li>
<b><code translate="no" dir="ltr">back_prop</code></b>: (optional) True enables support for back propagation.</li> <li>
<b><code translate="no" dir="ltr">swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li> <li>
<b><code translate="no" dir="ltr">infer_shape</code></b>: (optional) False disables tests for consistent output shapes.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: (optional) Name prefix for the returned tensors.</li> </ul> <h4 id="returns_2">Returns:</h4> <p>A tensor or (possibly nested) sequence of tensors. Each tensor packs the results of applying <code translate="no" dir="ltr">fn</code> to tensors unpacked from <code translate="no" dir="ltr">elems</code> along the first dimension, from first to last.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if <code translate="no" dir="ltr">fn</code> is not callable or the structure of the output of <code translate="no" dir="ltr">fn</code> and <code translate="no" dir="ltr">dtype</code> do not match, or if elems is a SparseTensor.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if the lengths of the output of <code translate="no" dir="ltr">fn</code> and <code translate="no" dir="ltr">dtype</code> do not match.</li> </ul> <h4 id="examples_2">Examples:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">elems = np.array([1, 2, 3, 4, 5, 6])
squares = map_fn(lambda x: x * x, elems)
# squares == [1, 4, 9, 16, 25, 36]
</pre>
<pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))
alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)
# alternate == [-1, 2, -3]
</pre>
<pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">elems = np.array([1, 2, 3])
alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))
# alternates[0] == [1, 2, 3]
# alternates[1] == [-1, -2, -3]
</pre> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="map_fn"><code translate="no" dir="ltr">tf.compat.v1.map_fn</code></a></li> <li><a href="map_fn"><code translate="no" dir="ltr">tf.compat.v2.map_fn</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/map_fn" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/map_fn</a>
  </p>
</div>
