<h1 class="devsite-page-title">tf.space_to_batch_nd</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.space_to_batch_nd"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/space_to_batch_nd">  TensorFlow 1 version</a> </td> </table>  <p>SpaceToBatch for N-D tensors of type T.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.space_to_batch_nd(
    input,
    block_shape,
    paddings,
    name=None
)
</pre>  <p>This operation divides "spatial" dimensions <code translate="no" dir="ltr">[1, ..., M]</code> of the input into a grid of blocks of shape <code translate="no" dir="ltr">block_shape</code>, and interleaves these blocks with the "batch" dimension (0) such that in the output, the spatial dimensions <code translate="no" dir="ltr">[1, ..., M]</code> correspond to the position within the grid, and the batch dimension combines both the position within a spatial block and the original batch position. Prior to division into blocks, the spatial dimensions of the input are optionally zero padded according to <code translate="no" dir="ltr">paddings</code>. See below for a precise description.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">input</code></b>: A <code translate="no" dir="ltr">Tensor</code>. N-D with shape <code translate="no" dir="ltr">input_shape = [batch] + spatial_shape + remaining_shape</code>, where spatial_shape has <code translate="no" dir="ltr">M</code> dimensions.</li> <li>
<b><code translate="no" dir="ltr">block_shape</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. 1-D with shape <code translate="no" dir="ltr">[M]</code>, all values must be &gt;= 1.</li> <li>
<p><b><code translate="no" dir="ltr">paddings</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>. 2-D with shape <code translate="no" dir="ltr">[M, 2]</code>, all values must be &gt;= 0. <code translate="no" dir="ltr">paddings[i] = [pad_start, pad_end]</code> specifies the padding for input dimension <code translate="no" dir="ltr">i + 1</code>, which corresponds to spatial dimension <code translate="no" dir="ltr">i</code>. It is required that <code translate="no" dir="ltr">block_shape[i]</code> divides <code translate="no" dir="ltr">input_shape[i + 1] + pad_start + pad_end</code>.</p> <p>This operation is equivalent to the following steps:</p> <ol> <li><p>Zero-pad the start and end of dimensions <code translate="no" dir="ltr">[1, ..., M]</code> of the input according to <code translate="no" dir="ltr">paddings</code> to produce <code translate="no" dir="ltr">padded</code> of shape <code translate="no" dir="ltr">padded_shape</code>.</p></li> <li>
<p>Reshape <code translate="no" dir="ltr">padded</code> to <code translate="no" dir="ltr">reshaped_padded</code> of shape:</p> <p>[batch] + [padded_shape[1] / block_shape[0], block_shape[0], ..., padded_shape[M] / block_shape[M-1], block_shape[M-1]] + remaining_shape</p>
</li> <li>
<p>Permute dimensions of <code translate="no" dir="ltr">reshaped_padded</code> to produce <code translate="no" dir="ltr">permuted_reshaped_padded</code> of shape:</p> <p>block_shape + [batch] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</p>
</li> <li>
<p>Reshape <code translate="no" dir="ltr">permuted_reshaped_padded</code> to flatten <code translate="no" dir="ltr">block_shape</code> into the batch dimension, producing an output tensor of shape:</p> <p>[batch * prod(block_shape)] + [padded_shape[1] / block_shape[0], ..., padded_shape[M] / block_shape[M-1]] + remaining_shape</p>
</li> </ol> <p>Some examples:</p> <p>(1) For the following input of shape <code translate="no" dir="ltr">[1, 2, 2, 1]</code>, <code translate="no" dir="ltr">block_shape = [2, 2]</code>, and <code translate="no" dir="ltr">paddings = [[0, 0], [0, 0]]</code>:</p>
</li> </ul> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1], [2]], [[3], [4]]]]
</pre> <p>The output tensor has shape <code translate="no" dir="ltr">[4, 1, 1, 1]</code> and value:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
</pre> <p>(2) For the following input of shape <code translate="no" dir="ltr">[1, 2, 2, 3]</code>, <code translate="no" dir="ltr">block_shape = [2, 2]</code>, and <code translate="no" dir="ltr">paddings = [[0, 0], [0, 0]]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1, 2, 3], [4, 5, 6]],
      [[7, 8, 9], [10, 11, 12]]]]
</pre> <p>The output tensor has shape <code translate="no" dir="ltr">[4, 1, 1, 3]</code> and value:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]
</pre> <p>(3) For the following input of shape <code translate="no" dir="ltr">[1, 4, 4, 1]</code>, <code translate="no" dir="ltr">block_shape = [2, 2]</code>, and <code translate="no" dir="ltr">paddings = [[0, 0], [0, 0]]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1],   [2],  [3],  [4]],
      [[5],   [6],  [7],  [8]],
      [[9],  [10], [11],  [12]],
      [[13], [14], [15],  [16]]]]
</pre> <p>The output tensor has shape <code translate="no" dir="ltr">[4, 2, 2, 1]</code> and value:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1], [3]], [[9], [11]]],
     [[[2], [4]], [[10], [12]]],
     [[[5], [7]], [[13], [15]]],
     [[[6], [8]], [[14], [16]]]]
</pre> <p>(4) For the following input of shape <code translate="no" dir="ltr">[2, 2, 4, 1]</code>, block_shape = <code translate="no" dir="ltr">[2, 2]</code>, and paddings = <code translate="no" dir="ltr">[[0, 0], [2, 0]]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1],   [2],  [3],  [4]],
      [[5],   [6],  [7],  [8]]],
     [[[9],  [10], [11],  [12]],
      [[13], [14], [15],  [16]]]]
</pre> <p>The output tensor has shape <code translate="no" dir="ltr">[8, 1, 3, 1]</code> and value:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
     [[[0], [2], [4]]], [[[0], [10], [12]]],
     [[[0], [5], [7]]], [[[0], [13], [15]]],
     [[[0], [6], [8]]], [[[0], [14], [16]]]]
</pre> <p>Among others, this operation is useful for reducing atrous convolution into regular convolution.</p> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">input</code>.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="space_to_batch_nd"><code translate="no" dir="ltr">tf.compat.v1.manip.space_to_batch_nd</code></a></li> <li><a href="space_to_batch_nd"><code translate="no" dir="ltr">tf.compat.v1.space_to_batch_nd</code></a></li> <li><a href="space_to_batch_nd"><code translate="no" dir="ltr">tf.compat.v2.space_to_batch_nd</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/space_to_batch_nd" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/space_to_batch_nd</a>
  </p>
</div>
