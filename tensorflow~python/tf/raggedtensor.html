<h1 class="devsite-page-title">tf.RaggedTensor</h1>    <devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax>  <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.RaggedTensor"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="dtype"> <meta itemprop="property" content="flat_values"> <meta itemprop="property" content="nested_row_splits"> <meta itemprop="property" content="ragged_rank"> <meta itemprop="property" content="row_splits"> <meta itemprop="property" content="shape"> <meta itemprop="property" content="values"> <meta itemprop="property" content="__abs__"> <meta itemprop="property" content="__add__"> <meta itemprop="property" content="__and__"> <meta itemprop="property" content="__bool__"> <meta itemprop="property" content="__div__"> <meta itemprop="property" content="__floordiv__"> <meta itemprop="property" content="__ge__"> <meta itemprop="property" content="__getitem__"> <meta itemprop="property" content="__gt__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="__invert__"> <meta itemprop="property" content="__le__"> <meta itemprop="property" content="__lt__"> <meta itemprop="property" content="__mod__"> <meta itemprop="property" content="__mul__"> <meta itemprop="property" content="__neg__"> <meta itemprop="property" content="__nonzero__"> <meta itemprop="property" content="__or__"> <meta itemprop="property" content="__pow__"> <meta itemprop="property" content="__radd__"> <meta itemprop="property" content="__rand__"> <meta itemprop="property" content="__rdiv__"> <meta itemprop="property" content="__rfloordiv__"> <meta itemprop="property" content="__rmod__"> <meta itemprop="property" content="__rmul__"> <meta itemprop="property" content="__ror__"> <meta itemprop="property" content="__rpow__"> <meta itemprop="property" content="__rsub__"> <meta itemprop="property" content="__rtruediv__"> <meta itemprop="property" content="__rxor__"> <meta itemprop="property" content="__sub__"> <meta itemprop="property" content="__truediv__"> <meta itemprop="property" content="__xor__"> <meta itemprop="property" content="bounding_shape"> <meta itemprop="property" content="consumers"> <meta itemprop="property" content="from_nested_row_lengths"> <meta itemprop="property" content="from_nested_row_splits"> <meta itemprop="property" content="from_nested_value_rowids"> <meta itemprop="property" content="from_row_lengths"> <meta itemprop="property" content="from_row_limits"> <meta itemprop="property" content="from_row_splits"> <meta itemprop="property" content="from_row_starts"> <meta itemprop="property" content="from_sparse"> <meta itemprop="property" content="from_tensor"> <meta itemprop="property" content="from_uniform_row_length"> <meta itemprop="property" content="from_value_rowids"> <meta itemprop="property" content="merge_dims"> <meta itemprop="property" content="nested_row_lengths"> <meta itemprop="property" content="nested_value_rowids"> <meta itemprop="property" content="nrows"> <meta itemprop="property" content="row_lengths"> <meta itemprop="property" content="row_limits"> <meta itemprop="property" content="row_starts"> <meta itemprop="property" content="to_list"> <meta itemprop="property" content="to_sparse"> <meta itemprop="property" content="to_tensor"> <meta itemprop="property" content="value_rowids"> <meta itemprop="property" content="with_flat_values"> <meta itemprop="property" content="with_row_splits_dtype"> <meta itemprop="property" content="with_values"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/RaggedTensor">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L57-L2073">  View source on GitHub </a> </td>
</table>  <h2 id="class_raggedtensor_2">Class <code translate="no" dir="ltr">RaggedTensor</code>
</h2> <p>Represents a ragged tensor.</p> <h3 id="used_in_the_guide_2">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/ragged_tensor">Ragged tensors</a></li> </ul> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/load_data/unicode">Unicode strings</a></li> </ul> <p>A <code translate="no" dir="ltr">RaggedTensor</code> is a tensor with one or more <em>ragged dimensions</em>, which are dimensions whose slices may have different lengths. For example, the inner (column) dimension of <code translate="no" dir="ltr">rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is ragged, since the column slices (<code translate="no" dir="ltr">rt[0, :]</code>, ..., <code translate="no" dir="ltr">rt[4, :]</code>) have different lengths. Dimensions whose slices all have the same length are called <em>uniform dimensions</em>. The outermost dimension of a <code translate="no" dir="ltr">RaggedTensor</code> is always uniform, since it consists of a single slice (and so there is no possibility for differing slice lengths).</p> <p>The total number of dimensions in a <code translate="no" dir="ltr">RaggedTensor</code> is called its <em>rank</em>, and the number of ragged dimensions in a <code translate="no" dir="ltr">RaggedTensor</code> is called its <em>ragged-rank</em>. A <code translate="no" dir="ltr">RaggedTensor</code>'s ragged-rank is fixed at graph creation time: it can't depend on the runtime values of <code translate="no" dir="ltr">Tensor</code>s, and can't vary dynamically for different session runs.</p> <h3 id="potentially_ragged_tensors_2">Potentially Ragged Tensors</h3> <p>Many ops support both <code translate="no" dir="ltr">Tensor</code>s and <code translate="no" dir="ltr">RaggedTensor</code>s. The term "potentially ragged tensor" may be used to refer to a tensor that might be either a <code translate="no" dir="ltr">Tensor</code> or a <code translate="no" dir="ltr">RaggedTensor</code>. The ragged-rank of a <code translate="no" dir="ltr">Tensor</code> is zero.</p> <h3 id="documenting_raggedtensor_shapes_2">Documenting RaggedTensor Shapes</h3> <p>When documenting the shape of a RaggedTensor, ragged dimensions can be indicated by enclosing them in parentheses. For example, the shape of a 3-D <code translate="no" dir="ltr">RaggedTensor</code> that stores the fixed-size word embedding for each word in a sentence, for each sentence in a batch, could be written as <code translate="no" dir="ltr">[num_sentences, (num_words), embedding_size]</code>. The parentheses around <code translate="no" dir="ltr">(num_words)</code> indicate that dimension is ragged, and that the length of each element list in that dimension may vary for each item.</p> <h3 id="component_tensors_2">Component Tensors</h3> <p>Internally, a <code translate="no" dir="ltr">RaggedTensor</code> consists of a concatenated list of values that are partitioned into variable-length rows. In particular, each <code translate="no" dir="ltr">RaggedTensor</code> consists of:</p> <ul> <li><p>A <code translate="no" dir="ltr">values</code> tensor, which concatenates the variable-length rows into a flattened list. For example, the <code translate="no" dir="ltr">values</code> tensor for <code translate="no" dir="ltr">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is <code translate="no" dir="ltr">[3, 1, 4, 1, 5, 9, 2, 6]</code>.</p></li> <li><p>A <code translate="no" dir="ltr">row_splits</code> vector, which indicates how those flattened values are divided into rows. In particular, the values for row <code translate="no" dir="ltr">rt[i]</code> are stored in the slice <code translate="no" dir="ltr">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p></li> </ul> <h4 id="example_25">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_row_splits( 
      values=[3, 1, 4, 1, 5, 9, 2, 6], 
      row_splits=[0, 4, 4, 7, 8, 8])) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="alternative_row-partitioning_schemes_2">Alternative Row-Partitioning Schemes</h3> <p>In addition to <code translate="no" dir="ltr">row_splits</code>, ragged tensors provide support for four other row-partitioning schemes:</p> <ul> <li><p><code translate="no" dir="ltr">row_lengths</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the length of each row.</p></li> <li><p><code translate="no" dir="ltr">value_rowids</code> and <code translate="no" dir="ltr">nrows</code>: <code translate="no" dir="ltr">value_rowids</code> is a vector with shape <code translate="no" dir="ltr">[nvals]</code>, corresponding one-to-one with <code translate="no" dir="ltr">values</code>, which specifies each value's row index. In particular, the row <code translate="no" dir="ltr">rt[row]</code> consists of the values <code translate="no" dir="ltr">rt.values[j]</code> where <code translate="no" dir="ltr">value_rowids[j]==row</code>. <code translate="no" dir="ltr">nrows</code> is an integer scalar that specifies the number of rows in the <code translate="no" dir="ltr">RaggedTensor</code>. (<code translate="no" dir="ltr">nrows</code> is used to indicate trailing empty rows.)</p></li> <li><p><code translate="no" dir="ltr">row_starts</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the start offset of each row. Equivalent to <code translate="no" dir="ltr">row_splits[:-1]</code>.</p></li> <li><p><code translate="no" dir="ltr">row_limits</code>: a vector with shape <code translate="no" dir="ltr">[nrows]</code>, which specifies the stop offset of each row. Equivalent to <code translate="no" dir="ltr">row_splits[1:]</code>.</p></li> <li><p><code translate="no" dir="ltr">uniform_row_length</code>: A scalar tensor, specifying the length of every row. This row-partitioning scheme may only be used if all rows have the same length.</p></li> </ul> <p>Example: The following ragged tensors are equivalent, and all represent the nested list <code translate="no" dir="ltr">[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
values = [3, 1, 4, 1, 5, 9, 2, 6] 
rt1 = RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8]) 
rt2 = RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0]) 
rt3 = RaggedTensor.from_value_rowids( 
    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5) 
rt4 = RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8]) 
rt5 = RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8]) 
</pre> <h3 id="multiple_ragged_dimensions_2">Multiple Ragged Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with multiple ragged dimensions can be defined by using a nested <code translate="no" dir="ltr">RaggedTensor</code> for the <code translate="no" dir="ltr">values</code> tensor. Each nested <code translate="no" dir="ltr">RaggedTensor</code> adds a single ragged dimension.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above 
    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8]) 
outer_rt = RaggedTensor.from_row_splits( 
    values=inner_rt, row_splits=[0, 3, 3, 5]) 
print(outer_rt.to_list()) 
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]] 
print(outer_rt.ragged_rank) 
2 
</pre> <p>The factory function <a href="raggedtensor#from_nested_row_splits"><code translate="no" dir="ltr">RaggedTensor.from_nested_row_splits</code></a> may be used to construct a <code translate="no" dir="ltr">RaggedTensor</code> with multiple ragged dimensions directly, by providing a list of <code translate="no" dir="ltr">row_splits</code> tensors:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
RaggedTensor.from_nested_row_splits( 
    flat_values=[3, 1, 4, 1, 5, 9, 2, 6], 
    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list() 
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]] 
</pre> <h3 id="uniform_inner_dimensions_2">Uniform Inner Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with uniform inner dimensions can be defined by using a multidimensional <code translate="no" dir="ltr">Tensor</code> for <code translate="no" dir="ltr">values</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32), 
                                  row_splits=[0, 2, 5]) 
print(rt.to_list()) 
[[[1, 1, 1], [1, 1, 1]], 
 [[1, 1, 1], [1, 1, 1], [1, 1, 1]]] 
print(rt.shape) 
(2, None, 3) 
</pre> <h3 id="uniform_outer_dimensions_2">Uniform Outer Dimensions</h3> <p><code translate="no" dir="ltr">RaggedTensor</code>s with uniform outer dimensions can be defined by using one or more <code translate="no" dir="ltr">RaggedTensor</code> with a <code translate="no" dir="ltr">uniform_row_length</code> row-partitioning tensor. For example, a <code translate="no" dir="ltr">RaggedTensor</code> with shape <code translate="no" dir="ltr">[2, 2, None]</code> can be constructed with this method from a <code translate="no" dir="ltr">RaggedTensor</code> values with shape <code translate="no" dir="ltr">[4, None]</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]]) 
print(values.shape) 
(4, None) 
rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2) 
print(rt6) 
&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt; 
print(rt6.shape) 
(2, 2, None) 
</pre> <p>Note that <code translate="no" dir="ltr">rt6</code> only contains one ragged dimension (the innermost dimension). In contrast, if <code translate="no" dir="ltr">from_row_splits</code> is used to construct a similar <code translate="no" dir="ltr">RaggedTensor</code>, then that <code translate="no" dir="ltr">RaggedTensor</code> will have two ragged dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4]) 
print(rt7.shape) 
(2, None, None) 
</pre> <p>Uniform and ragged outer dimensions may be interleaved, meaning that a tensor with any combination of ragged and uniform dimensions may be created. For example, a RaggedTensor <code translate="no" dir="ltr">t4</code> with shape <code translate="no" dir="ltr">[3, None, 4, 8, None, 2]</code> could be constructed as follows:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]
t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]
t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]
t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]
t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]
</pre> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L228-L310">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    values,
    row_splits,
    cached_row_lengths=None,
    cached_value_rowids=None,
    cached_nrows=None,
    internal=False,
    uniform_row_length=None
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with a specified partitioning for <code translate="no" dir="ltr">values</code>.</p> <p>This constructor is private -- please use one of the following ops to build <code translate="no" dir="ltr">RaggedTensor</code>s:</p> <ul> <li><a href="raggedtensor#from_row_lengths"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_lengths</code></a></li> <li><a href="raggedtensor#from_value_rowids"><code translate="no" dir="ltr">tf.RaggedTensor.from_value_rowids</code></a></li> <li><a href="raggedtensor#from_row_splits"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_splits</code></a></li> <li><a href="raggedtensor#from_row_starts"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_starts</code></a></li> <li><a href="raggedtensor#from_row_limits"><code translate="no" dir="ltr">tf.RaggedTensor.from_row_limits</code></a></li> <li><a href="raggedtensor#from_nested_row_splits"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_row_splits</code></a></li> <li><a href="raggedtensor#from_nested_row_lengths"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_row_lengths</code></a></li> <li><a href="raggedtensor#from_nested_value_rowids"><code translate="no" dir="ltr">tf.RaggedTensor.from_nested_value_rowids</code></a></li> </ul> <h4 id="args_57">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor of any dtype and shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">row_splits</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows+1]</code>.</li> <li>
<b><code translate="no" dir="ltr">cached_row_lengths</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>
</li> <li>
<b><code translate="no" dir="ltr">cached_value_rowids</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nvals]</code>.</li> <li>
<b><code translate="no" dir="ltr">cached_nrows</code></b>: A 1-D integer scalar tensor.</li> <li>
<b><code translate="no" dir="ltr">internal</code></b>: True if the constructor is being called by one of the factory methods. If false, an exception will be raised.</li> <li>
<b><code translate="no" dir="ltr">uniform_row_length</code></b>: A scalar tensor.</li> </ul> <h4 id="raises_13">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If a row partitioning tensor has an inappropriate dtype.</li> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If exactly one row partitioning argument was not specified.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If a row partitioning tensor has an inappropriate shape.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If multiple partitioning arguments are specified.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If nrows is specified but value_rowids is not None.</li> </ul> <h2 id="properties_2">Properties</h2> <h3 id="dtype"><code translate="no" dir="ltr">dtype</code></h3> <p>The <code translate="no" dir="ltr">DType</code> of values in this tensor.</p> <h3 id="flat_values"><code translate="no" dir="ltr">flat_values</code></h3> <p>The innermost <code translate="no" dir="ltr">values</code> tensor for this ragged tensor.</p> <p>Concretely, if <code translate="no" dir="ltr">rt.values</code> is a <code translate="no" dir="ltr">Tensor</code>, then <code translate="no" dir="ltr">rt.flat_values</code> is <code translate="no" dir="ltr">rt.values</code>; otherwise, <code translate="no" dir="ltr">rt.flat_values</code> is <code translate="no" dir="ltr">rt.values.flat_values</code>.</p> <p>Conceptually, <code translate="no" dir="ltr">flat_values</code> is the tensor formed by flattening the outermost dimension and all of the ragged dimensions into a single dimension.</p> <p><code translate="no" dir="ltr">rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]</code> (where <code translate="no" dir="ltr">nvals</code> is the number of items in the flattened dimensions).</p> <h4 id="returns_63">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>.</p> <h4 id="example_26">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]) 
print(rt.flat_values) 
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) 
</pre> <h3 id="nested_row_splits"><code translate="no" dir="ltr">nested_row_splits</code></h3> <p>A tuple containing the row_splits for all ragged dimensions.</p> <p><code translate="no" dir="ltr">rt.nested_row_splits</code> is a tuple containing the <code translate="no" dir="ltr">row_splits</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost. In particular, <code translate="no" dir="ltr">rt.nested_row_splits = (rt.row_splits,) + value_splits</code> where:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">* `value_splits = ()` if `rt.values` is a `Tensor`.
* `value_splits = rt.values.nested_row_splits` otherwise.
</pre> <h4 id="returns_64">Returns:</h4> <p>A <code translate="no" dir="ltr">tuple</code> of 1-D integer <code translate="no" dir="ltr">Tensor</code>s.</p> <h4 id="example_27">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant( 
    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]]) 
for i, splits in enumerate(rt.nested_row_splits): 
  print('Splits for dimension %d: %s' % (i+1, splits.numpy())) 
Splits for dimension 1: [0 3] 
Splits for dimension 2: [0 3 3 5] 
Splits for dimension 3: [0 4 4 7 8 8] 
</pre> <h3 id="ragged_rank"><code translate="no" dir="ltr">ragged_rank</code></h3> <p>The number of ragged dimensions in this ragged tensor.</p> <h4 id="returns_65">Returns:</h4> <p>A Python <code translate="no" dir="ltr">int</code> indicating the number of ragged dimensions in this ragged tensor. The outermost dimension is not considered ragged.</p> <h3 id="row_splits"><code translate="no" dir="ltr">row_splits</code></h3> <p>The row-split indices for this ragged tensor's <code translate="no" dir="ltr">values</code>.</p> <p><code translate="no" dir="ltr">rt.row_splits</code> specifies where the values for each row begin and end in <code translate="no" dir="ltr">rt.values</code>. In particular, the values for row <code translate="no" dir="ltr">rt[i]</code> are stored in the slice <code translate="no" dir="ltr">rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p> <h4 id="returns_66">Returns:</h4> <p>A 1-D integer <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[self.nrows+1]</code>. The returned tensor is non-empty, and is sorted in ascending order. <code translate="no" dir="ltr">self.row_splits[0]</code> is zero, and <code translate="no" dir="ltr">self.row_splits[-1]</code> is equal to <code translate="no" dir="ltr">self.values.shape[0]</code>.</p> <h4 id="example_28">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.row_splits)  # indices of row splits in rt.values 
tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64) 
</pre> <h3 id="shape"><code translate="no" dir="ltr">shape</code></h3> <p>The statically known shape of this ragged tensor.</p> <h4 id="returns_67">Returns:</h4> <p>A <code translate="no" dir="ltr">TensorShape</code> containing the statically known shape of this ragged tensor. Ragged dimensions have a size of <code translate="no" dir="ltr">None</code>.</p> <h4 id="examples_6">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
tf.ragged.constant([[0], [1, 2]]).shape 
TensorShape([2, None]) 
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape 
TensorShape([2, None, 2]) 
</pre> <h3 id="values"><code translate="no" dir="ltr">values</code></h3> <p>The concatenated rows for this ragged tensor.</p> <p><code translate="no" dir="ltr">rt.values</code> is a potentially ragged tensor formed by flattening the two outermost dimensions of <code translate="no" dir="ltr">rt</code> into a single dimension.</p> <p><code translate="no" dir="ltr">rt.values.shape = [nvals] + rt.shape[2:]</code> (where <code translate="no" dir="ltr">nvals</code> is the number of items in the outer two dimensions of <code translate="no" dir="ltr">rt</code>).</p> <p><code translate="no" dir="ltr">rt.ragged_rank = self.ragged_rank - 1</code></p> <h4 id="returns_68">Returns:</h4> <p>A potentially ragged tensor.</p> <h4 id="example_29">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.values) 
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) 
</pre> <h2 id="methods_2">Methods</h2> <h3 id="__abs__"><code translate="no" dir="ltr">__abs__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L248-L281">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__abs__(
    x,
    name=None
)
</pre> <p>Computes the absolute value of a tensor.</p> <p>Given a tensor of integer or floating-point values, this operation returns a tensor of the same type, where each element contains the absolute value of the corresponding element in the input.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> of complex numbers, this operation returns a tensor of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code> that is the absolute value of each element in <code translate="no" dir="ltr">x</code>. All elements in <code translate="no" dir="ltr">x</code> must be complex numbers of the form \(a + bj\). The absolute value is computed as \( \sqrt{a^2 + b^2}\). For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)  # [5.25594902, 6.60492229]
</pre> <h4 id="args_58">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_69">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> the same size, type, and sparsity as <code translate="no" dir="ltr">x</code> with absolute values. Note, for <code translate="no" dir="ltr">complex64</code> or <code translate="no" dir="ltr">complex128</code> input, the returned <code translate="no" dir="ltr">Tensor</code> will be of type <code translate="no" dir="ltr">float32</code> or <code translate="no" dir="ltr">float64</code>, respectively.</p> <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code></p> <h3 id="__add__"><code translate="no" dir="ltr">__add__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__add__(
    x,
    y,
    name=None
)
</pre> <p>Returns x + y element-wise.</p> <p><em>NOTE</em>: <a href="math/add"><code translate="no" dir="ltr">math.add</code></a> supports broadcasting. <code translate="no" dir="ltr">AddN</code> does not. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_59">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">string</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_70">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__and__"><code translate="no" dir="ltr">__and__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__and__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <p><em>NOTE</em>: <a href="math/logical_and"><code translate="no" dir="ltr">math.logical_and</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_60">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_71">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__bool__"><code translate="no" dir="ltr">__bool__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_operators.py#L72-L74">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__bool__(_)
</pre> <p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p> <h3 id="__div__"><code translate="no" dir="ltr">__div__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1072-L1095">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__div__(
    x,
    y,
    name=None
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.</p> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p> <h4 id="args_61">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_72">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> returns the quotient of x and y.</p> <h3 id="__floordiv__"><code translate="no" dir="ltr">__floordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1150-L1178">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__floordiv__(
    x,
    y,
    name=None
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="raggedtensor#__div__"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p> <h4 id="args_62">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_73">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> rounded down.</p> <h4 id="raises_14">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If the inputs are complex.</li> </ul> <h3 id="__ge__"><code translate="no" dir="ltr">__ge__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__ge__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of (x &gt;= y) element-wise.</p> <p><em>NOTE</em>: <a href="math/greater_equal"><code translate="no" dir="ltr">math.greater_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="example_30">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6, 7])
y = tf.constant([5, 2, 5, 10])
tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]

x = tf.constant([5, 4, 6, 7])
y = tf.constant([5])
tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]
</pre> <h4 id="args_63">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_74">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__getitem__"><code translate="no" dir="ltr">__getitem__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_getitem.py#L32-L103">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__getitem__(key)
</pre> <p>Returns the specified piece of this RaggedTensor.</p> <p>Supports multidimensional indexing and slicing, with one restriction: indexing into a ragged inner dimension is not allowed. This case is problematic because the indicated value may exist in some rows but not others. In such cases, it's not obvious whether we should (1) report an IndexError; (2) use a default value; or (3) skip that value and return a tensor with fewer rows than we started with. Following the guiding principles of Python ("In the face of ambiguity, refuse the temptation to guess"), we simply disallow this operation.</p> <p>Any dimensions added by <code translate="no" dir="ltr">array_ops.newaxis</code> will be ragged if the following dimension is ragged.</p> <h4 id="args_64">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">self</code></b>: The RaggedTensor to slice.</li> <li>
<p><b><code translate="no" dir="ltr">key</code></b>: Indicates which piece of the RaggedTensor to return, using standard Python semantics (e.g., negative values index from the end). <code translate="no" dir="ltr">key</code> may have any of the following types:</p> <ul> <li>
<code translate="no" dir="ltr">int</code> constant</li> <li>Scalar integer <code translate="no" dir="ltr">Tensor</code>
</li> <li>
<code translate="no" dir="ltr">slice</code> containing integer constants and/or scalar integer <code translate="no" dir="ltr">Tensor</code>s</li> <li><code translate="no" dir="ltr">Ellipsis</code></li> <li><code translate="no" dir="ltr">tf.newaxis</code></li> <li>
<code translate="no" dir="ltr">tuple</code> containing any of the above (for multidimentional indexing)</li> </ul>
</li> </ul> <h4 id="returns_75">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">RaggedTensor</code> object. Values that include at least one ragged dimension are returned as <code translate="no" dir="ltr">RaggedTensor</code>. Values that include no ragged dimensions are returned as <code translate="no" dir="ltr">Tensor</code>. See above for examples of expressions that return <code translate="no" dir="ltr">Tensor</code>s vs <code translate="no" dir="ltr">RaggedTensor</code>s.</p> <h4 id="raises_15">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">key</code> is out of bounds.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">key</code> is not supported.</li> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If the indices in <code translate="no" dir="ltr">key</code> have an unsupported type.</li> </ul> <h4 id="examples_7">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
# A 2-D ragged tensor with 1 ragged dimension. 
rt = tf.ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']]) 
rt[0].numpy()                 # First row (1-D `Tensor`) 
array([b'a', b'b', b'c'], dtype=object) 
rt[:3].to_list()              # First three rows (2-D RaggedTensor) 
[[b'a', b'b', b'c'], [b'd', b'e'], [b'f']] 
rt[3, 0].numpy()              # 1st element of 4th row (scalar) 
b'g' 
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
# A 3-D ragged tensor with 2 ragged dimensions. 
rt = tf.ragged.constant([[[1, 2, 3], [4]], 
                         [[5], [], [6]], 
                         [[7]], 
                         [[8, 9], [10]]]) 
rt[1].to_list()               # Second row (2-D RaggedTensor) 
[[5], [], [6]] 
rt[3, 0].numpy()              # First element of fourth row (1-D Tensor) 
array([8, 9], dtype=int32) 
rt[:, 1:3].to_list()          # Items 1-3 of each row (3-D RaggedTensor) 
[[[4]], [[], [6]], [], [[10]]] 
rt[:, -1:].to_list()          # Last item of each row (3-D RaggedTensor) 
[[[4]], [[6]], [[7]], [[10]]] 
</pre> <h3 id="__gt__"><code translate="no" dir="ltr">__gt__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__gt__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of (x &gt; y) element-wise.</p> <p><em>NOTE</em>: <a href="math/greater"><code translate="no" dir="ltr">math.greater</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="example_31">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5, 2, 5])
tf.math.greater(x, y) ==&gt; [False, True, True]

x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.greater(x, y) ==&gt; [False, False, True]
</pre> <h4 id="args_65">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_76">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__invert__"><code translate="no" dir="ltr">__invert__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__invert__(
    x,
    name=None
)
</pre> <p>Returns the truth value of NOT x element-wise.</p> <h4 id="args_66">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_77">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__le__"><code translate="no" dir="ltr">__le__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__le__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of (x &lt;= y) element-wise.</p> <p><em>NOTE</em>: <a href="math/less_equal"><code translate="no" dir="ltr">math.less_equal</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="example_32">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less_equal(x, y) ==&gt; [True, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 6])
tf.math.less_equal(x, y) ==&gt; [True, True, True]
</pre> <h4 id="args_67">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_78">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__lt__"><code translate="no" dir="ltr">__lt__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__lt__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of (x &lt; y) element-wise.</p> <p><em>NOTE</em>: <a href="math/less"><code translate="no" dir="ltr">math.less</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="example_33">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([5, 4, 6])
y = tf.constant([5])
tf.math.less(x, y) ==&gt; [False, True, False]

x = tf.constant([5, 4, 6])
y = tf.constant([5, 6, 7])
tf.math.less(x, y) ==&gt; [False, True, True]
</pre> <h4 id="args_68">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">uint32</code>, <code translate="no" dir="ltr">uint64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_79">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__mod__"><code translate="no" dir="ltr">__mod__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__mod__(
    x,
    y,
    name=None
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <p><em>NOTE</em>: <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_69">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_80">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__mul__"><code translate="no" dir="ltr">__mul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L331-L334">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__mul__(
    x,
    y,
    name=None
)
</pre> <p>Returns x * y element-wise.</p> <p><em>NOTE</em>: <a href="math/multiply"><code translate="no" dir="ltr">tf.multiply</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_70">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_81">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__neg__"><code translate="no" dir="ltr">__neg__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__neg__(
    x,
    name=None
)
</pre> <p>Computes numerical negative value element-wise.</p> <p>I.e., \(y = -x\).</p> <h4 id="args_71">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_82">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <p>If <code translate="no" dir="ltr">x</code> is a <code translate="no" dir="ltr">SparseTensor</code>, returns <code translate="no" dir="ltr">SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code></p> <h3 id="__nonzero__"><code translate="no" dir="ltr">__nonzero__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_operators.py#L72-L74">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__nonzero__(_)
</pre> <p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p> <h3 id="__or__"><code translate="no" dir="ltr">__or__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__or__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <p><em>NOTE</em>: <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_72">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_83">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__pow__"><code translate="no" dir="ltr">__pow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L437-L462">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__pow__(
    x,
    y,
    name=None
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre> <h4 id="args_73">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_84">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>.</p> <h3 id="__radd__"><code translate="no" dir="ltr">__radd__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__radd__(
    x,
    y,
    name=None
)
</pre> <p>Returns x + y element-wise.</p> <p><em>NOTE</em>: <a href="math/add"><code translate="no" dir="ltr">math.add</code></a> supports broadcasting. <code translate="no" dir="ltr">AddN</code> does not. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_74">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>, <code translate="no" dir="ltr">string</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_85">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__rand__"><code translate="no" dir="ltr">__rand__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rand__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of x AND y element-wise.</p> <p><em>NOTE</em>: <a href="math/logical_and"><code translate="no" dir="ltr">math.logical_and</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_75">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_86">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__rdiv__"><code translate="no" dir="ltr">__rdiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1072-L1095">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rdiv__(
    x,
    y,
    name=None
)
</pre> <p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide.</span></aside> <p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.</p> <p>This function divides <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>, forcing Python 2 semantics. That is, if <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> are both integers then the result will be an integer. This is in contrast to Python 3, where division with <code translate="no" dir="ltr">/</code> is always a float while division with <code translate="no" dir="ltr">//</code> is always an integer.</p> <h4 id="args_76">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_87">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> returns the quotient of x and y.</p> <h3 id="__rfloordiv__"><code translate="no" dir="ltr">__rfloordiv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1150-L1178">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rfloordiv__(
    x,
    y,
    name=None
)
</pre> <p>Divides <code translate="no" dir="ltr">x / y</code> elementwise, rounding toward the most negative integer.</p> <p>The same as <a href="raggedtensor#__div__"><code translate="no" dir="ltr">tf.compat.v1.div(x,y)</code></a> for integers, but uses <code translate="no" dir="ltr">tf.floor(tf.compat.v1.div(x,y))</code> for floating point arguments so that the result is always an integer (though possibly an integer represented as floating point). This op is generated by <code translate="no" dir="ltr">x // y</code> floor division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same type, and the result will have the same type as well.</p> <h4 id="args_77">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of real numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_88">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> rounded down.</p> <h4 id="raises_16">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If the inputs are complex.</li> </ul> <h3 id="__rmod__"><code translate="no" dir="ltr">__rmod__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rmod__(
    x,
    y,
    name=None
)
</pre> <p>Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p>true, this follows Python semantics in that the result here is consistent with a flooring divide. E.g. <code translate="no" dir="ltr">floor(x / y) * y + mod(x, y) = x</code>.</p> <p><em>NOTE</em>: <a href="math/floormod"><code translate="no" dir="ltr">math.floormod</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_78">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_89">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__rmul__"><code translate="no" dir="ltr">__rmul__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L331-L334">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rmul__(
    x,
    y,
    name=None
)
</pre> <p>Returns x * y element-wise.</p> <p><em>NOTE</em>: <a href="math/multiply"><code translate="no" dir="ltr">tf.multiply</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_79">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_90">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__ror__"><code translate="no" dir="ltr">__ror__</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__ror__(
    x,
    y,
    name=None
)
</pre> <p>Returns the truth value of x OR y element-wise.</p> <p><em>NOTE</em>: <a href="math/logical_or"><code translate="no" dir="ltr">math.logical_or</code></a> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_80">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_91">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">bool</code>.</p> <h3 id="__rpow__"><code translate="no" dir="ltr">__rpow__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L437-L462">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rpow__(
    x,
    y,
    name=None
)
</pre> <p>Computes the power of one value to another.</p> <p>Given a tensor <code translate="no" dir="ltr">x</code> and a tensor <code translate="no" dir="ltr">y</code>, this operation computes \(x^y\) for corresponding elements in <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>. For example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</pre> <h4 id="args_81">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, or <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_92">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>.</p> <h3 id="__rsub__"><code translate="no" dir="ltr">__rsub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L352-L355">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rsub__(
    x,
    y,
    name=None
)
</pre> <p>Returns x - y element-wise.</p> <p><em>NOTE</em>: <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_82">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_93">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__rtruediv__"><code translate="no" dir="ltr">__rtruediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1039-L1069">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rtruediv__(
    x,
    y,
    name=None
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</p> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p> <h4 id="args_83">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_94">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> evaluated in floating point.</p> <h4 id="raises_17">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes.</li> </ul> <h3 id="__rxor__"><code translate="no" dir="ltr">__rxor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1229-L1260">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__rxor__(
    x,
    y,
    name='LogicalXor'
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Inputs are tensor and if the tensors contains more than one element, an element-wise logical XOR is computed.</p> <h4 id="usage_5">Usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name="LogicalXor")
#  here z = [False  True  True False]
</pre> <h4 id="args_84">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> type bool.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type bool.</li> </ul> <h4 id="returns_95">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type bool with the same size as that of x or y.</p> <h3 id="__sub__"><code translate="no" dir="ltr">__sub__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L352-L355">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__sub__(
    x,
    y,
    name=None
)
</pre> <p>Returns x - y element-wise.</p> <p><em>NOTE</em>: <code translate="no" dir="ltr">Subtract</code> supports broadcasting. More about broadcasting <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p> <h4 id="args_85">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must be one of the following types: <code translate="no" dir="ltr">bfloat16</code>, <code translate="no" dir="ltr">half</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">uint8</code>, <code translate="no" dir="ltr">int8</code>, <code translate="no" dir="ltr">uint16</code>, <code translate="no" dir="ltr">int16</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">int64</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code>. Must have the same type as <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_96">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">x</code>.</p> <h3 id="__truediv__"><code translate="no" dir="ltr">__truediv__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1039-L1069">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__truediv__(
    x,
    y,
    name=None
)
</pre> <p>Divides x / y elementwise (using Python 3 division operator semantics).</p> <p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.</p> <p>This function forces Python 3 division operator semantics where all integer arguments are cast to floating types first. This op is generated by normal <code translate="no" dir="ltr">x / y</code> division in Python 3 and in Python 2.7 with <code translate="no" dir="ltr">from __future__ import division</code>. If you want integer division that rounds down, use <code translate="no" dir="ltr">x // y</code> or <code translate="no" dir="ltr">tf.math.floordiv</code>.</p> <p><code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> must have the same numeric type. If the inputs are floating point, the output will have the same type. If the inputs are integral, the inputs are cast to <code translate="no" dir="ltr">float32</code> for <code translate="no" dir="ltr">int8</code> and <code translate="no" dir="ltr">int16</code> and <code translate="no" dir="ltr">float64</code> for <code translate="no" dir="ltr">int32</code> and <code translate="no" dir="ltr">int64</code> (matching the behavior of Numpy).</p> <h4 id="args_86">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: <code translate="no" dir="ltr">Tensor</code> numerator of numeric type.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: <code translate="no" dir="ltr">Tensor</code> denominator of numeric type.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_97">Returns:</h4> <p><code translate="no" dir="ltr">x / y</code> evaluated in floating point.</p> <h4 id="raises_18">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> have different dtypes.</li> </ul> <h3 id="__xor__"><code translate="no" dir="ltr">__xor__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L1229-L1260">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__xor__(
    x,
    y,
    name='LogicalXor'
)
</pre> <p>Logical XOR function.</p> <p>x ^ y = (x | y) &amp; ~(x &amp; y)</p> <p>Inputs are tensor and if the tensors contains more than one element, an element-wise logical XOR is computed.</p> <h4 id="usage_6">Usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name="LogicalXor")
#  here z = [False  True  True False]
</pre> <h4 id="args_87">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A <code translate="no" dir="ltr">Tensor</code> type bool.</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type bool.</li> </ul> <h4 id="returns_98">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> of type bool with the same size as that of x or y.</p> <h3 id="bounding_shape"><code translate="no" dir="ltr">bounding_shape</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1344-L1394">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">bounding_shape(
    axis=None,
    name=None,
    out_type=None
)
</pre> <p>Returns the tight bounding box shape for this <code translate="no" dir="ltr">RaggedTensor</code>.</p> <h4 id="args_88">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">axis</code></b>: An integer scalar or vector indicating which axes to return the bounding box for. If not specified, then the full bounding box is returned.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> <li>
<b><code translate="no" dir="ltr">out_type</code></b>: <code translate="no" dir="ltr">dtype</code> for the returned tensor. Defaults to <code translate="no" dir="ltr">self.row_splits.dtype</code>.</li> </ul> <h4 id="returns_99">Returns:</h4> <p>An integer <code translate="no" dir="ltr">Tensor</code> (<code translate="no" dir="ltr">dtype=self.row_splits.dtype</code>). If <code translate="no" dir="ltr">axis</code> is not specified, then <code translate="no" dir="ltr">output</code> is a vector with <code translate="no" dir="ltr">output.shape=[self.shape.ndims]</code>. If <code translate="no" dir="ltr">axis</code> is a scalar, then the <code translate="no" dir="ltr">output</code> is a scalar. If <code translate="no" dir="ltr">axis</code> is a vector, then <code translate="no" dir="ltr">output</code> is a vector, where <code translate="no" dir="ltr">output[i]</code> is the bounding size for dimension <code translate="no" dir="ltr">axis[i]</code>.</p> <h4 id="example_34">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]]) 
rt.bounding_shape().numpy() 
array([5, 4]) 
</pre> <h3 id="consumers"><code translate="no" dir="ltr">consumers</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L2072-L2073">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">consumers()
</pre> <h3 id="from_nested_row_lengths"><code translate="no" dir="ltr">from_nested_row_lengths</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L890-L926">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_nested_row_lengths(
    cls,
    flat_values,
    nested_row_lengths,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">row_lengths</code> tensors.</p> <h4 id="equivalent_to_4">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for row_lengths in reversed(nested_row_lengths):
  result = from_row_lengths(result, row_lengths)
</pre> <h4 id="args_89">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">flat_values</code></b>: A potentially ragged tensor.</li> <li>
<b><code translate="no" dir="ltr">nested_row_lengths</code></b>: A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">row_lengths</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_100">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_row_lengths</code> is empty).</p> <h3 id="from_nested_row_splits"><code translate="no" dir="ltr">from_nested_row_splits</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L852-L888">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_nested_row_splits(
    cls,
    flat_values,
    nested_row_splits,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">row_splits</code> tensors.</p> <h4 id="equivalent_to_5">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for row_splits in reversed(nested_row_splits):
  result = from_row_splits(result, row_splits)
</pre> <h4 id="args_90">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">flat_values</code></b>: A potentially ragged tensor.</li> <li>
<b><code translate="no" dir="ltr">nested_row_splits</code></b>: A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">row_splits</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_101">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_row_splits</code> is empty).</p> <h3 id="from_nested_value_rowids"><code translate="no" dir="ltr">from_nested_value_rowids</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L795-L850">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_nested_value_rowids(
    cls,
    flat_values,
    nested_value_rowids,
    nested_nrows=None,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> from a nested list of <code translate="no" dir="ltr">value_rowids</code> tensors.</p> <h4 id="equivalent_to_6">Equivalent to:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = flat_values
for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):
  result = from_value_rowids(result, rowids, nrows)
</pre> <h4 id="args_91">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">flat_values</code></b>: A potentially ragged tensor.</li> <li>
<b><code translate="no" dir="ltr">nested_value_rowids</code></b>: A list of 1-D integer tensors. The <code translate="no" dir="ltr">i</code>th tensor is used as the <code translate="no" dir="ltr">value_rowids</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension.</li> <li>
<b><code translate="no" dir="ltr">nested_nrows</code></b>: A list of integer scalars. The <code translate="no" dir="ltr">i</code>th scalar is used as the <code translate="no" dir="ltr">nrows</code> for the <code translate="no" dir="ltr">i</code>th ragged dimension.</li> <li><p><b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</p></li> <li><p><b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</p></li> </ul> <h4 id="returns_102">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> (or <code translate="no" dir="ltr">flat_values</code> if <code translate="no" dir="ltr">nested_value_rowids</code> is empty).</p> <h4 id="raises_19">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">len(nested_values_rowids) != len(nested_nrows)</code>.</li> </ul> <h3 id="from_row_lengths"><code translate="no" dir="ltr">from_row_lengths</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L496-L553">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_row_lengths(
    cls,
    values,
    row_lengths,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_lengths</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values.pop(0) for i in range(length)]
          for length in row_lengths]
</pre> <h4 id="args_92">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">row_lengths</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be nonnegative. <code translate="no" dir="ltr">sum(row_lengths)</code> must be <code translate="no" dir="ltr">nvals</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_103">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h4 id="example_35">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_row_lengths( 
    values=[3, 1, 4, 1, 5, 9, 2, 6], 
    row_lengths=[4, 0, 3, 1, 0])) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="from_row_limits"><code translate="no" dir="ltr">from_row_limits</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L605-L653">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_row_limits(
    cls,
    values,
    row_limits,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_limits</code>.</p> <p>Equivalent to: <code translate="no" dir="ltr">from_row_splits(values, concat([0, row_limits]))</code>.</p> <h4 id="args_93">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">row_limits</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be sorted in ascending order. If <code translate="no" dir="ltr">nrows&gt;0</code>, then <code translate="no" dir="ltr">row_limits[-1]</code> must be <code translate="no" dir="ltr">nvals</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_104">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h4 id="example_36">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_row_limits( 
    values=[3, 1, 4, 1, 5, 9, 2, 6], 
    row_limits=[4, 4, 7, 8, 8])) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="from_row_splits"><code translate="no" dir="ltr">from_row_splits</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L434-L494">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_row_splits(
    cls,
    values,
    row_splits,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_splits</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [values[row_splits[i]:row_splits[i + 1]]
          for i in range(len(row_splits) - 1)]
</pre> <h4 id="args_94">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">row_splits</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows+1]</code>. Must not be empty, and must be sorted in ascending order. <code translate="no" dir="ltr">row_splits[0]</code> must be zero and <code translate="no" dir="ltr">row_splits[-1]</code> must be <code translate="no" dir="ltr">nvals</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_105">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h4 id="raises_20">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">row_splits</code> is an empty list.</li> </ul> <h4 id="example_37">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_row_splits( 
    values=[3, 1, 4, 1, 5, 9, 2, 6], 
    row_splits=[0, 4, 4, 7, 8, 8])) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="from_row_starts"><code translate="no" dir="ltr">from_row_starts</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L555-L603">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_row_starts(
    cls,
    values,
    row_starts,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">row_starts</code>.</p> <p>Equivalent to: <code translate="no" dir="ltr">from_row_splits(values, concat([row_starts, nvals]))</code>.</p> <h4 id="args_95">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">row_starts</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nrows]</code>. Must be nonnegative and sorted in ascending order. If <code translate="no" dir="ltr">nrows&gt;0</code>, then <code translate="no" dir="ltr">row_starts[0]</code> must be zero.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_106">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h4 id="example_38">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_row_starts( 
    values=[3, 1, 4, 1, 5, 9, 2, 6], 
    row_starts=[0, 4, 4, 7, 8])) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="from_sparse"><code translate="no" dir="ltr">from_sparse</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1797-L1857">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_sparse(
    cls,
    st_input,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</pre> <p>Converts a 2D <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.SparseTensor</code></a> to a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>Each row of the <code translate="no" dir="ltr">output</code> <code translate="no" dir="ltr">RaggedTensor</code> will contain the explicit values from the same row in <code translate="no" dir="ltr">st_input</code>. <code translate="no" dir="ltr">st_input</code> must be ragged-right. If not it is not ragged-right, then an error will be generated.</p> <h4 id="example_39">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
st = tf.SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]], 
                     values=[1, 2, 3, 4, 5], 
                     dense_shape=[4, 3]) 
tf.RaggedTensor.from_sparse(st).to_list() 
[[1, 2, 3], [4], [], [5]] 
</pre> <p>Currently, only two-dimensional <code translate="no" dir="ltr">SparseTensors</code> are supported.</p> <h4 id="args_96">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">st_input</code></b>: The sparse tensor to convert. Must have rank 2.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> <li>
<b><code translate="no" dir="ltr">row_splits_dtype</code></b>: <code translate="no" dir="ltr">dtype</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>'s <code translate="no" dir="ltr">row_splits</code> tensor. One of <a href="../tf#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf#int64"><code translate="no" dir="ltr">tf.int64</code></a>.</li> </ul> <h4 id="returns_107">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> with the same values as <code translate="no" dir="ltr">st_input</code>. <code translate="no" dir="ltr">output.ragged_rank = rank(st_input) - 1</code>. <code translate="no" dir="ltr">output.shape = [st_input.dense_shape[0], None]</code>.</p> <h4 id="raises_21">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If the number of dimensions in <code translate="no" dir="ltr">st_input</code> is not known statically, or is not two.</li> </ul> <h3 id="from_tensor"><code translate="no" dir="ltr">from_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1541-L1746">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_tensor(
    cls,
    tensor,
    lengths=None,
    padding=None,
    ragged_rank=1,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</pre> <p>Converts a <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> into a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>The set of absent/default values may be specified using a vector of lengths or a padding value (but not both). If <code translate="no" dir="ltr">lengths</code> is specified, then the output tensor will satisfy <code translate="no" dir="ltr">output[row] = tensor[row][:lengths[row]]</code>. If 'lengths' is a list of lists or tuple of lists, those lists will be used as nested row lengths. If <code translate="no" dir="ltr">padding</code> is specified, then any row <em>suffix</em> consisting entirely of <code translate="no" dir="ltr">padding</code> will be excluded from the returned <code translate="no" dir="ltr">RaggedTensor</code>. If neither <code translate="no" dir="ltr">lengths</code> nor <code translate="no" dir="ltr">padding</code> is specified, then the returned <code translate="no" dir="ltr">RaggedTensor</code> will have no absent/default values.</p> <h4 id="examples_8">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]]) 
tf.RaggedTensor.from_tensor(dt) 
&lt;tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]&gt; 
tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3]) 
&lt;tf.RaggedTensor [[5], [], [6, 0, 0]]&gt; 
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
tf.RaggedTensor.from_tensor(dt, padding=0) 
&lt;tf.RaggedTensor [[5, 7], [0, 3], [6]]&gt; 
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
dt = tf.constant([[[5, 0], [7, 0], [0, 0]], 
                  [[0, 0], [3, 0], [0, 0]], 
                  [[6, 0], [0, 0], [0, 0]]]) 
tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1])) 
&lt;tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]&gt; 
</pre> <h4 id="args_97">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">tensor</code></b>: The <code translate="no" dir="ltr">Tensor</code> to convert. Must have rank <code translate="no" dir="ltr">ragged_rank + 1</code> or higher.</li> <li>
<b><code translate="no" dir="ltr">lengths</code></b>: An optional set of row lengths, specified using a 1-D integer <code translate="no" dir="ltr">Tensor</code> whose length is equal to <code translate="no" dir="ltr">tensor.shape[0]</code> (the number of rows in <code translate="no" dir="ltr">tensor</code>). If specified, then <code translate="no" dir="ltr">output[row]</code> will contain <code translate="no" dir="ltr">tensor[row][:lengths[row]]</code>. Negative lengths are treated as zero. You may optionally pass a list or tuple of lengths to this argument, which will be used as nested row lengths to construct a ragged tensor with multiple ragged dimensions.</li> <li>
<b><code translate="no" dir="ltr">padding</code></b>: An optional padding value. If specified, then any row suffix consisting entirely of <code translate="no" dir="ltr">padding</code> will be excluded from the returned RaggedTensor. <code translate="no" dir="ltr">padding</code> is a <code translate="no" dir="ltr">Tensor</code> with the same dtype as <code translate="no" dir="ltr">tensor</code> and with <code translate="no" dir="ltr">shape=tensor.shape[ragged_rank + 1:]</code>.</li> <li>
<b><code translate="no" dir="ltr">ragged_rank</code></b>: Integer specifying the ragged rank for the returned <code translate="no" dir="ltr">RaggedTensor</code>. Must be greater than zero.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> <li>
<b><code translate="no" dir="ltr">row_splits_dtype</code></b>: <code translate="no" dir="ltr">dtype</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>'s <code translate="no" dir="ltr">row_splits</code> tensor. One of <a href="../tf#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf#int64"><code translate="no" dir="ltr">tf.int64</code></a>.</li> </ul> <h4 id="returns_108">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> with the specified <code translate="no" dir="ltr">ragged_rank</code>. The shape of the returned ragged tensor is compatible with the shape of <code translate="no" dir="ltr">tensor</code>.</p> <h4 id="raises_22">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If both <code translate="no" dir="ltr">lengths</code> and <code translate="no" dir="ltr">padding</code> are specified.</li> </ul> <h3 id="from_uniform_row_length"><code translate="no" dir="ltr">from_uniform_row_length</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L655-L793">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_uniform_row_length(
    cls,
    values,
    uniform_row_length,
    nrows=None,
    validate=True,
    name=None
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">uniform_row_length</code>.</p> <p>This method can be used to create <code translate="no" dir="ltr">RaggedTensor</code>s with multiple uniform outer dimensions. For example, a <code translate="no" dir="ltr">RaggedTensor</code> with shape <code translate="no" dir="ltr">[2, 2, None]</code> can be constructed with this method from a <code translate="no" dir="ltr">RaggedTensor</code> values with shape <code translate="no" dir="ltr">[4, None]</code>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]]) 
print(values.shape) 
(4, None) 
rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2) 
print(rt1) 
&lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt; 
print(rt1.shape) 
(2, 2, None) 
</pre> <p>Note that <code translate="no" dir="ltr">rt1</code> only contains one ragged dimension (the innermost dimension). In contrast, if <code translate="no" dir="ltr">from_row_splits</code> is used to construct a similar <code translate="no" dir="ltr">RaggedTensor</code>, then that <code translate="no" dir="ltr">RaggedTensor</code> will have two ragged dimensions:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4]) 
print(rt2.shape) 
(2, None, None) 
</pre> <h4 id="args_98">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">uniform_row_length</code></b>: A scalar integer tensor. Must be nonnegative. The size of the outer axis of <code translate="no" dir="ltr">values</code> must be evenly divisible by <code translate="no" dir="ltr">uniform_row_length</code>.</li> <li>
<b><code translate="no" dir="ltr">nrows</code></b>: The number of rows in the constructed RaggedTensor. If not specified, then it defaults to <code translate="no" dir="ltr">nvals/uniform_row_length</code> (or <code translate="no" dir="ltr">0</code> if <code translate="no" dir="ltr">uniform_row_length==0</code>). <code translate="no" dir="ltr">nrows</code> only needs to be specified if <code translate="no" dir="ltr">uniform_row_length</code> might be zero. <code translate="no" dir="ltr">uniform_row_length*nrows</code> must be <code translate="no" dir="ltr">nvals</code>.</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> </ul> <h4 id="returns_109">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code> that corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values.pop(0) for i in range(uniform_row_length)]
          for _ in range(nrows)]
</pre> <p><code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h3 id="from_value_rowids"><code translate="no" dir="ltr">from_value_rowids</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L316-L432">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">@classmethod
from_value_rowids(
    cls,
    values,
    value_rowids,
    nrows=None,
    name=None,
    validate=True
)
</pre> <p>Creates a <code translate="no" dir="ltr">RaggedTensor</code> with rows partitioned by <code translate="no" dir="ltr">value_rowids</code>.</p> <p>The returned <code translate="no" dir="ltr">RaggedTensor</code> corresponds with the python list defined by:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]
          for row in range(nrows)]
</pre> <h4 id="args_99">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">values</code></b>: A potentially ragged tensor with shape <code translate="no" dir="ltr">[nvals, ...]</code>.</li> <li>
<b><code translate="no" dir="ltr">value_rowids</code></b>: A 1-D integer tensor with shape <code translate="no" dir="ltr">[nvals]</code>, which corresponds one-to-one with <code translate="no" dir="ltr">values</code>, and specifies each value's row index. Must be nonnegative, and must be sorted in ascending order.</li> <li>
<b><code translate="no" dir="ltr">nrows</code></b>: An integer scalar specifying the number of rows. This should be specified if the <code translate="no" dir="ltr">RaggedTensor</code> may containing empty training rows. Must be greater than <code translate="no" dir="ltr">value_rowids[-1]</code> (or zero if <code translate="no" dir="ltr">value_rowids</code> is empty). Defaults to <code translate="no" dir="ltr">value_rowids[-1]</code> (or zero if <code translate="no" dir="ltr">value_rowids</code> is empty).</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the RaggedTensor (optional).</li> <li>
<b><code translate="no" dir="ltr">validate</code></b>: If true, then use assertions to check that the arguments form a valid <code translate="no" dir="ltr">RaggedTensor</code>.</li> </ul> <h4 id="returns_110">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = values.rank + 1</code>. <code translate="no" dir="ltr">result.ragged_rank = values.ragged_rank + 1</code>.</p> <h4 id="raises_23">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">nrows</code> is incompatible with <code translate="no" dir="ltr">value_rowids</code>.</li> </ul> <h4 id="example_40">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
print(tf.RaggedTensor.from_value_rowids( 
    values=[3, 1, 4, 1, 5, 9, 2, 6], 
    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], 
    nrows=5)) 
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt; 
</pre> <h3 id="merge_dims"><code translate="no" dir="ltr">merge_dims</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1496-L1534">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">merge_dims(
    outer_axis,
    inner_axis
)
</pre> <p>Merges outer_axis...inner_axis into a single dimension.</p> <p>Returns a copy of this RaggedTensor with the specified range of dimensions flattened into a single dimension, with elements in row-major order.</p> <h4 id="examples_9">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]]) 
print(rt.merge_dims(0, 1)) 
&lt;tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]&gt; 
print(rt.merge_dims(1, 2)) 
&lt;tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]&gt; 
print(rt.merge_dims(0, 2)) 
tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32) 
</pre> <p>To mimic the behavior of <code translate="no" dir="ltr">np.flatten</code> (which flattens all dimensions), use <code translate="no" dir="ltr">rt.merge_dims(0, -1). To mimic the behavior of</code>tf.layers.Flatten<code translate="no" dir="ltr">(which flattens all dimensions except the outermost batch dimension), use</code>rt.merge_dims(1, -1)`.</p> <h4 id="args_100">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">outer_axis</code></b>: <code translate="no" dir="ltr">int</code>: The first dimension in the range of dimensions to merge. May be negative if <code translate="no" dir="ltr">self.shape.rank</code> is statically known.</li> <li>
<b><code translate="no" dir="ltr">inner_axis</code></b>: <code translate="no" dir="ltr">int</code>: The last dimension in the range of dimensions to merge. May be negative if <code translate="no" dir="ltr">self.shape.rank</code> is statically known.</li> </ul> <h4 id="returns_111">Returns:</h4> <p>A copy of this tensor, with the specified dimensions merged into a single dimension. The shape of the returned tensor will be <code translate="no" dir="ltr">self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]</code>, where <code translate="no" dir="ltr">N</code> is the total number of slices in the merged dimensions.</p> <h3 id="nested_row_lengths"><code translate="no" dir="ltr">nested_row_lengths</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1323-L1342">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">nested_row_lengths(name=None)
</pre> <p>Returns a tuple containing the row_lengths for all ragged dimensions.</p> <p><code translate="no" dir="ltr">rt.nested_row_lengths()</code> is a tuple containing the <code translate="no" dir="ltr">row_lengths</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost.</p> <h4 id="args_101">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> </ul> <h4 id="returns_112">Returns:</h4> <p>A <code translate="no" dir="ltr">tuple</code> of 1-D integer <code translate="no" dir="ltr">Tensors</code>. The length of the tuple is equal to <code translate="no" dir="ltr">self.ragged_rank</code>.</p> <h3 id="nested_value_rowids"><code translate="no" dir="ltr">nested_value_rowids</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1162-L1197">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">nested_value_rowids(name=None)
</pre> <p>Returns a tuple containing the value_rowids for all ragged dimensions.</p> <p><code translate="no" dir="ltr">rt.nested_value_rowids</code> is a tuple containing the <code translate="no" dir="ltr">value_rowids</code> tensors for all ragged dimensions in <code translate="no" dir="ltr">rt</code>, ordered from outermost to innermost. In particular, <code translate="no" dir="ltr">rt.nested_value_rowids = (rt.value_rowids(),) + value_ids</code> where:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">* `value_ids = ()` if `rt.values` is a `Tensor`.
* `value_ids = rt.values.nested_value_rowids` otherwise.
</pre> <h4 id="args_102">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> </ul> <h4 id="returns_113">Returns:</h4> <p>A <code translate="no" dir="ltr">tuple</code> of 1-D integer <code translate="no" dir="ltr">Tensor</code>s.</p> <h4 id="example_41">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant( 
    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]]) 
for i, ids in enumerate(rt.nested_value_rowids()): 
  print('row ids for dimension %d: %s' % (i+1, ids.numpy())) 
row ids for dimension 1: [0 0 0] 
row ids for dimension 2: [0 0 0 2 2] 
row ids for dimension 3: [0 0 0 0 2 2 2 3] 
</pre> <h3 id="nrows"><code translate="no" dir="ltr">nrows</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1199-L1226">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">nrows(
    out_type=None,
    name=None
)
</pre> <p>Returns the number of rows in this ragged tensor.</p> <p>I.e., the size of the outermost dimension of the tensor.</p> <h4 id="args_103">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">out_type</code></b>: <code translate="no" dir="ltr">dtype</code> for the returned tensor. Defaults to <code translate="no" dir="ltr">self.row_splits.dtype</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> </ul> <h4 id="returns_114">Returns:</h4> <p>A scalar <code translate="no" dir="ltr">Tensor</code> with dtype <code translate="no" dir="ltr">out_type</code>.</p> <h4 id="example_42">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.nrows())  # rt has 5 rows. 
tf.Tensor(5, shape=(), dtype=int64) 
</pre> <h3 id="row_lengths"><code translate="no" dir="ltr">row_lengths</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1278-L1321">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">row_lengths(
    axis=1,
    name=None
)
</pre> <p>Returns the lengths of the rows in this ragged tensor.</p> <p><code translate="no" dir="ltr">rt.row_lengths()[i]</code> indicates the number of values in the <code translate="no" dir="ltr">i</code>th row of <code translate="no" dir="ltr">rt</code>.</p> <h4 id="args_104">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">axis</code></b>: An integer constant indicating the axis whose row lengths should be returned.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> </ul> <h4 id="returns_115">Returns:</h4> <p>A potentially ragged integer Tensor with shape <code translate="no" dir="ltr">self.shape[:axis]</code>.</p> <h4 id="raises_24">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">axis</code> is out of bounds.</li> </ul> <h4 id="example_43">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant( 
    [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []]) 
print(rt.row_lengths())  # lengths of rows in rt 
tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64) 
print(rt.row_lengths(axis=2))  # lengths of axis=2 rows. 
&lt;tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]&gt; 
</pre> <h3 id="row_limits"><code translate="no" dir="ltr">row_limits</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1253-L1276">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">row_limits(name=None)
</pre> <p>Returns the limit indices for rows in this ragged tensor.</p> <p>These indices specify where the values for each row end in <code translate="no" dir="ltr">self.values</code>. <code translate="no" dir="ltr">rt.row_limits(self)</code> is equal to <code translate="no" dir="ltr">rt.row_splits[:-1]</code>.</p> <h4 id="args_105">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> </ul> <h4 id="returns_116">Returns:</h4> <p>A 1-D integer Tensor with shape <code translate="no" dir="ltr">[nrows]</code>. The returned tensor is nonnegative, and is sorted in ascending order.</p> <h4 id="example_44">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.values) 
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) 
print(rt.row_limits())  # indices of row limits in rt.values 
tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64) 
</pre> <h3 id="row_starts"><code translate="no" dir="ltr">row_starts</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1228-L1251">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">row_starts(name=None)
</pre> <p>Returns the start indices for rows in this ragged tensor.</p> <p>These indices specify where the values for each row begin in <code translate="no" dir="ltr">self.values</code>. <code translate="no" dir="ltr">rt.row_starts()</code> is equal to <code translate="no" dir="ltr">rt.row_splits[:-1]</code>.</p> <h4 id="args_106">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> </ul> <h4 id="returns_117">Returns:</h4> <p>A 1-D integer Tensor with shape <code translate="no" dir="ltr">[nrows]</code>. The returned tensor is nonnegative, and is sorted in ascending order.</p> <h4 id="example_45">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.values) 
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) 
print(rt.row_starts())  # indices of row starts in rt.values 
tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64) 
</pre> <h3 id="to_list"><code translate="no" dir="ltr">to_list</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1999-L2012">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">to_list()
</pre> <p>Returns a nested Python <code translate="no" dir="ltr">list</code> with the values for this <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p>Requires that <code translate="no" dir="ltr">rt</code> was constructed in eager execution mode.</p> <h4 id="returns_118">Returns:</h4> <p>A nested Python <code translate="no" dir="ltr">list</code>.</p> <h3 id="to_sparse"><code translate="no" dir="ltr">to_sparse</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1859-L1883">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">to_sparse(name=None)
</pre> <p>Converts this <code translate="no" dir="ltr">RaggedTensor</code> into a <a href="sparse/sparsetensor"><code translate="no" dir="ltr">tf.SparseTensor</code></a>.</p> <h4 id="example_46">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]]) 
print(rt.to_sparse()) 
SparseTensor(indices=tf.Tensor( 
                 [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]], 
                 shape=(6, 2), dtype=int64), 
             values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32), 
             dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64)) 
</pre> <h4 id="args_107">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> </ul> <h4 id="returns_119">Returns:</h4> <p>A SparseTensor with the same values as <code translate="no" dir="ltr">self</code>.</p> <h3 id="to_tensor"><code translate="no" dir="ltr">to_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1748-L1795">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">to_tensor(
    default_value=None,
    name=None,
    shape=None
)
</pre> <p>Converts this <code translate="no" dir="ltr">RaggedTensor</code> into a <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a>.</p> <p>If <code translate="no" dir="ltr">shape</code> is specified, then the result is padded and/or truncated to the specified shape.</p> <h4 id="examples_10">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]]) 
print(rt.to_tensor()) 
tf.Tensor( 
    [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32) 
print(rt.to_tensor(shape=[5, 2])) 
tf.Tensor( 
    [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32) 
</pre> <h4 id="args_108">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">default_value</code></b>: Value to set for indices not specified in <code translate="no" dir="ltr">self</code>. Defaults to zero. <code translate="no" dir="ltr">default_value</code> must be broadcastable to <code translate="no" dir="ltr">self.shape[self.ragged_rank + 1:]</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensors (optional).</li> <li>
<b><code translate="no" dir="ltr">shape</code></b>: The shape of the resulting dense tensor. In particular, <code translate="no" dir="ltr">result.shape[i]</code> is <code translate="no" dir="ltr">shape[i]</code> (if <code translate="no" dir="ltr">shape[i]</code> is not None), or <code translate="no" dir="ltr">self.bounding_shape(i)</code> (otherwise).<code translate="no" dir="ltr">shape.rank</code> must be <code translate="no" dir="ltr">None</code> or equal to <code translate="no" dir="ltr">self.rank</code>.</li> </ul> <h4 id="returns_120">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">ragged.bounding_shape(self)</code> and the values specified by the non-empty values in <code translate="no" dir="ltr">self</code>. Empty values are assigned <code translate="no" dir="ltr">default_value</code>.</p> <h3 id="value_rowids"><code translate="no" dir="ltr">value_rowids</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1132-L1160">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">value_rowids(name=None)
</pre> <p>Returns the row indices for the <code translate="no" dir="ltr">values</code> in this ragged tensor.</p> <p><code translate="no" dir="ltr">rt.value_rowids()</code> corresponds one-to-one with the outermost dimension of <code translate="no" dir="ltr">rt.values</code>, and specifies the row containing each value. In particular, the row <code translate="no" dir="ltr">rt[row]</code> consists of the values <code translate="no" dir="ltr">rt.values[j]</code> where <code translate="no" dir="ltr">rt.value_rowids()[j] == row</code>.</p> <h4 id="args_109">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name prefix for the returned tensor (optional).</li> </ul> <h4 id="returns_121">Returns:</h4> <p>A 1-D integer <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">self.values.shape[:1]</code>. The returned tensor is nonnegative, and is sorted in ascending order.</p> <h4 id="example_47">Example:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []]) 
print(rt.values) 
tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32) 
print(rt.value_rowids())  # corresponds 1:1 with rt.values 
tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64) 
</pre> <h3 id="with_flat_values"><code translate="no" dir="ltr">with_flat_values</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1434-L1453">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">with_flat_values(new_values)
</pre> <p>Returns a copy of <code translate="no" dir="ltr">self</code> with <code translate="no" dir="ltr">flat_values</code> replaced by <code translate="no" dir="ltr">new_value</code>.</p> <p>Preserves cached row-partitioning tensors such as <code translate="no" dir="ltr">self.cached_nrows</code> and <code translate="no" dir="ltr">self.cached_value_rowids</code> if they have values.</p> <h4 id="args_110">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">new_values</code></b>: Potentially ragged tensor that should replace <code translate="no" dir="ltr">self.flat_values</code>. Must have <code translate="no" dir="ltr">rank &gt; 0</code>, and must have the same number of rows as <code translate="no" dir="ltr">self.flat_values</code>.</li> </ul> <h4 id="returns_122">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = self.ragged_rank + new_values.rank</code>. <code translate="no" dir="ltr">result.ragged_rank = self.ragged_rank + new_values.ragged_rank</code>.</p> <h3 id="with_row_splits_dtype"><code translate="no" dir="ltr">with_row_splits_dtype</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1455-L1494">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">with_row_splits_dtype(dtype)
</pre> <p>Returns a copy of this RaggedTensor with the given <code translate="no" dir="ltr">row_splits</code> dtype.</p> <p>For RaggedTensors with multiple ragged dimensions, the <code translate="no" dir="ltr">row_splits</code> for all nested <code translate="no" dir="ltr">RaggedTensor</code> objects are cast to the given dtype.</p> <h4 id="args_111">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: The dtype for <code translate="no" dir="ltr">row_splits</code>. One of <a href="../tf#int32"><code translate="no" dir="ltr">tf.int32</code></a> or <a href="../tf#int64"><code translate="no" dir="ltr">tf.int64</code></a>.</li> </ul> <h4 id="returns_123">Returns:</h4> <p>A copy of this RaggedTensor, with the <code translate="no" dir="ltr">row_splits</code> cast to the given type.</p> <h3 id="with_values"><code translate="no" dir="ltr">with_values</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/ragged/ragged_tensor.py#L1400-L1432">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">with_values(new_values)
</pre> <p>Returns a copy of <code translate="no" dir="ltr">self</code> with <code translate="no" dir="ltr">values</code> replaced by <code translate="no" dir="ltr">new_value</code>.</p> <p>Preserves cached row-partitioning tensors such as <code translate="no" dir="ltr">self.cached_nrows</code> and <code translate="no" dir="ltr">self.cached_value_rowids</code> if they have values.</p> <h4 id="args_112">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">new_values</code></b>: Potentially ragged tensor to use as the <code translate="no" dir="ltr">values</code> for the returned <code translate="no" dir="ltr">RaggedTensor</code>. Must have <code translate="no" dir="ltr">rank &gt; 0</code>, and must have the same number of rows as <code translate="no" dir="ltr">self.values</code>.</li> </ul> <h4 id="returns_124">Returns:</h4> <p>A <code translate="no" dir="ltr">RaggedTensor</code>. <code translate="no" dir="ltr">result.rank = 1 + new_values.rank</code>. <code translate="no" dir="ltr">result.ragged_rank = 1 + new_values.ragged_rank</code></p> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="raggedtensor"><code translate="no" dir="ltr">tf.compat.v1.RaggedTensor</code></a></li> <li><a href="raggedtensor"><code translate="no" dir="ltr">tf.compat.v2.RaggedTensor</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/RaggedTensor" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/RaggedTensor</a>
  </p>
</div>
