<h1 class="devsite-page-title">tf.linalg.lstsq</h1>    <devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax>  <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.linalg.lstsq"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/linalg/lstsq">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/linalg_ops.py#L172-L306">  View source on GitHub </a> </td>
</table>  <p>Solves one or more linear least-squares problems.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.linalg.lstsq(
    matrix,
    rhs,
    l2_regularizer=0.0,
    fast=True,
    name=None
)
</pre>  <p><code translate="no" dir="ltr">matrix</code> is a tensor of shape <code translate="no" dir="ltr">[..., M, N]</code> whose inner-most 2 dimensions form <code translate="no" dir="ltr">M</code>-by-<code translate="no" dir="ltr">N</code> matrices. Rhs is a tensor of shape <code translate="no" dir="ltr">[..., M, K]</code> whose inner-most 2 dimensions form <code translate="no" dir="ltr">M</code>-by-<code translate="no" dir="ltr">K</code> matrices. The computed output is a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[..., N, K]</code> whose inner-most 2 dimensions form <code translate="no" dir="ltr">M</code>-by-<code translate="no" dir="ltr">K</code> matrices that solve the equations <code translate="no" dir="ltr">matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares sense.</p> <p>Below we will use the following notation for each pair of matrix and right-hand sides in the batch:</p> <p><code translate="no" dir="ltr">matrix</code>=\(A \in \Re^{m \times n}\), <code translate="no" dir="ltr">rhs</code>=\(B \in \Re^{m \times k}\), <code translate="no" dir="ltr">output</code>=\(X \in \Re^{n \times k}\), <code translate="no" dir="ltr">l2_regularizer</code>=\(\lambda\).</p> <p>If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">True</code>, then the solution is computed by solving the normal equations using Cholesky decomposition. Specifically, if \(m \ge n\) then \(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the least-squares problem \(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||A Z - B||_F^2 + \lambda ||Z||_F^2\). If \(m \lt n\) then <code translate="no" dir="ltr">output</code> is computed as \(X = A^T (A A^T + \lambda I)^{-1} B\), which (for \(\lambda = 0\)) is the minimum-norm solution to the under-determined linear system, i.e. \(X = \mathrm{argmin}_{Z \in \Re^{n \times k}} ||Z||_F^2 \), subject to \(A Z = B\). Notice that the fast path is only numerically stable when \(A\) is numerically full rank and has a condition number \(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach}}}\) or\(\lambda\) is sufficiently large.</p> <p>If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">False</code> an algorithm based on the numerically robust complete orthogonal decomposition is used. This computes the minimum-norm least-squares solution, even when \(A\) is rank deficient. This path is typically 6-7 times slower than the fast path. If <code translate="no" dir="ltr">fast</code> is <code translate="no" dir="ltr">False</code> then <code translate="no" dir="ltr">l2_regularizer</code> is ignored.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">matrix</code></b>: <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[..., M, N]</code>.</li> <li>
<b><code translate="no" dir="ltr">rhs</code></b>: <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[..., M, K]</code>.</li> <li>
<b><code translate="no" dir="ltr">l2_regularizer</code></b>: 0-D <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>. Ignored if <code translate="no" dir="ltr">fast=False</code>.</li> <li>
<b><code translate="no" dir="ltr">fast</code></b>: bool. Defaults to <code translate="no" dir="ltr">True</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: string, optional name of the operation.</li> </ul> <h4 id="returns">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">output</code></b>: <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[..., N, K]</code> whose inner-most 2 dimensions form <code translate="no" dir="ltr">M</code>-by-<code translate="no" dir="ltr">K</code> matrices that solve the equations <code translate="no" dir="ltr">matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares sense.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">NotImplementedError</code></b>: linalg.lstsq is currently disabled for complex128 and l2_regularizer != 0 due to poor accuracy.</li> </ul> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="lstsq"><code translate="no" dir="ltr">tf.compat.v1.linalg.lstsq</code></a></li> <li><a href="lstsq"><code translate="no" dir="ltr">tf.compat.v1.matrix_solve_ls</code></a></li> <li><a href="lstsq"><code translate="no" dir="ltr">tf.compat.v2.linalg.lstsq</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/lstsq" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/linalg/lstsq</a>
  </p>
</div>
