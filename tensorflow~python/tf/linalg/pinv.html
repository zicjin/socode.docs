<h1 class="devsite-page-title">tf.linalg.pinv</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.linalg.pinv"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/linalg/pinv">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/linalg/linalg_impl.py#L702-L828">  View source on GitHub </a> </td>
</table>  <p>Compute the Moore-Penrose pseudo-inverse of one or more matrices.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.linalg.pinv(
    a,
    rcond=None,
    validate_args=False,
    name=None
)
</pre>  <p>Calculate the <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">generalized inverse of a matrix</a> using its singular-value decomposition (SVD) and including all large singular values.</p> <p>The pseudo-inverse of a matrix <code translate="no" dir="ltr">A</code>, is defined as: 'the matrix that 'solves' [the least-squares problem] <code translate="no" dir="ltr">A @ x = b</code>,' i.e., if <code translate="no" dir="ltr">x_hat</code> is a solution, then <code translate="no" dir="ltr">A_pinv</code> is the matrix such that <code translate="no" dir="ltr">x_hat = A_pinv @ b</code>. It can be shown that if <code translate="no" dir="ltr">U @ Sigma @ V.T = A</code> is the singular value decomposition of <code translate="no" dir="ltr">A</code>, then <code translate="no" dir="ltr">A_pinv = V @ inv(Sigma) U^T</code>. [(Strang, 1980)][1]</p> <p>This function is analogous to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html"><code translate="no" dir="ltr">numpy.linalg.pinv</code></a>. It differs only in default value of <code translate="no" dir="ltr">rcond</code>. In <code translate="no" dir="ltr">numpy.linalg.pinv</code>, the default <code translate="no" dir="ltr">rcond</code> is <code translate="no" dir="ltr">1e-15</code>. Here the default is <code translate="no" dir="ltr">10. * max(num_rows, num_cols) * np.finfo(dtype).eps</code>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">a</code></b>: (Batch of) <code translate="no" dir="ltr">float</code>-like matrix-shaped <code translate="no" dir="ltr">Tensor</code>(s) which are to be pseudo-inverted.</li> <li>
<b><code translate="no" dir="ltr">rcond</code></b>: <code translate="no" dir="ltr">Tensor</code> of small singular value cutoffs. Singular values smaller (in modulus) than <code translate="no" dir="ltr">rcond</code> * largest_singular_value (again, in modulus) are set to zero. Must broadcast against <code translate="no" dir="ltr">tf.shape(a)[:-2]</code>. Default value: <code translate="no" dir="ltr">10. * max(num_rows, num_cols) * np.finfo(a.dtype).eps</code>.</li> <li>
<b><code translate="no" dir="ltr">validate_args</code></b>: When <code translate="no" dir="ltr">True</code>, additional assertions might be embedded in the graph. Default value: <code translate="no" dir="ltr">False</code> (i.e., no graph assertions are added).</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prefixed to ops created by this function. Default value: 'pinv'.</li> </ul> <h4 id="returns">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">a_pinv</code></b>: (Batch of) pseudo-inverse of input <code translate="no" dir="ltr">a</code>. Has same shape as <code translate="no" dir="ltr">a</code> except rightmost two dimensions are transposed.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if input <code translate="no" dir="ltr">a</code> does not have <code translate="no" dir="ltr">float</code>-like <code translate="no" dir="ltr">dtype</code>.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if input <code translate="no" dir="ltr">a</code> has fewer than 2 dimensions.</li> </ul> <h4 id="examples">Examples</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf
import tensorflow_probability as tfp

a = tf.constant([[1.,  0.4,  0.5],
                 [0.4, 0.2,  0.25],
                 [0.5, 0.25, 0.35]])
tf.matmul(tf.linalg..pinv(a), a)
# ==&gt; array([[1., 0., 0.],
             [0., 1., 0.],
             [0., 0., 1.]], dtype=float32)

a = tf.constant([[1.,  0.4,  0.5,  1.],
                 [0.4, 0.2,  0.25, 2.],
                 [0.5, 0.25, 0.35, 3.]])
tf.matmul(tf.linalg..pinv(a), a)
# ==&gt; array([[ 0.76,  0.37,  0.21, -0.02],
             [ 0.37,  0.43, -0.33,  0.02],
             [ 0.21, -0.33,  0.81,  0.01],
             [-0.02,  0.02,  0.01,  1.  ]], dtype=float32)
</pre> <h4 id="references">References</h4> <p>[1]: G. Strang. 'Linear Algebra and Its Applications, 2nd Ed.' Academic Press, Inc., 1980, pp. 139-142.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="pinv"><code translate="no" dir="ltr">tf.compat.v1.linalg.pinv</code></a></li> <li><a href="pinv"><code translate="no" dir="ltr">tf.compat.v2.linalg.pinv</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/pinv" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/linalg/pinv</a>
  </p>
</div>
