<h1 class="devsite-page-title">tf.linalg.matmul</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.linalg.matmul"> <meta itemprop="path" content="Stable"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/linalg/matmul">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/math_ops.py#L2617-L2798">  View source on GitHub </a> </td>
</table>  <p>Multiplies matrix <code translate="no" dir="ltr">a</code> by matrix <code translate="no" dir="ltr">b</code>, producing <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code>.</p> <p><strong>Aliases</strong>: <a href="matmul"><code translate="no" dir="ltr">tf.matmul</code></a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
</pre> <h3 id="used_in_the_guide_2">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/eager">Eager execution</a></li> <li><a href="https://www.tensorflow.org/guide/gpu">Use a GPU</a></li> <li><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Writing custom layers and models with Keras</a></li> <li><a href="https://www.tensorflow.org/guide/function">Better performance with tf.function and AutoGraph</a></li> <li><a href="https://www.tensorflow.org/guide/keras/functional">The Keras functional API in TensorFlow</a></li> </ul> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/customization/basics">Customization basics: tensors and operations</a></li> <li><a href="https://www.tensorflow.org/tutorials/text/transformer">Transformer model for language understanding</a></li> <li><a href="https://www.tensorflow.org/tutorials/customization/custom_layers">Custom layers</a></li> <li><a href="https://www.tensorflow.org/tutorials/customization/performance">Better performance with tf.function</a></li> </ul> <p>The inputs must, following any transpositions, be tensors of rank &gt;= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.</p> <p>Both matrices must be of the same type. The supported types are: <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code>.</p> <p>Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default.</p> <p>If one or both of the matrices contain a lot of zeros, a more efficient multiplication algorithm can be used by setting the corresponding <code translate="no" dir="ltr">a_is_sparse</code> or <code translate="no" dir="ltr">b_is_sparse</code> flag to <code translate="no" dir="ltr">True</code>. These are <code translate="no" dir="ltr">False</code> by default. This optimization is only available for plain matrices (rank-2 tensors) with datatypes <code translate="no" dir="ltr">bfloat16</code> or <code translate="no" dir="ltr">float32</code>.</p> <p>A simple 2-D tensor matrix multiplication:</p> <blockquote>   <p>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) a # 2-D tensor <tf.tensor: shape="(2," dtype="int32," numpy="array([[1,"> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) b # 2-D tensor <tf.tensor: shape="(3," dtype="int32," numpy="array([["> c = tf.matmul(a, b) c # <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code> <tf.tensor: shape="(2," dtype="int32," numpy="array([["></tf.tensor:></tf.tensor:></tf.tensor:></p>   </blockquote> <p>A batch matrix multiplication with batch shape [2]</p> <blockquote>   <p>a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3]) a # 3-D tensor <tf.tensor: shape="(2," dtype="int32," numpy="array([[["> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2]) b # 3-D tensor <tf.tensor: shape="(2," dtype="int32," numpy="array([[[13,"> c = tf.matmul(a, b) c # <code translate="no" dir="ltr">a</code> * <code translate="no" dir="ltr">b</code> <tf.tensor: shape="(2," dtype="int32," numpy="array([[["></tf.tensor:></tf.tensor:></tf.tensor:></p>   </blockquote> <p>Since python &gt;= 3.5 the @ operator is supported (see <a href="https://www.python.org/dev/peps/pep-0465/">PEP 465</a>). In TensorFlow, it simply calls the <a href="matmul"><code translate="no" dir="ltr">tf.matmul()</code></a> function, so the following lines are equivalent:</p> <blockquote>   <p>d = a @ b @ [[10], [11]] d = tf.matmul(tf.matmul(a, b), [[10], [11]])</p>   </blockquote> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">a</code></b>: <a href="../tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of type <code translate="no" dir="ltr">float16</code>, <code translate="no" dir="ltr">float32</code>, <code translate="no" dir="ltr">float64</code>, <code translate="no" dir="ltr">int32</code>, <code translate="no" dir="ltr">complex64</code>, <code translate="no" dir="ltr">complex128</code> and rank &gt; 1.</li> <li>
<b><code translate="no" dir="ltr">b</code></b>: <a href="../tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> with same type and rank as <code translate="no" dir="ltr">a</code>.</li> <li>
<b><code translate="no" dir="ltr">transpose_a</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is transposed before multiplication.</li> <li>
<b><code translate="no" dir="ltr">transpose_b</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is transposed before multiplication.</li> <li>
<b><code translate="no" dir="ltr">adjoint_a</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is conjugated and transposed before multiplication.</li> <li>
<b><code translate="no" dir="ltr">adjoint_b</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is conjugated and transposed before multiplication.</li> <li>
<b><code translate="no" dir="ltr">a_is_sparse</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">a</code> is treated as a sparse matrix.</li> <li>
<b><code translate="no" dir="ltr">b_is_sparse</code></b>: If <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">b</code> is treated as a sparse matrix.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Name for the operation (optional).</li> </ul> <h4 id="returns_2">Returns:</h4> <p>A <a href="../tensor"><code translate="no" dir="ltr">tf.Tensor</code></a> of the same type as <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code> where each inner-most matrix is the product of the corresponding matrices in <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>, e.g. if all transpose or adjoint attributes are <code translate="no" dir="ltr">False</code>:</p> <p><code translate="no" dir="ltr">output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])</code>, for all indices <code translate="no" dir="ltr">i</code>, <code translate="no" dir="ltr">j</code>.</p> <ul> <li>
<b><code translate="no" dir="ltr">Note</code></b>: This is matrix product, not element-wise product.</li> </ul> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">transpose_a</code> and <code translate="no" dir="ltr">adjoint_a</code>, or <code translate="no" dir="ltr">transpose_b</code> and <code translate="no" dir="ltr">adjoint_b</code> are both set to <code translate="no" dir="ltr">True</code>.</li> </ul> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="matmul"><code translate="no" dir="ltr">tf.compat.v1.linalg.matmul</code></a></li> <li><a href="matmul"><code translate="no" dir="ltr">tf.compat.v1.matmul</code></a></li> <li><a href="matmul"><code translate="no" dir="ltr">tf.compat.v2.linalg.matmul</code></a></li> <li><a href="matmul"><code translate="no" dir="ltr">tf.compat.v2.matmul</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/linalg/matmul</a>
  </p>
</div>
