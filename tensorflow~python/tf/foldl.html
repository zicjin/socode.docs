<h1 class="devsite-page-title">tf.foldl</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.foldl"> <meta itemprop="path" content="Stable"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/foldl">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/functional_ops.py#L45-L159">  View source on GitHub </a> </td>
</table>  <p>foldl on the list of tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.foldl(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None
)
</pre>  <p>This foldl operator repeatedly applies the callable <code translate="no" dir="ltr">fn</code> to a sequence of elements from first to last. The elements are made of the tensors unpacked from <code translate="no" dir="ltr">elems</code> on dimension 0. The callable fn takes two tensors as arguments. The first argument is the accumulated value computed from the preceding invocation of fn, and the second is the value at the current position of <code translate="no" dir="ltr">elems</code>. If <code translate="no" dir="ltr">initializer</code> is None, <code translate="no" dir="ltr">elems</code> must contain at least one element, and its first element is used as the initializer.</p> <p>Suppose that <code translate="no" dir="ltr">elems</code> is unpacked into <code translate="no" dir="ltr">values</code>, a list of tensors. The shape of the result tensor is fn(initializer, values[0]).shape`.</p> <p>This method also allows multi-arity <code translate="no" dir="ltr">elems</code> and output of <code translate="no" dir="ltr">fn</code>. If <code translate="no" dir="ltr">elems</code> is a (possibly nested) list or tuple of tensors, then each of these tensors must have a matching first (unpack) dimension. The signature of <code translate="no" dir="ltr">fn</code> may match the structure of <code translate="no" dir="ltr">elems</code>. That is, if <code translate="no" dir="ltr">elems</code> is <code translate="no" dir="ltr">(t1, [t2, t3, [t4, t5]])</code>, then an appropriate signature for <code translate="no" dir="ltr">fn</code> is: <code translate="no" dir="ltr">fn = lambda (t1, [t2, t3, [t4, t5]]):</code>.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">fn</code></b>: The callable to be performed.</li> <li>
<b><code translate="no" dir="ltr">elems</code></b>: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be the first argument to <code translate="no" dir="ltr">fn</code>.</li> <li>
<b><code translate="no" dir="ltr">initializer</code></b>: (optional) A tensor or (possibly nested) sequence of tensors, as the initial value for the accumulator.</li> <li>
<b><code translate="no" dir="ltr">parallel_iterations</code></b>: (optional) The number of iterations allowed to run in parallel.</li> <li>
<b><code translate="no" dir="ltr">back_prop</code></b>: (optional) True enables support for back propagation.</li> <li>
<b><code translate="no" dir="ltr">swap_memory</code></b>: (optional) True enables GPU-CPU memory swapping.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: (optional) Name prefix for the returned tensors.</li> </ul> <h4 id="returns_2">Returns:</h4> <p>A tensor or (possibly nested) sequence of tensors, resulting from applying <code translate="no" dir="ltr">fn</code> consecutively to the list of tensors unpacked from <code translate="no" dir="ltr">elems</code>, from first to last.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if <code translate="no" dir="ltr">fn</code> is not callable.</li> </ul> <h4 id="example_2">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">elems = tf.constant([1, 2, 3, 4, 5, 6])
sum = foldl(lambda a, x: a + x, elems)
# sum == 21
</pre> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="foldl"><code translate="no" dir="ltr">tf.compat.v1.foldl</code></a></li> <li><a href="foldl"><code translate="no" dir="ltr">tf.compat.v2.foldl</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/foldl" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/foldl</a>
  </p>
</div>
