<h1 class="devsite-page-title">tf.nn.safe_embedding_lookup_sparse</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn.safe_embedding_lookup_sparse"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn/safe_embedding_lookup_sparse">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/embedding_ops.py#L627-L688">  View source on GitHub </a> </td>
</table>  <p>Lookup embedding results, accounting for invalid IDs and empty features.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.nn.safe_embedding_lookup_sparse(
    embedding_weights,
    sparse_ids,
    sparse_weights=None,
    combiner='mean',
    default_id=None,
    max_norm=None,
    name=None
)
</pre>  <p>The partitioned embedding in <code translate="no" dir="ltr">embedding_weights</code> must all be the same shape except for the first dimension. The first dimension is allowed to vary as the vocabulary size is not necessarily a multiple of <code translate="no" dir="ltr">P</code>. <code translate="no" dir="ltr">embedding_weights</code> may be a <code translate="no" dir="ltr">PartitionedVariable</code> as returned by using <a href="../compat/v1/get_variable"><code translate="no" dir="ltr">tf.compat.v1.get_variable()</code></a> with a partitioner.</p> <p>Invalid IDs (&lt; 0) are pruned from input IDs and weights, as well as any IDs with non-positive weight. For an entry with no features, the embedding vector for <code translate="no" dir="ltr">default_id</code> is returned, or the 0-vector if <code translate="no" dir="ltr">default_id</code> is not supplied.</p> <p>The ids and weights may be multi-dimensional. Embeddings are always aggregated along the last dimension.</p> <blockquote class="note">
<strong>Note:</strong><span> when doing embedding lookup on <code translate="no" dir="ltr">embedding_weights</code>, "div" partition strategy will be used. Support for other partition strategy will be added later.</span>
</blockquote> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">embedding_weights</code></b>: A list of <code translate="no" dir="ltr">P</code> float <code translate="no" dir="ltr">Tensor</code>s or values representing partitioned embedding <code translate="no" dir="ltr">Tensor</code>s. Alternatively, a <code translate="no" dir="ltr">PartitionedVariable</code> created by partitioning along dimension 0. The total unpartitioned shape should be <code translate="no" dir="ltr">[e_0, e_1, ..., e_m]</code>, where <code translate="no" dir="ltr">e_0</code> represents the vocab size and <code translate="no" dir="ltr">e_1, ..., e_m</code> are the embedding dimensions.</li> <li>
<b><code translate="no" dir="ltr">sparse_ids</code></b>: <code translate="no" dir="ltr">SparseTensor</code> of shape <code translate="no" dir="ltr">[d_0, d_1, ..., d_n]</code> containing the ids. <code translate="no" dir="ltr">d_0</code> is typically batch size.</li> <li>
<b><code translate="no" dir="ltr">sparse_weights</code></b>: <code translate="no" dir="ltr">SparseTensor</code> of same shape as <code translate="no" dir="ltr">sparse_ids</code>, containing float weights corresponding to <code translate="no" dir="ltr">sparse_ids</code>, or <code translate="no" dir="ltr">None</code> if all weights are be assumed to be 1.0.</li> <li>
<b><code translate="no" dir="ltr">combiner</code></b>: A string specifying how to combine embedding results for each entry. Currently "mean", "sqrtn" and "sum" are supported, with "mean" the default.</li> <li>
<b><code translate="no" dir="ltr">default_id</code></b>: The id to use for an entry with no features.</li> <li>
<b><code translate="no" dir="ltr">max_norm</code></b>: If not <code translate="no" dir="ltr">None</code>, all embeddings are l2-normalized to max_norm before combining.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for this operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>Dense <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">[d_0, d_1, ..., d_{n-1}, e_1, ..., e_m]</code>.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">embedding_weights</code> is empty.</li> </ul> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="safe_embedding_lookup_sparse"><code translate="no" dir="ltr">tf.compat.v2.nn.safe_embedding_lookup_sparse</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn/safe_embedding_lookup_sparse" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn/safe_embedding_lookup_sparse</a>
  </p>
</div>
