<h1 class="devsite-page-title">tf.nn.dropout</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn.dropout"> <meta itemprop="path" content="Stable"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn/dropout">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/nn_ops.py#L4292-L4406">  View source on GitHub </a> </td>
</table>  <p>Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.nn.dropout(
    x,
    rate,
    noise_shape=None,
    seed=None,
    name=None
)
</pre> <h3 id="used_in_the_guide_2">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Writing custom layers and models with Keras</a></li> </ul> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/customization/performance">Better performance with tf.function</a></li> </ul> <blockquote class="note">
<strong>Note:</strong><span> The behavior of dropout has changed between TensorFlow 1.x and 2.x. When converting 1.x code, please use named arguments to ensure behavior stays consistent.</span>
</blockquote> <p>See also: <a href="../keras/layers/dropout"><code translate="no" dir="ltr">tf.keras.layers.Dropout</code></a> for a dropout layer.</p> <p><a href="https://arxiv.org/abs/1207.0580">Dropout</a> is useful for regularizing DNN models. Inputs elements are randomly set to zero (and the other elements are rescaled). This encourages each node to be independently useful, as it cannot rely on the output of other nodes.</p> <p>More precisely: With probability <code translate="no" dir="ltr">rate</code> elements of <code translate="no" dir="ltr">x</code> are set to <code translate="no" dir="ltr">0</code>. The remaining elemenst are scaled up by <code translate="no" dir="ltr">1.0 / (1 - rate)</code>, so that the expected value is preserved.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
tf.random.set_seed(0) 
x = tf.ones([3,5]) 
tf.nn.dropout(x, rate = 0.5).numpy() 
array([[0., 0., 2., 2., 0.], 
       [2., 0., 2., 2., 0.], 
       [2., 2., 2., 0., 0.]], dtype=float32) 
tf.nn.dropout(x, rate = 0.8).numpy() 
array([[0., 0., 5., 0., 0.], 
       [0., 0., 5., 0., 0.], 
       [5., 0., 0., 5., 0.]], dtype=float32) 
</pre> <p>If rate is set to <code translate="no" dir="ltr">0</code> the input is returned, unchanged:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
tf.nn.dropout(x, rate = 0.0) is x 
True 
</pre> <p>By default, each element is kept or dropped independently. If <code translate="no" dir="ltr">noise_shape</code> is specified, it must be <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcastable</a> to the shape of <code translate="no" dir="ltr">x</code>, and only dimensions with <code translate="no" dir="ltr">noise_shape[i] == shape(x)[i]</code> will make independent decisions. This is useful for dropping whole channels from an image or sequence. For example:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="python">
x = tf.ones([3,10]) 
tf.nn.dropout(x, rate = 2/3, noise_shape=[1,10]).numpy() 
array([[0., 3., 0., 3., 0., 0., 3., 0., 0., 3.], 
       [0., 3., 0., 3., 0., 0., 3., 0., 0., 3.], 
       [0., 3., 0., 3., 0., 0., 3., 0., 0., 3.]], dtype=float32) 
</pre> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: A floating point tensor.</li> <li>
<b><code translate="no" dir="ltr">rate</code></b>: A scalar <code translate="no" dir="ltr">Tensor</code> with the same type as x. The probability that each element is dropped. For example, setting rate=0.1 would drop 10% of input elements.</li> <li>
<b><code translate="no" dir="ltr">noise_shape</code></b>: A 1-D <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">int32</code>, representing the shape for randomly generated keep/drop flags.</li> <li>
<b><code translate="no" dir="ltr">seed</code></b>: A Python integer. Used to create random seeds. See <a href="../random/set_seed"><code translate="no" dir="ltr">tf.random.set_seed</code></a> for behavior.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for this operation (optional).</li> </ul> <h4 id="returns_2">Returns:</h4> <p>A Tensor of the same shape of <code translate="no" dir="ltr">x</code>.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">rate</code> is not in <code translate="no" dir="ltr">[0, 1)</code> or if <code translate="no" dir="ltr">x</code> is not a floating point tensor. <code translate="no" dir="ltr">rate=1</code> is disallowed, because theoutput would be all zeros, which is likely not what was intended.</li> </ul> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="dropout"><code translate="no" dir="ltr">tf.compat.v2.nn.dropout</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn/dropout</a>
  </p>
</div>
