<h1 class="devsite-page-title">tf.nn.space_to_depth</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.nn.space_to_depth"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn/space_to_depth">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/array_ops.py#L3367-L3369">  View source on GitHub </a> </td>
</table>  <p>SpaceToDepth for tensors of type T.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.nn.space_to_depth(
    input,
    block_size,
    data_format='NHWC',
    name=None
)
</pre>  <p>Rearranges blocks of spatial data, into depth. More specifically, this op outputs a copy of the input tensor where values from the <code translate="no" dir="ltr">height</code> and <code translate="no" dir="ltr">width</code> dimensions are moved to the <code translate="no" dir="ltr">depth</code> dimension. The attr <code translate="no" dir="ltr">block_size</code> indicates the input block size.</p> <ul> <li>Non-overlapping blocks of size <code translate="no" dir="ltr">block_size x block size</code> are rearranged into depth at each location.</li> <li>The depth of the output tensor is <code translate="no" dir="ltr">block_size * block_size * input_depth</code>.</li> <li>The Y, X coordinates within each block of the input become the high order component of the output channel index.</li> <li>The input tensor's height and width must be divisible by block_size.</li> </ul> <p>The <code translate="no" dir="ltr">data_format</code> attr specifies the layout of the input and output tensors with the following options: "NHWC": <code translate="no" dir="ltr">[ batch, height, width, channels ]</code> "NCHW": <code translate="no" dir="ltr">[ batch, channels, height, width ]</code> "NCHW_VECT_C": <code translate="no" dir="ltr">qint8 [ batch, channels / 4, height, width, 4 ]</code></p> <p>It is useful to consider the operation as transforming a 6-D Tensor. e.g. for data_format = NHWC, Each element in the input tensor can be specified via 6 coordinates, ordered by decreasing memory layout significance as: n,oY,bY,oX,bX,iC (where n=batch index, oX, oY means X or Y coordinates within the output image, bX, bY means coordinates within the input block, iC means input channels). The output would be a transpose to the following layout: n,oY,oX,bY,bX,iC</p> <p>This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.</p> <p>For example, given an input of shape <code translate="no" dir="ltr">[1, 2, 2, 1]</code>, data_format = "NHWC" and block_size = 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1], [2]],
      [[3], [4]]]]
</pre> <p>This operation will output a tensor of shape <code translate="no" dir="ltr">[1, 1, 1, 4]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1, 2, 3, 4]]]]
</pre> <p>Here, the input has a batch of 1 and each batch element has shape <code translate="no" dir="ltr">[2, 2, 1]</code>, the corresponding output will have a single element (i.e. width and height are both 1) and will have a depth of 4 channels (1 * block_size * block_size). The output element shape is <code translate="no" dir="ltr">[1, 1, 4]</code>.</p> <p>For an input tensor with larger depth, here of shape <code translate="no" dir="ltr">[1, 2, 2, 3]</code>, e.g.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1, 2, 3], [4, 5, 6]],
      [[7, 8, 9], [10, 11, 12]]]]
</pre> <p>This operation, for block_size of 2, will return the following tensor of shape <code translate="no" dir="ltr">[1, 1, 1, 12]</code></p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
</pre> <p>Similarly, for the following input of shape <code translate="no" dir="ltr">[1 4 4 1]</code>, and a block size of 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1],   [2],  [5],  [6]],
      [[3],   [4],  [7],  [8]],
      [[9],  [10], [13],  [14]],
      [[11], [12], [15],  [16]]]]
</pre> <p>the operator will return the following tensor of shape <code translate="no" dir="ltr">[1 2 2 4]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]
</pre> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">input</code></b>: A <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">block_size</code></b>: An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 2</code>. The size of the spatial block.</li> <li>
<b><code translate="no" dir="ltr">data_format</code></b>: An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"NHWC", "NCHW", "NCHW_VECT_C"</code>. Defaults to <code translate="no" dir="ltr">"NHWC"</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">input</code>.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="space_to_depth"><code translate="no" dir="ltr">tf.compat.v2.nn.space_to_depth</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/nn/space_to_depth" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/nn/space_to_depth</a>
  </p>
</div>
