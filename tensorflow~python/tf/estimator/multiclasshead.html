<h1 class="devsite-page-title">tf.estimator.MultiClassHead</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.estimator.MultiClassHead"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="logits_dimension"> <meta itemprop="property" content="loss_reduction"> <meta itemprop="property" content="name"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="create_estimator_spec"> <meta itemprop="property" content="loss"> <meta itemprop="property" content="metrics"> <meta itemprop="property" content="predictions"> <meta itemprop="property" content="update_metrics"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/MultiClassHead">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">  View source on GitHub </a> </td>
</table>  <h2 id="class_multiclasshead_2">Class <code translate="no" dir="ltr">MultiClassHead</code>
</h2> <p>Creates a <code translate="no" dir="ltr">Head</code> for multi class classification.</p> <p>Inherits From: <a href="head"><code translate="no" dir="ltr">Head</code></a></p>  <p>Uses <code translate="no" dir="ltr">sparse_softmax_cross_entropy</code> loss.</p> <p>The head expects <code translate="no" dir="ltr">logits</code> with shape <code translate="no" dir="ltr">[D0, D1, ... DN, n_classes]</code>. In many applications, the shape is <code translate="no" dir="ltr">[batch_size, n_classes]</code>.</p> <p><code translate="no" dir="ltr">labels</code> must be a dense <code translate="no" dir="ltr">Tensor</code> with shape matching <code translate="no" dir="ltr">logits</code>, namely <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>. If <code translate="no" dir="ltr">label_vocabulary</code> given, <code translate="no" dir="ltr">labels</code> must be a string <code translate="no" dir="ltr">Tensor</code> with values from the vocabulary. If <code translate="no" dir="ltr">label_vocabulary</code> is not given, <code translate="no" dir="ltr">labels</code> must be an integer <code translate="no" dir="ltr">Tensor</code> with values specifying the class index.</p> <p>If <code translate="no" dir="ltr">weight_column</code> is specified, weights must be of shape <code translate="no" dir="ltr">[D0, D1, ... DN]</code>, or <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>.</p> <p>The loss is the weighted sum over the input dimensions. Namely, if the input labels have shape <code translate="no" dir="ltr">[batch_size, 1]</code>, the loss is the weighted sum over <code translate="no" dir="ltr">batch_size</code>.</p> <p>Also supports custom <code translate="no" dir="ltr">loss_fn</code>. <code translate="no" dir="ltr">loss_fn</code> takes <code translate="no" dir="ltr">(labels, logits)</code> or <code translate="no" dir="ltr">(labels, logits, features, loss_reduction)</code> as arguments and returns unreduced loss with shape <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>. <code translate="no" dir="ltr">loss_fn</code> must support integer <code translate="no" dir="ltr">labels</code> with shape <code translate="no" dir="ltr">[D0, D1, ... DN, 1]</code>. Namely, the head applies <code translate="no" dir="ltr">label_vocabulary</code> to the input labels before passing them to <code translate="no" dir="ltr">loss_fn</code>.</p> <p>The head can be used with a canned estimator. Example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">my_head = tf.estimator.MultiClassHead(n_classes=3)
my_estimator = tf.estimator.DNNEstimator(
    head=my_head,
    hidden_units=...,
    feature_columns=...)
</pre> <p>It can also be used with a custom <code translate="no" dir="ltr">model_fn</code>. Example:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def _my_model_fn(features, labels, mode):
  my_head = tf.estimator.MultiClassHead(n_classes=3)
  logits = tf.keras.Model(...)(features)

  return my_head.create_estimator_spec(
      features=features,
      mode=mode,
      labels=labels,
      optimizer=tf.keras.optimizers.Adagrad(lr=0.1),
      logits=logits)

my_estimator = tf.estimator.Estimator(model_fn=_my_model_fn)
</pre> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">n_classes</code></b>: Number of classes, must be greater than 2 (for 2 classes, use <code translate="no" dir="ltr">BinaryClassHead</code>).</li> <li>
<b><code translate="no" dir="ltr">weight_column</code></b>: A string or a <code translate="no" dir="ltr">NumericColumn</code> created by <a href="../feature_column/numeric_column"><code translate="no" dir="ltr">tf.feature_column.numeric_column</code></a> defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example.</li> <li>
<b><code translate="no" dir="ltr">label_vocabulary</code></b>: A list or tuple of strings representing possible label values. If it is not given, that means labels are already encoded as an integer within [0, n_classes). If given, labels must be of string type and have any value in <code translate="no" dir="ltr">label_vocabulary</code>. Note that errors will be raised if <code translate="no" dir="ltr">label_vocabulary</code> is not provided but labels are strings. If both <code translate="no" dir="ltr">n_classes</code> and <code translate="no" dir="ltr">label_vocabulary</code> are provided, <code translate="no" dir="ltr">label_vocabulary</code> should contain exactly <code translate="no" dir="ltr">n_classes</code> items.</li> <li>
<b><code translate="no" dir="ltr">loss_reduction</code></b>: One of <a href="../keras/losses/reduction"><code translate="no" dir="ltr">tf.losses.Reduction</code></a> except <code translate="no" dir="ltr">NONE</code>. Decides how to reduce training loss over batch. Defaults to <code translate="no" dir="ltr">SUM_OVER_BATCH_SIZE</code>, namely weighted sum of losses divided by <code translate="no" dir="ltr">batch size * label_dimension</code>.</li> <li>
<b><code translate="no" dir="ltr">loss_fn</code></b>: Optional loss function.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Name of the head. If provided, summary and metrics keys will be suffixed by <code translate="no" dir="ltr">"/" + name</code>. Also used as <code translate="no" dir="ltr">name_scope</code> when creating ops.</li> </ul> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    n_classes,
    weight_column=None,
    label_vocabulary=None,
    loss_reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    name=None
)
</pre> <p>Initialize self. See help(type(self)) for accurate signature.</p> <h2 id="properties_2">Properties</h2> <h3 id="logits_dimension"><code translate="no" dir="ltr">logits_dimension</code></h3> <p>See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="loss_reduction"><code translate="no" dir="ltr">loss_reduction</code></h3> <p>See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="name"><code translate="no" dir="ltr">name</code></h3> <p>See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h2 id="methods_2">Methods</h2> <h3 id="create_estimator_spec"><code translate="no" dir="ltr">create_estimator_spec</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/base_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">create_estimator_spec(
    features,
    mode,
    logits,
    labels=None,
    optimizer=None,
    trainable_variables=None,
    train_op_fn=None,
    update_ops=None,
    regularization_losses=None
)
</pre> <p>Returns <code translate="no" dir="ltr">EstimatorSpec</code> that a model_fn can return.</p> <p>It is recommended to pass all args via name.</p> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">features</code></b>: Input <code translate="no" dir="ltr">dict</code> mapping string feature names to <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects containing the values for that feature in a minibatch. Often to be used to fetch example-weight tensor.</li> <li>
<b><code translate="no" dir="ltr">mode</code></b>: Estimator's <code translate="no" dir="ltr">ModeKeys</code>.</li> <li>
<b><code translate="no" dir="ltr">logits</code></b>: Logits <code translate="no" dir="ltr">Tensor</code> to be used by the head.</li> <li>
<b><code translate="no" dir="ltr">labels</code></b>: Labels <code translate="no" dir="ltr">Tensor</code>, or <code translate="no" dir="ltr">dict</code> mapping string label names to <code translate="no" dir="ltr">Tensor</code> objects of the label values.</li> <li>
<b><code translate="no" dir="ltr">optimizer</code></b>: An <a href="../keras/optimizers/optimizer"><code translate="no" dir="ltr">tf.keras.optimizers.Optimizer</code></a> instance to optimize the loss in TRAIN mode. Namely, sets <code translate="no" dir="ltr">train_op = optimizer.get_updates(loss, trainable_variables)</code>, which updates variables to minimize <code translate="no" dir="ltr">loss</code>.</li> <li>
<b><code translate="no" dir="ltr">trainable_variables</code></b>: A list or tuple of <code translate="no" dir="ltr">Variable</code> objects to update to minimize <code translate="no" dir="ltr">loss</code>. In Tensorflow 1.x, by default these are the list of variables collected in the graph under the key <code translate="no" dir="ltr">GraphKeys.TRAINABLE_VARIABLES</code>. As Tensorflow 2.x doesn't have collections and GraphKeys, trainable_variables need to be passed explicitly here.</li> <li>
<b><code translate="no" dir="ltr">train_op_fn</code></b>: Function that takes a scalar loss <code translate="no" dir="ltr">Tensor</code> and returns an op to optimize the model with the loss in TRAIN mode. Used if <code translate="no" dir="ltr">optimizer</code> is <code translate="no" dir="ltr">None</code>. Exactly one of <code translate="no" dir="ltr">train_op_fn</code> and <code translate="no" dir="ltr">optimizer</code> must be set in TRAIN mode. By default, it is <code translate="no" dir="ltr">None</code> in other modes. If you want to optimize loss yourself, you can pass <code translate="no" dir="ltr">lambda _: tf.no_op()</code> and then use <a href="estimatorspec#loss"><code translate="no" dir="ltr">EstimatorSpec.loss</code></a> to compute and apply gradients.</li> <li>
<b><code translate="no" dir="ltr">update_ops</code></b>: A list or tuple of update ops to be run at training time. For example, layers such as BatchNormalization create mean and variance update ops that need to be run at training time. In Tensorflow 1.x, these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x doesn't have collections, update_ops need to be passed explicitly here.</li> <li>
<b><code translate="no" dir="ltr">regularization_losses</code></b>: A list of additional scalar losses to be added to the training loss, such as regularization losses.</li> </ul> <h4 id="returns_3">Returns:</h4> <p><code translate="no" dir="ltr">EstimatorSpec</code>.</p> <h3 id="loss"><code translate="no" dir="ltr">loss</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">loss(
    labels,
    logits,
    features=None,
    mode=None,
    regularization_losses=None
)
</pre> <p>Returns regularized training loss. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="metrics"><code translate="no" dir="ltr">metrics</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">metrics(regularization_losses=None)
</pre> <p>Creates metrics. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h3 id="predictions"><code translate="no" dir="ltr">predictions</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predictions(
    logits,
    keys=None
)
</pre> <p>Return predictions based on keys. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">logits</code></b>: logits <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[D0, D1, ... DN, logits_dimension]</code>. For many applications, the shape is <code translate="no" dir="ltr">[batch_size, logits_dimension]</code>.</li> <li>
<b><code translate="no" dir="ltr">keys</code></b>: a list or tuple of prediction keys. Each key can be either the class variable of prediction_keys.PredictionKeys or its string value, such as: prediction_keys.PredictionKeys.CLASSES or 'classes'. If not specified, it will return the predictions for all valid keys.</li> </ul> <h4 id="returns_4">Returns:</h4> <p>A dict of predictions.</p> <h3 id="update_metrics"><code translate="no" dir="ltr">update_metrics</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_class_head.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">update_metrics(
    eval_metrics,
    features,
    logits,
    labels,
    regularization_losses=None
)
</pre> <p>Updates eval metrics. See <code translate="no" dir="ltr">base_head.Head</code> for details.</p> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="multiclasshead"><code translate="no" dir="ltr">tf.compat.v1.estimator.MultiClassHead</code></a></li> <li><a href="multiclasshead"><code translate="no" dir="ltr">tf.compat.v2.estimator.MultiClassHead</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/MultiClassHead" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/estimator/MultiClassHead</a>
  </p>
</div>
