<h1 class="devsite-page-title">tf.estimator.RunConfig</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.estimator.RunConfig"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="cluster_spec"> <meta itemprop="property" content="device_fn"> <meta itemprop="property" content="eval_distribute"> <meta itemprop="property" content="evaluation_master"> <meta itemprop="property" content="experimental_max_worker_delay_secs"> <meta itemprop="property" content="global_id_in_cluster"> <meta itemprop="property" content="is_chief"> <meta itemprop="property" content="keep_checkpoint_every_n_hours"> <meta itemprop="property" content="keep_checkpoint_max"> <meta itemprop="property" content="log_step_count_steps"> <meta itemprop="property" content="master"> <meta itemprop="property" content="model_dir"> <meta itemprop="property" content="num_ps_replicas"> <meta itemprop="property" content="num_worker_replicas"> <meta itemprop="property" content="protocol"> <meta itemprop="property" content="save_checkpoints_secs"> <meta itemprop="property" content="save_checkpoints_steps"> <meta itemprop="property" content="save_summary_steps"> <meta itemprop="property" content="service"> <meta itemprop="property" content="session_config"> <meta itemprop="property" content="session_creation_timeout_secs"> <meta itemprop="property" content="task_id"> <meta itemprop="property" content="task_type"> <meta itemprop="property" content="tf_random_seed"> <meta itemprop="property" content="train_distribute"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="replace"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/RunConfig">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/run_config.py">  View source on GitHub </a> </td>
</table>  <h2 id="class_runconfig">Class <code translate="no" dir="ltr">RunConfig</code>
</h2> <p>This class specifies the configurations for an <code translate="no" dir="ltr">Estimator</code> run.</p> <h3 id="used_in_the_guide">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/distributed_training">Distributed training with TensorFlow</a></li> </ul> <h3 id="used_in_the_tutorials">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/distribute/multi_worker_with_estimator">Multi-worker training with Estimator</a></li> </ul> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/run_config.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    model_dir=None,
    tf_random_seed=None,
    save_summary_steps=100,
    save_checkpoints_steps=_USE_DEFAULT,
    save_checkpoints_secs=_USE_DEFAULT,
    session_config=None,
    keep_checkpoint_max=5,
    keep_checkpoint_every_n_hours=10000,
    log_step_count_steps=100,
    train_distribute=None,
    device_fn=None,
    protocol=None,
    eval_distribute=None,
    experimental_distribute=None,
    experimental_max_worker_delay_secs=None,
    session_creation_timeout_secs=7200
)
</pre> <p>Constructs a RunConfig.</p> <p>All distributed training related properties <code translate="no" dir="ltr">cluster_spec</code>, <code translate="no" dir="ltr">is_chief</code>, <code translate="no" dir="ltr">master</code> , <code translate="no" dir="ltr">num_worker_replicas</code>, <code translate="no" dir="ltr">num_ps_replicas</code>, <code translate="no" dir="ltr">task_id</code>, and <code translate="no" dir="ltr">task_type</code> are set based on the <code translate="no" dir="ltr">TF_CONFIG</code> environment variable, if the pertinent information is present. The <code translate="no" dir="ltr">TF_CONFIG</code> environment variable is a JSON object with attributes: <code translate="no" dir="ltr">cluster</code> and <code translate="no" dir="ltr">task</code>.</p> <p><code translate="no" dir="ltr">cluster</code> is a JSON serialized version of <code translate="no" dir="ltr">ClusterSpec</code>'s Python dict from <code translate="no" dir="ltr">server_lib.py</code>, mapping task types (usually one of the <code translate="no" dir="ltr">TaskType</code> enums) to a list of task addresses.</p> <p><code translate="no" dir="ltr">task</code> has two attributes: <code translate="no" dir="ltr">type</code> and <code translate="no" dir="ltr">index</code>, where <code translate="no" dir="ltr">type</code> can be any of the task types in <code translate="no" dir="ltr">cluster</code>. When <code translate="no" dir="ltr">TF_CONFIG</code> contains said information, the following properties are set on this class:</p> <ul> <li>
<code translate="no" dir="ltr">cluster_spec</code> is parsed from <code translate="no" dir="ltr">TF_CONFIG['cluster']</code>. Defaults to {}. If present, must have one and only one node in the <code translate="no" dir="ltr">chief</code> attribute of <code translate="no" dir="ltr">cluster_spec</code>.</li> <li>
<code translate="no" dir="ltr">task_type</code> is set to <code translate="no" dir="ltr">TF_CONFIG['task']['type']</code>. Must set if <code translate="no" dir="ltr">cluster_spec</code> is present; must be <code translate="no" dir="ltr">worker</code> (the default value) if <code translate="no" dir="ltr">cluster_spec</code> is not set.</li> <li>
<code translate="no" dir="ltr">task_id</code> is set to <code translate="no" dir="ltr">TF_CONFIG['task']['index']</code>. Must set if <code translate="no" dir="ltr">cluster_spec</code> is present; must be 0 (the default value) if <code translate="no" dir="ltr">cluster_spec</code> is not set.</li> <li>
<code translate="no" dir="ltr">master</code> is determined by looking up <code translate="no" dir="ltr">task_type</code> and <code translate="no" dir="ltr">task_id</code> in the <code translate="no" dir="ltr">cluster_spec</code>. Defaults to ''.</li> <li>
<code translate="no" dir="ltr">num_ps_replicas</code> is set by counting the number of nodes listed in the <code translate="no" dir="ltr">ps</code> attribute of <code translate="no" dir="ltr">cluster_spec</code>. Defaults to 0.</li> <li>
<code translate="no" dir="ltr">num_worker_replicas</code> is set by counting the number of nodes listed in the <code translate="no" dir="ltr">worker</code> and <code translate="no" dir="ltr">chief</code> attributes of <code translate="no" dir="ltr">cluster_spec</code>. Defaults to 1.</li> <li>
<code translate="no" dir="ltr">is_chief</code> is determined based on <code translate="no" dir="ltr">task_type</code> and <code translate="no" dir="ltr">cluster</code>.</li> </ul> <p>There is a special node with <code translate="no" dir="ltr">task_type</code> as <code translate="no" dir="ltr">evaluator</code>, which is not part of the (training) <code translate="no" dir="ltr">cluster_spec</code>. It handles the distributed evaluation job.</p> <p>Example of non-chief node:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">cluster = {'chief': ['host0:2222'],
           'ps': ['host1:2222', 'host2:2222'],
           'worker': ['host3:2222', 'host4:2222', 'host5:2222']}
os.environ['TF_CONFIG'] = json.dumps(
    {'cluster': cluster,
     'task': {'type': 'worker', 'index': 1}})
config = RunConfig()
assert config.master == 'host4:2222'
assert config.task_id == 1
assert config.num_ps_replicas == 2
assert config.num_worker_replicas == 4
assert config.cluster_spec == server_lib.ClusterSpec(cluster)
assert config.task_type == 'worker'
assert not config.is_chief
</pre> <h4 id="example_of_chief_node">Example of chief node:</h4> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">cluster = {'chief': ['host0:2222'],
           'ps': ['host1:2222', 'host2:2222'],
           'worker': ['host3:2222', 'host4:2222', 'host5:2222']}
os.environ['TF_CONFIG'] = json.dumps(
    {'cluster': cluster,
     'task': {'type': 'chief', 'index': 0}})
config = RunConfig()
assert config.master == 'host0:2222'
assert config.task_id == 0
assert config.num_ps_replicas == 2
assert config.num_worker_replicas == 4
assert config.cluster_spec == server_lib.ClusterSpec(cluster)
assert config.task_type == 'chief'
assert config.is_chief
</pre> <p>Example of evaluator node (evaluator is not part of training cluster):</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">cluster = {'chief': ['host0:2222'],
           'ps': ['host1:2222', 'host2:2222'],
           'worker': ['host3:2222', 'host4:2222', 'host5:2222']}
os.environ['TF_CONFIG'] = json.dumps(
    {'cluster': cluster,
     'task': {'type': 'evaluator', 'index': 0}})
config = RunConfig()
assert config.master == ''
assert config.evaluator_master == ''
assert config.task_id == 0
assert config.num_ps_replicas == 0
assert config.num_worker_replicas == 0
assert config.cluster_spec == {}
assert config.task_type == 'evaluator'
assert not config.is_chief
</pre> <p>N.B.: If <code translate="no" dir="ltr">save_checkpoints_steps</code> or <code translate="no" dir="ltr">save_checkpoints_secs</code> is set, <code translate="no" dir="ltr">keep_checkpoint_max</code> might need to be adjusted accordingly, especially in distributed training. For example, setting <code translate="no" dir="ltr">save_checkpoints_secs</code> as 60 without adjusting <code translate="no" dir="ltr">keep_checkpoint_max</code> (defaults to 5) leads to situation that checkpoint would be garbage collected after 5 minutes. In distributed training, the evaluation job starts asynchronously and might fail to load or find the checkpoint due to race condition.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">model_dir</code></b>: directory where model parameters, graph, etc are saved. If <code translate="no" dir="ltr">PathLike</code> object, the path will be resolved. If <code translate="no" dir="ltr">None</code>, will use a default value set by the Estimator.</li> <li>
<b><code translate="no" dir="ltr">tf_random_seed</code></b>: Random seed for TensorFlow initializers. Setting this value allows consistency between reruns.</li> <li>
<b><code translate="no" dir="ltr">save_summary_steps</code></b>: Save summaries every this many steps.</li> <li>
<b><code translate="no" dir="ltr">save_checkpoints_steps</code></b>: Save checkpoints every this many steps. Can not be specified with <code translate="no" dir="ltr">save_checkpoints_secs</code>.</li> <li>
<b><code translate="no" dir="ltr">save_checkpoints_secs</code></b>: Save checkpoints every this many seconds. Can not be specified with <code translate="no" dir="ltr">save_checkpoints_steps</code>. Defaults to 600 seconds if both <code translate="no" dir="ltr">save_checkpoints_steps</code> and <code translate="no" dir="ltr">save_checkpoints_secs</code> are not set in constructor. If both <code translate="no" dir="ltr">save_checkpoints_steps</code> and <code translate="no" dir="ltr">save_checkpoints_secs</code> are <code translate="no" dir="ltr">None</code>, then checkpoints are disabled.</li> <li>
<b><code translate="no" dir="ltr">session_config</code></b>: a ConfigProto used to set session parameters, or <code translate="no" dir="ltr">None</code>.</li> <li>
<b><code translate="no" dir="ltr">keep_checkpoint_max</code></b>: The maximum number of recent checkpoint files to keep. As new files are created, older files are deleted. If <code translate="no" dir="ltr">None</code> or 0, all checkpoint files are kept. Defaults to 5 (that is, the 5 most recent checkpoint files are kept.)</li> <li>
<b><code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code></b>: Number of hours between each checkpoint to be saved. The default value of 10,000 hours effectively disables the feature.</li> <li>
<b><code translate="no" dir="ltr">log_step_count_steps</code></b>: The frequency, in number of global steps, that the global step and the loss will be logged during training. Also controls the frequency that the global steps / s will be logged (and written to summary) during training.</li> <li>
<b><code translate="no" dir="ltr">train_distribute</code></b>: An optional instance of <a href="../distribute/strategy"><code translate="no" dir="ltr">tf.distribute.Strategy</code></a>. If specified, then Estimator will distribute the user's model during training, according to the policy specified by that strategy. Setting <code translate="no" dir="ltr">experimental_distribute.train_distribute</code> is preferred.</li> <li>
<b><code translate="no" dir="ltr">device_fn</code></b>: A callable invoked for every <code translate="no" dir="ltr">Operation</code> that takes the <code translate="no" dir="ltr">Operation</code> and returns the device string. If <code translate="no" dir="ltr">None</code>, defaults to the device function returned by <code translate="no" dir="ltr">tf.train.replica_device_setter</code> with round-robin strategy.</li> <li>
<b><code translate="no" dir="ltr">protocol</code></b>: An optional argument which specifies the protocol used when starting server. <code translate="no" dir="ltr">None</code> means default to grpc.</li> <li>
<b><code translate="no" dir="ltr">eval_distribute</code></b>: An optional instance of <a href="../distribute/strategy"><code translate="no" dir="ltr">tf.distribute.Strategy</code></a>. If specified, then Estimator will distribute the user's model during evaluation, according to the policy specified by that strategy. Setting <code translate="no" dir="ltr">experimental_distribute.eval_distribute</code> is preferred.</li> <li>
<b><code translate="no" dir="ltr">experimental_distribute</code></b>: An optional <code translate="no" dir="ltr">tf.contrib.distribute.DistributeConfig</code> object specifying DistributionStrategy-related configuration. The <code translate="no" dir="ltr">train_distribute</code> and <code translate="no" dir="ltr">eval_distribute</code> can be passed as parameters to <code translate="no" dir="ltr">RunConfig</code> or set in <code translate="no" dir="ltr">experimental_distribute</code> but not both.</li> <li>
<b><code translate="no" dir="ltr">experimental_max_worker_delay_secs</code></b>: An optional integer specifying the maximum time a worker should wait before starting. By default, workers are started at staggered times, with each worker being delayed by up to 60 seconds. This is intended to reduce the risk of divergence, which can occur when many workers simultaneously update the weights of a randomly initialized model. Users who warm-start their models and train them for short durations (a few minutes or less) should consider reducing this default to improve training times.</li> <li>
<b><code translate="no" dir="ltr">session_creation_timeout_secs</code></b>: Max time workers should wait for a session to become available (on initialization or when recovering a session) with MonitoredTrainingSession. Defaults to 7200 seconds, but users may want to set a lower value to detect problems with variable / session (re)-initialization more quickly.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If both <code translate="no" dir="ltr">save_checkpoints_steps</code> and <code translate="no" dir="ltr">save_checkpoints_secs</code> are set.</li> </ul> <h2 id="properties">Properties</h2> <h3 id="cluster_spec"><code translate="no" dir="ltr">cluster_spec</code></h3> <h3 id="device_fn"><code translate="no" dir="ltr">device_fn</code></h3> <p>Returns the device_fn.</p> <p>If device_fn is not <code translate="no" dir="ltr">None</code>, it overrides the default device function used in <code translate="no" dir="ltr">Estimator</code>. Otherwise the default one is used.</p> <h3 id="eval_distribute"><code translate="no" dir="ltr">eval_distribute</code></h3> <p>Optional <a href="../distribute/strategy"><code translate="no" dir="ltr">tf.distribute.Strategy</code></a> for evaluation.</p> <h3 id="evaluation_master"><code translate="no" dir="ltr">evaluation_master</code></h3> <h3 id="experimental_max_worker_delay_secs"><code translate="no" dir="ltr">experimental_max_worker_delay_secs</code></h3> <h3 id="global_id_in_cluster"><code translate="no" dir="ltr">global_id_in_cluster</code></h3> <p>The global id in the training cluster.</p> <p>All global ids in the training cluster are assigned from an increasing sequence of consecutive integers. The first id is 0.</p> <blockquote class="note">
<strong>Note:</strong><span> Task id (the property field <code translate="no" dir="ltr">task_id</code>) is tracking the index of the node among all nodes with the SAME task type. For example, given the cluster definition as follows:</span>
</blockquote>
<pre class="prettyprint" translate="no" dir="ltr" data-language="python">cluster = {'chief': ['host0:2222'],
           'ps': ['host1:2222', 'host2:2222'],
           'worker': ['host3:2222', 'host4:2222', 'host5:2222']}
</pre> <p>Nodes with task type <code translate="no" dir="ltr">worker</code> can have id 0, 1, 2. Nodes with task type <code translate="no" dir="ltr">ps</code> can have id, 0, 1. So, <code translate="no" dir="ltr">task_id</code> is not unique, but the pair (<code translate="no" dir="ltr">task_type</code>, <code translate="no" dir="ltr">task_id</code>) can uniquely determine a node in the cluster.</p> <p>Global id, i.e., this field, is tracking the index of the node among ALL nodes in the cluster. It is uniquely assigned. For example, for the cluster spec given above, the global ids are assigned as:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">task_type  | task_id  |  global_id
--------------------------------
chief      | 0        |  0
worker     | 0        |  1
worker     | 1        |  2
worker     | 2        |  3
ps         | 0        |  4
ps         | 1        |  5
</pre> <h4 id="returns">Returns:</h4> <p>An integer id.</p> <h3 id="is_chief"><code translate="no" dir="ltr">is_chief</code></h3> <h3 id="keep_checkpoint_every_n_hours"><code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code></h3> <h3 id="keep_checkpoint_max"><code translate="no" dir="ltr">keep_checkpoint_max</code></h3> <h3 id="log_step_count_steps"><code translate="no" dir="ltr">log_step_count_steps</code></h3> <h3 id="master"><code translate="no" dir="ltr">master</code></h3> <h3 id="model_dir"><code translate="no" dir="ltr">model_dir</code></h3> <h3 id="num_ps_replicas"><code translate="no" dir="ltr">num_ps_replicas</code></h3> <h3 id="num_worker_replicas"><code translate="no" dir="ltr">num_worker_replicas</code></h3> <h3 id="protocol"><code translate="no" dir="ltr">protocol</code></h3> <p>Returns the optional protocol value.</p> <h3 id="save_checkpoints_secs"><code translate="no" dir="ltr">save_checkpoints_secs</code></h3> <h3 id="save_checkpoints_steps"><code translate="no" dir="ltr">save_checkpoints_steps</code></h3> <h3 id="save_summary_steps"><code translate="no" dir="ltr">save_summary_steps</code></h3> <h3 id="service"><code translate="no" dir="ltr">service</code></h3> <p>Returns the platform defined (in TF_CONFIG) service dict.</p> <h3 id="session_config"><code translate="no" dir="ltr">session_config</code></h3> <h3 id="session_creation_timeout_secs"><code translate="no" dir="ltr">session_creation_timeout_secs</code></h3> <h3 id="task_id"><code translate="no" dir="ltr">task_id</code></h3> <h3 id="task_type"><code translate="no" dir="ltr">task_type</code></h3> <h3 id="tf_random_seed"><code translate="no" dir="ltr">tf_random_seed</code></h3> <h3 id="train_distribute"><code translate="no" dir="ltr">train_distribute</code></h3> <p>Optional <a href="../distribute/strategy"><code translate="no" dir="ltr">tf.distribute.Strategy</code></a> for training.</p> <h2 id="methods">Methods</h2> <h3 id="replace"><code translate="no" dir="ltr">replace</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/run_config.py">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">replace(**kwargs)
</pre> <p>Returns a new instance of <code translate="no" dir="ltr">RunConfig</code> replacing specified properties.</p> <p>Only the properties in the following list are allowed to be replaced:</p> <ul> <li>
<code translate="no" dir="ltr">model_dir</code>,</li> <li>
<code translate="no" dir="ltr">tf_random_seed</code>,</li> <li>
<code translate="no" dir="ltr">save_summary_steps</code>,</li> <li>
<code translate="no" dir="ltr">save_checkpoints_steps</code>,</li> <li>
<code translate="no" dir="ltr">save_checkpoints_secs</code>,</li> <li>
<code translate="no" dir="ltr">session_config</code>,</li> <li>
<code translate="no" dir="ltr">keep_checkpoint_max</code>,</li> <li>
<code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code>,</li> <li>
<code translate="no" dir="ltr">log_step_count_steps</code>,</li> <li>
<code translate="no" dir="ltr">train_distribute</code>,</li> <li>
<code translate="no" dir="ltr">device_fn</code>,</li> <li>
<code translate="no" dir="ltr">protocol</code>.</li> <li>
<code translate="no" dir="ltr">eval_distribute</code>,</li> <li>
<code translate="no" dir="ltr">experimental_distribute</code>,</li> <li>
<code translate="no" dir="ltr">experimental_max_worker_delay_secs</code>,</li> </ul> <p>In addition, either <code translate="no" dir="ltr">save_checkpoints_steps</code> or <code translate="no" dir="ltr">save_checkpoints_secs</code> can be set (should not be both).</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: keyword named properties with new values.</li> </ul> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If any property name in <code translate="no" dir="ltr">kwargs</code> does not exist or is not allowed to be replaced, or both <code translate="no" dir="ltr">save_checkpoints_steps</code> and <code translate="no" dir="ltr">save_checkpoints_secs</code> are set.</li> </ul> <h4 id="returns_2">Returns:</h4> <p>a new instance of <code translate="no" dir="ltr">RunConfig</code>.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="runconfig"><code translate="no" dir="ltr">tf.compat.v1.estimator.RunConfig</code></a></li> <li><a href="runconfig"><code translate="no" dir="ltr">tf.compat.v2.estimator.RunConfig</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig</a>
  </p>
</div>
