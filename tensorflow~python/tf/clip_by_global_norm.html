<h1 class="devsite-page-title">tf.clip_by_global_norm</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.clip_by_global_norm"> <meta itemprop="path" content="Stable"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/clip_by_global_norm">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/clip_ops.py#L237-L325">  View source on GitHub </a> </td>
</table>  <p>Clips values of multiple tensors by the ratio of the sum of their norms.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.clip_by_global_norm(
    t_list,
    clip_norm,
    use_norm=None,
    name=None
)
</pre>  <p>Given a tuple or list of tensors <code translate="no" dir="ltr">t_list</code>, and a clipping ratio <code translate="no" dir="ltr">clip_norm</code>, this operation returns a list of clipped tensors <code translate="no" dir="ltr">list_clipped</code> and the global norm (<code translate="no" dir="ltr">global_norm</code>) of all tensors in <code translate="no" dir="ltr">t_list</code>. Optionally, if you've already computed the global norm for <code translate="no" dir="ltr">t_list</code>, you can specify the global norm with <code translate="no" dir="ltr">use_norm</code>.</p> <p>To perform the clipping, the values <code translate="no" dir="ltr">t_list[i]</code> are set to:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">t_list[i] * clip_norm / max(global_norm, clip_norm)
</pre> <p>where:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
</pre> <p>If <code translate="no" dir="ltr">clip_norm &gt; global_norm</code> then the entries in <code translate="no" dir="ltr">t_list</code> remain as they are, otherwise they're all shrunk by the global ratio.</p> <p>If <code translate="no" dir="ltr">global_norm == infinity</code> then the entries in <code translate="no" dir="ltr">t_list</code> are all set to <code translate="no" dir="ltr">NaN</code> to signal that an error occurred.</p> <p>Any of the entries of <code translate="no" dir="ltr">t_list</code> that are of type <code translate="no" dir="ltr">None</code> are ignored.</p> <p>This is the correct way to perform gradient clipping (for example, see <a href="http://arxiv.org/abs/1211.5063">Pascanu et al., 2012</a> (<a href="http://arxiv.org/pdf/1211.5063.pdf">pdf</a>)).</p> <p>However, it is slower than <code translate="no" dir="ltr">clip_by_norm()</code> because all the parameters must be ready before the clipping operation can be performed.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">t_list</code></b>: A tuple or list of mixed <code translate="no" dir="ltr">Tensors</code>, <code translate="no" dir="ltr">IndexedSlices</code>, or None.</li> <li>
<b><code translate="no" dir="ltr">clip_norm</code></b>: A 0-D (scalar) <code translate="no" dir="ltr">Tensor</code> &gt; 0. The clipping ratio.</li> <li>
<b><code translate="no" dir="ltr">use_norm</code></b>: A 0-D (scalar) <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float</code> (optional). The global norm to use. If not provided, <code translate="no" dir="ltr">global_norm()</code> is used to compute the norm.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns_2">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">list_clipped</code></b>: A list of <code translate="no" dir="ltr">Tensors</code> of the same type as <code translate="no" dir="ltr">list_t</code>.</li> <li>
<b><code translate="no" dir="ltr">global_norm</code></b>: A 0-D (scalar) <code translate="no" dir="ltr">Tensor</code> representing the global norm.</li> </ul> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If <code translate="no" dir="ltr">t_list</code> is not a sequence.</li> </ul> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="clip_by_global_norm"><code translate="no" dir="ltr">tf.compat.v1.clip_by_global_norm</code></a></li> <li><a href="clip_by_global_norm"><code translate="no" dir="ltr">tf.compat.v2.clip_by_global_norm</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm</a>
  </p>
</div>
