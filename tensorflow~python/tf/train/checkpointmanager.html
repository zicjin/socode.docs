<h1 class="devsite-page-title">tf.train.CheckpointManager</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.train.CheckpointManager"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="checkpoints"> <meta itemprop="property" content="latest_checkpoint"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="save"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/CheckpointManager">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/checkpoint_management.py#L496-L737">  View source on GitHub </a> </td>
</table>  <h2 id="class_checkpointmanager_2">Class <code translate="no" dir="ltr">CheckpointManager</code>
</h2> <p>Deletes old checkpoints.</p> <h3 id="used_in_the_guide_2">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/checkpoint">Training checkpoints</a></li> </ul> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/generative/cyclegan">CycleGAN</a></li> <li><a href="https://www.tensorflow.org/tutorials/text/image_captioning">Image captioning with visual attention</a></li> <li><a href="https://www.tensorflow.org/tutorials/text/transformer">Transformer model for language understanding</a></li> </ul> <h4 id="example_usage_2">Example usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow as tf
checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
manager = tf.train.CheckpointManager(
    checkpoint, directory="/tmp/model", max_to_keep=5)
status = checkpoint.restore(manager.latest_checkpoint)
while True:
  # train
  manager.save()
</pre> <p><code translate="no" dir="ltr">CheckpointManager</code> preserves its own state across instantiations (see the <code translate="no" dir="ltr">__init__</code> documentation for details). Only one should be active in a particular directory at a time.</p> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/checkpoint_management.py#L517-L606">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    checkpoint,
    directory,
    max_to_keep,
    keep_checkpoint_every_n_hours=None,
    checkpoint_name='ckpt'
)
</pre> <p>Configure a <code translate="no" dir="ltr">CheckpointManager</code> for use in <code translate="no" dir="ltr">directory</code>.</p> <p>If a <code translate="no" dir="ltr">CheckpointManager</code> was previously used in <code translate="no" dir="ltr">directory</code>, its state will be restored. This includes the list of managed checkpoints and the timestamp bookkeeping necessary to support <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code>. The behavior of the new <code translate="no" dir="ltr">CheckpointManager</code> will be the same as the previous <code translate="no" dir="ltr">CheckpointManager</code>, including cleaning up existing checkpoints if appropriate.</p> <p>Checkpoints are only considered for deletion just after a new checkpoint has been added. At that point, <code translate="no" dir="ltr">max_to_keep</code> checkpoints will remain in an "active set". Once a checkpoint is preserved by <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code> it will not be deleted by this <code translate="no" dir="ltr">CheckpointManager</code> or any future <code translate="no" dir="ltr">CheckpointManager</code> instantiated in <code translate="no" dir="ltr">directory</code> (regardless of the new setting of <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code>). The <code translate="no" dir="ltr">max_to_keep</code> checkpoints in the active set may be deleted by this <code translate="no" dir="ltr">CheckpointManager</code> or a future <code translate="no" dir="ltr">CheckpointManager</code> instantiated in <code translate="no" dir="ltr">directory</code> (subject to its <code translate="no" dir="ltr">max_to_keep</code> and <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code> settings).</p> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">checkpoint</code></b>: The <a href="checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> instance to save and manage checkpoints for.</li> <li>
<b><code translate="no" dir="ltr">directory</code></b>: The path to a directory in which to write checkpoints. A special file named "checkpoint" is also written to this directory (in a human-readable text format) which contains the state of the <code translate="no" dir="ltr">CheckpointManager</code>.</li> <li>
<b><code translate="no" dir="ltr">max_to_keep</code></b>: An integer, the number of checkpoints to keep. Unless preserved by <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code>, checkpoints will be deleted from the active set, oldest first, until only <code translate="no" dir="ltr">max_to_keep</code> checkpoints remain. If <code translate="no" dir="ltr">None</code>, no checkpoints are deleted and everything stays in the active set. Note that <code translate="no" dir="ltr">max_to_keep=None</code> will keep all checkpoint paths in memory and in the checkpoint state protocol buffer on disk.</li> <li>
<b><code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code></b>: Upon removal from the active set, a checkpoint will be preserved if it has been at least <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code> since the last preserved checkpoint. The default setting of <code translate="no" dir="ltr">None</code> does not preserve any checkpoints in this way.</li> <li>
<b><code translate="no" dir="ltr">checkpoint_name</code></b>: Custom name for the checkpoint file.</li> </ul> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">max_to_keep</code> is not a positive integer.</li> </ul> <h2 id="properties_2">Properties</h2> <h3 id="checkpoints"><code translate="no" dir="ltr">checkpoints</code></h3> <p>A list of managed checkpoints.</p> <p>Note that checkpoints saved due to <code translate="no" dir="ltr">keep_checkpoint_every_n_hours</code> will not show up in this list (to avoid ever-growing filename lists).</p> <h4 id="returns_4">Returns:</h4> <p>A list of filenames, sorted from oldest to newest.</p> <h3 id="latest_checkpoint"><code translate="no" dir="ltr">latest_checkpoint</code></h3> <p>The prefix of the most recent checkpoint in <code translate="no" dir="ltr">directory</code>.</p> <p>Equivalent to <a href="latest_checkpoint"><code translate="no" dir="ltr">tf.train.latest_checkpoint(directory)</code></a> where <code translate="no" dir="ltr">directory</code> is the constructor argument to <code translate="no" dir="ltr">CheckpointManager</code>.</p> <p>Suitable for passing to <a href="checkpoint#restore"><code translate="no" dir="ltr">tf.train.Checkpoint.restore</code></a> to resume training.</p> <h4 id="returns_5">Returns:</h4> <p>The checkpoint prefix. If there are no checkpoints, returns <code translate="no" dir="ltr">None</code>.</p> <h2 id="methods_2">Methods</h2> <h3 id="save"><code translate="no" dir="ltr">save</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/checkpoint_management.py#L679-L737">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">save(checkpoint_number=None)
</pre> <p>Creates a new checkpoint and manages it.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">checkpoint_number</code></b>: An optional integer, or an integer-dtype <code translate="no" dir="ltr">Variable</code> or <code translate="no" dir="ltr">Tensor</code>, used to number the checkpoint. If <code translate="no" dir="ltr">None</code> (default), checkpoints are numbered using <code translate="no" dir="ltr">checkpoint.save_counter</code>. Even if <code translate="no" dir="ltr">checkpoint_number</code> is provided, <code translate="no" dir="ltr">save_counter</code> is still incremented. A user-provided <code translate="no" dir="ltr">checkpoint_number</code> is not incremented even if it is a <code translate="no" dir="ltr">Variable</code>.</li> </ul> <h4 id="returns_6">Returns:</h4> <p>The path to the new checkpoint. It is also recorded in the <code translate="no" dir="ltr">checkpoints</code> and <code translate="no" dir="ltr">latest_checkpoint</code> properties.</p> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="checkpointmanager"><code translate="no" dir="ltr">tf.compat.v1.train.CheckpointManager</code></a></li> <li><a href="checkpointmanager"><code translate="no" dir="ltr">tf.compat.v2.train.CheckpointManager</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager</a>
  </p>
</div>
