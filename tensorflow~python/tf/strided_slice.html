<h1 class="devsite-page-title">tf.strided_slice</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.strided_slice"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/strided_slice">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/array_ops.py#L955-L1092">  View source on GitHub </a> </td>
</table>  <p>Extracts a strided slice of a tensor (generalized python array indexing).</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.strided_slice(
    input_,
    begin,
    end,
    strides=None,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    var=None,
    name=None
)
</pre>  <p><strong>Instead of calling this op directly most users will want to use the NumPy-style slicing syntax (e.g. <code translate="no" dir="ltr">tensor[..., 3:4:-1, tf.newaxis, 3]</code>), which is supported via <a href="tensor#__getitem__"><code translate="no" dir="ltr">tf.Tensor.<strong>getitem</strong></code></a> and <a href="variable#__getitem__"><code translate="no" dir="ltr">tf.Variable.<strong>getitem</strong></code></a>.</strong> The interface of this op is a low-level encoding of the slicing syntax.</p> <p>Roughly speaking, this op extracts a slice of size <code translate="no" dir="ltr">(end-begin)/stride</code> from the given <code translate="no" dir="ltr">input_</code> tensor. Starting at the location specified by <code translate="no" dir="ltr">begin</code> the slice continues by adding <code translate="no" dir="ltr">stride</code> to the index until all dimensions are not less than <code translate="no" dir="ltr">end</code>. Note that a stride can be negative, which causes a reverse slice.</p> <p>Given a Python slice <code translate="no" dir="ltr">input[spec0, spec1, ..., specn]</code>, this function will be called as follows.</p> <p><code translate="no" dir="ltr">begin</code>, <code translate="no" dir="ltr">end</code>, and <code translate="no" dir="ltr">strides</code> will be vectors of length n. n in general is not equal to the rank of the <code translate="no" dir="ltr">input_</code> tensor.</p> <p>In each mask field (<code translate="no" dir="ltr">begin_mask</code>, <code translate="no" dir="ltr">end_mask</code>, <code translate="no" dir="ltr">ellipsis_mask</code>, <code translate="no" dir="ltr">new_axis_mask</code>, <code translate="no" dir="ltr">shrink_axis_mask</code>) the ith bit will correspond to the ith spec.</p> <p>If the ith bit of <code translate="no" dir="ltr">begin_mask</code> is set, <code translate="no" dir="ltr">begin[i]</code> is ignored and the fullest possible range in that dimension is used instead. <code translate="no" dir="ltr">end_mask</code> works analogously, except with the end range.</p> <p><code translate="no" dir="ltr">foo[5:,:,:3]</code> on a 7x8x9 tensor is equivalent to <code translate="no" dir="ltr">foo[5:7,0:8,0:3]</code>. <code translate="no" dir="ltr">foo[::-1]</code> reverses a tensor with shape 8.</p> <p>If the ith bit of <code translate="no" dir="ltr">ellipsis_mask</code> is set, as many unspecified dimensions as needed will be inserted between other dimensions. Only one non-zero bit is allowed in <code translate="no" dir="ltr">ellipsis_mask</code>.</p> <p>For example <code translate="no" dir="ltr">foo[3:5,...,4:5]</code> on a shape 10x3x3x10 tensor is equivalent to <code translate="no" dir="ltr">foo[3:5,:,:,4:5]</code> and <code translate="no" dir="ltr">foo[3:5,...]</code> is equivalent to <code translate="no" dir="ltr">foo[3:5,:,:,:]</code>.</p> <p>If the ith bit of <code translate="no" dir="ltr">new_axis_mask</code> is set, then <code translate="no" dir="ltr">begin</code>, <code translate="no" dir="ltr">end</code>, and <code translate="no" dir="ltr">stride</code> are ignored and a new length 1 dimension is added at this point in the output tensor.</p> <p>For example, <code translate="no" dir="ltr">foo[:4, tf.newaxis, :2]</code> would produce a shape <code translate="no" dir="ltr">(4, 1, 2)</code> tensor.</p> <p>If the ith bit of <code translate="no" dir="ltr">shrink_axis_mask</code> is set, it implies that the ith specification shrinks the dimensionality by 1, taking on the value at index <code translate="no" dir="ltr">begin[i]</code>. <code translate="no" dir="ltr">end[i]</code> and <code translate="no" dir="ltr">strides[i]</code> are ignored in this case. For example in Python one might do <code translate="no" dir="ltr">foo[:, 3, :]</code> which would result in <code translate="no" dir="ltr">shrink_axis_mask</code> equal to 2.</p> <p>NOTE: <code translate="no" dir="ltr">begin</code> and <code translate="no" dir="ltr">end</code> are zero-indexed. <code translate="no" dir="ltr">strides</code> entries must be non-zero.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">t = tf.constant([[[1, 1, 1], [2, 2, 2]],
                 [[3, 3, 3], [4, 4, 4]],
                 [[5, 5, 5], [6, 6, 6]]])
tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])  # [[[3, 3, 3]]]
tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])  # [[[3, 3, 3],
                                                      #   [4, 4, 4]]]
tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])  # [[[4, 4, 4],
                                                         #   [3, 3, 3]]]
</pre> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">input_</code></b>: A <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">begin</code></b>: An <code translate="no" dir="ltr">int32</code> or <code translate="no" dir="ltr">int64</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">end</code></b>: An <code translate="no" dir="ltr">int32</code> or <code translate="no" dir="ltr">int64</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">strides</code></b>: An <code translate="no" dir="ltr">int32</code> or <code translate="no" dir="ltr">int64</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">begin_mask</code></b>: An <code translate="no" dir="ltr">int32</code> mask.</li> <li>
<b><code translate="no" dir="ltr">end_mask</code></b>: An <code translate="no" dir="ltr">int32</code> mask.</li> <li>
<b><code translate="no" dir="ltr">ellipsis_mask</code></b>: An <code translate="no" dir="ltr">int32</code> mask.</li> <li>
<b><code translate="no" dir="ltr">new_axis_mask</code></b>: An <code translate="no" dir="ltr">int32</code> mask.</li> <li>
<b><code translate="no" dir="ltr">shrink_axis_mask</code></b>: An <code translate="no" dir="ltr">int32</code> mask.</li> <li>
<b><code translate="no" dir="ltr">var</code></b>: The variable corresponding to <code translate="no" dir="ltr">input_</code> or None</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code> the same type as <code translate="no" dir="ltr">input</code>.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="strided_slice"><code translate="no" dir="ltr">tf.compat.v1.strided_slice</code></a></li> <li><a href="strided_slice"><code translate="no" dir="ltr">tf.compat.v2.strided_slice</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/strided_slice" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/strided_slice</a>
  </p>
</div>
