<h1 class="devsite-page-title">Module: tf.keras.losses</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.losses"> <meta itemprop="path" content="Stable"> </div> <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/losses">  TensorFlow 1 version</a> </td> </table> <p>Built-in loss functions.</p> <p><strong>Aliases</strong>: <a href="losses"><code translate="no" dir="ltr">tf.losses</code></a></p> <h2 id="classes">Classes</h2> <p><a href="losses/binarycrossentropy"><code translate="no" dir="ltr">class BinaryCrossentropy</code></a>: Computes the cross-entropy loss between true labels and predicted labels.</p> <p><a href="losses/categoricalcrossentropy"><code translate="no" dir="ltr">class CategoricalCrossentropy</code></a>: Computes the crossentropy loss between the labels and predictions.</p> <p><a href="losses/categoricalhinge"><code translate="no" dir="ltr">class CategoricalHinge</code></a>: Computes the categorical hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/cosinesimilarity"><code translate="no" dir="ltr">class CosineSimilarity</code></a>: Computes the cosine similarity between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/hinge"><code translate="no" dir="ltr">class Hinge</code></a>: Computes the hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/huber"><code translate="no" dir="ltr">class Huber</code></a>: Computes the Huber loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/kldivergence"><code translate="no" dir="ltr">class KLDivergence</code></a>: Computes Kullback-Leibler divergence loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/logcosh"><code translate="no" dir="ltr">class LogCosh</code></a>: Computes the logarithm of the hyperbolic cosine of the prediction error.</p> <p><a href="losses/loss"><code translate="no" dir="ltr">class Loss</code></a>: Loss base class.</p> <p><a href="losses/meanabsoluteerror"><code translate="no" dir="ltr">class MeanAbsoluteError</code></a>: Computes the mean of absolute difference between labels and predictions.</p> <p><a href="losses/meanabsolutepercentageerror"><code translate="no" dir="ltr">class MeanAbsolutePercentageError</code></a>: Computes the mean absolute percentage error between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/meansquarederror"><code translate="no" dir="ltr">class MeanSquaredError</code></a>: Computes the mean of squares of errors between labels and predictions.</p> <p><a href="losses/meansquaredlogarithmicerror"><code translate="no" dir="ltr">class MeanSquaredLogarithmicError</code></a>: Computes the mean squared logarithmic error between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/poisson"><code translate="no" dir="ltr">class Poisson</code></a>: Computes the Poisson loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/reduction"><code translate="no" dir="ltr">class Reduction</code></a>: Types of loss reduction.</p> <p><a href="losses/sparsecategoricalcrossentropy"><code translate="no" dir="ltr">class SparseCategoricalCrossentropy</code></a>: Computes the crossentropy loss between the labels and predictions.</p> <p><a href="losses/squaredhinge"><code translate="no" dir="ltr">class SquaredHinge</code></a>: Computes the squared hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <h2 id="functions">Functions</h2> <p><a href="losses/kld"><code translate="no" dir="ltr">KLD(...)</code></a>: Computes Kullback-Leibler divergence loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/mae"><code translate="no" dir="ltr">MAE(...)</code></a></p> <p><a href="losses/mape"><code translate="no" dir="ltr">MAPE(...)</code></a></p> <p><a href="losses/mse"><code translate="no" dir="ltr">MSE(...)</code></a></p> <p><a href="losses/msle"><code translate="no" dir="ltr">MSLE(...)</code></a></p> <p><a href="losses/binary_crossentropy"><code translate="no" dir="ltr">binary_crossentropy(...)</code></a></p> <p><a href="losses/categorical_crossentropy"><code translate="no" dir="ltr">categorical_crossentropy(...)</code></a>: Computes the categorical crossentropy loss.</p> <p><a href="losses/categorical_hinge"><code translate="no" dir="ltr">categorical_hinge(...)</code></a>: Computes the categorical hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/cosine_similarity"><code translate="no" dir="ltr">cosine_similarity(...)</code></a>: Computes the cosine similarity between labels and predictions.</p> <p><a href="losses/deserialize"><code translate="no" dir="ltr">deserialize(...)</code></a></p> <p><a href="losses/get"><code translate="no" dir="ltr">get(...)</code></a></p> <p><a href="losses/hinge"><code translate="no" dir="ltr">hinge(...)</code></a>: Computes the hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/kld"><code translate="no" dir="ltr">kld(...)</code></a>: Computes Kullback-Leibler divergence loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/kld"><code translate="no" dir="ltr">kullback_leibler_divergence(...)</code></a>: Computes Kullback-Leibler divergence loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p> <p><a href="losses/logcosh"><code translate="no" dir="ltr">logcosh(...)</code></a>: Logarithm of the hyperbolic cosine of the prediction error.</p> <p><a href="losses/mae"><code translate="no" dir="ltr">mae(...)</code></a></p> <p><a href="losses/mape"><code translate="no" dir="ltr">mape(...)</code></a></p> <p><a href="losses/mae"><code translate="no" dir="ltr">mean_absolute_error(...)</code></a></p> <p><a href="losses/mape"><code translate="no" dir="ltr">mean_absolute_percentage_error(...)</code></a></p> <p><a href="losses/mse"><code translate="no" dir="ltr">mean_squared_error(...)</code></a></p> <p><a href="losses/msle"><code translate="no" dir="ltr">mean_squared_logarithmic_error(...)</code></a></p> <p><a href="losses/mse"><code translate="no" dir="ltr">mse(...)</code></a></p> <p><a href="losses/msle"><code translate="no" dir="ltr">msle(...)</code></a></p> <p><a href="losses/poisson"><code translate="no" dir="ltr">poisson(...)</code></a>: Computes the Poisson loss between y_true and y_pred.</p> <p><a href="losses/serialize"><code translate="no" dir="ltr">serialize(...)</code></a></p> <p><a href="losses/sparse_categorical_crossentropy"><code translate="no" dir="ltr">sparse_categorical_crossentropy(...)</code></a></p> <p><a href="losses/squared_hinge"><code translate="no" dir="ltr">squared_hinge(...)</code></a>: Computes the squared hinge loss between <code translate="no" dir="ltr">y_true</code> and <code translate="no" dir="ltr">y_pred</code>.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/losses</a>
  </p>
</div>
