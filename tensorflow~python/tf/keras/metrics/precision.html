<h1 class="devsite-page-title">tf.keras.metrics.Precision</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.metrics.Precision"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="__new__"> <meta itemprop="property" content="reset_states"> <meta itemprop="property" content="result"> <meta itemprop="property" content="update_state"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/metrics/Precision">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L1112-L1235">  View source on GitHub </a> </td>
</table>  <h2 id="class_precision_2">Class <code translate="no" dir="ltr">Precision</code>
</h2> <p>Computes the precision of the predictions with respect to the labels.</p> <p>Inherits From: <a href="metric"><code translate="no" dir="ltr">Metric</code></a></p> <p><strong>Aliases</strong>: <a href="precision"><code translate="no" dir="ltr">tf.metrics.Precision</code></a></p> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/structured_data/imbalanced_data">Classification on imbalanced data</a></li> </ul> <p>For example, if <code translate="no" dir="ltr">y_true</code> is [0, 1, 1, 1] and <code translate="no" dir="ltr">y_pred</code> is [1, 0, 1, 1] then the precision value is 2/(2+1) ie. 0.66. If the weights were specified as [0, 0, 1, 0] then the precision value would be 1.</p> <p>The metric creates two local variables, <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code> that are used to compute the precision. This value is ultimately returned as <code translate="no" dir="ltr">precision</code>, an idempotent operation that simply divides <code translate="no" dir="ltr">true_positives</code> by the sum of <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code>.</p> <p>If <code translate="no" dir="ltr">sample_weight</code> is <code translate="no" dir="ltr">None</code>, weights default to 1. Use <code translate="no" dir="ltr">sample_weight</code> of 0 to mask values.</p> <p>If <code translate="no" dir="ltr">top_k</code> is set, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</p> <p>If <code translate="no" dir="ltr">class_id</code> is specified, we calculate precision by considering only the entries in the batch for which <code translate="no" dir="ltr">class_id</code> is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which <code translate="no" dir="ltr">class_id</code> is indeed a correct label.</p> <h4 id="usage_2">Usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">m = tf.keras.metrics.Precision()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1])
print('Final result: ', m.result().numpy())  # Final result: 0.66
</pre> <p>Usage with tf.keras API:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">model = tf.keras.Model(inputs, outputs)
model.compile('sgd', loss='mse', metrics=[tf.keras.metrics.Precision()])
</pre> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L1152-L1190">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    thresholds=None,
    top_k=None,
    class_id=None,
    name=None,
    dtype=None
)
</pre> <p>Creates a <code translate="no" dir="ltr">Precision</code> instance.</p> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">thresholds</code></b>: (Optional) A float value or a python list/tuple of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is <code translate="no" dir="ltr">true</code>, below is <code translate="no" dir="ltr">false</code>). One metric value is generated for each threshold value. If neither thresholds nor top_k are set, the default is to calculate precision with <code translate="no" dir="ltr">thresholds=0.5</code>.</li> <li>
<b><code translate="no" dir="ltr">top_k</code></b>: (Optional) Unset by default. An int value specifying the top-k predictions to consider when calculating precision.</li> <li>
<b><code translate="no" dir="ltr">class_id</code></b>: (Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval <code translate="no" dir="ltr">[0, num_classes)</code>, where <code translate="no" dir="ltr">num_classes</code> is the last dimension of predictions.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: (Optional) string name of the metric instance.</li> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: (Optional) data type of the metric result.</li> </ul> <h2 id="__new__"><code translate="no" dir="ltr">__new__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L147-L163">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__new__(
    cls,
    *args,
    **kwargs
)
</pre> <p>Create and return a new object. See help(type) for accurate signature.</p> <h2 id="methods_2">Methods</h2> <h3 id="reset_states"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L1223-L1226">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">reset_states()
</pre> <p>Resets all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> <h3 id="result"><code translate="no" dir="ltr">result</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L1218-L1221">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">result()
</pre> <p>Computes and returns the metric value tensor.</p> <p>Result computation is an idempotent operation that simply calculates the metric value using the state variables.</p> <h3 id="update_state"><code translate="no" dir="ltr">update_state</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/metrics.py#L1192-L1216">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">update_state(
    y_true,
    y_pred,
    sample_weight=None
)
</pre> <p>Accumulates true positive and false positive statistics.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">y_true</code></b>: The ground truth values, with the same dimensions as <code translate="no" dir="ltr">y_pred</code>. Will be cast to <code translate="no" dir="ltr">bool</code>.</li> <li>
<b><code translate="no" dir="ltr">y_pred</code></b>: The predicted values. Each element must be in the range <code translate="no" dir="ltr">[0, 1]</code>.</li> <li>
<b><code translate="no" dir="ltr">sample_weight</code></b>: Optional weighting of each example. Defaults to 1. Can be a <code translate="no" dir="ltr">Tensor</code> whose rank is either 0, or the same rank as <code translate="no" dir="ltr">y_true</code>, and must be broadcastable to <code translate="no" dir="ltr">y_true</code>.</li> </ul> <h4 id="returns_2">Returns:</h4> <p>Update op.</p> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="precision"><code translate="no" dir="ltr">tf.compat.v1.keras.metrics.Precision</code></a></li> <li><a href="precision"><code translate="no" dir="ltr">tf.compat.v2.keras.metrics.Precision</code></a></li> <li><a href="precision"><code translate="no" dir="ltr">tf.compat.v2.metrics.Precision</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision</a>
  </p>
</div>
