<h1 class="devsite-page-title">tf.keras.Sequential</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.Sequential"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="layers"> <meta itemprop="property" content="metrics_names"> <meta itemprop="property" content="run_eagerly"> <meta itemprop="property" content="sample_weights"> <meta itemprop="property" content="state_updates"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="add"> <meta itemprop="property" content="compile"> <meta itemprop="property" content="evaluate"> <meta itemprop="property" content="evaluate_generator"> <meta itemprop="property" content="fit"> <meta itemprop="property" content="fit_generator"> <meta itemprop="property" content="get_layer"> <meta itemprop="property" content="load_weights"> <meta itemprop="property" content="pop"> <meta itemprop="property" content="predict"> <meta itemprop="property" content="predict_classes"> <meta itemprop="property" content="predict_generator"> <meta itemprop="property" content="predict_on_batch"> <meta itemprop="property" content="predict_proba"> <meta itemprop="property" content="reset_metrics"> <meta itemprop="property" content="reset_states"> <meta itemprop="property" content="save"> <meta itemprop="property" content="save_weights"> <meta itemprop="property" content="summary"> <meta itemprop="property" content="test_on_batch"> <meta itemprop="property" content="to_json"> <meta itemprop="property" content="to_yaml"> <meta itemprop="property" content="train_on_batch"> </div>   <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Sequential">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L43-L391">  View source on GitHub </a> </td>
</table>  <h2 id="class_sequential_2">Class <code translate="no" dir="ltr">Sequential</code>
</h2> <p>Linear stack of layers.</p> <p>Inherits From: <a href="model"><code translate="no" dir="ltr">Model</code></a></p> <p><strong>Aliases</strong>: <a href="sequential"><code translate="no" dir="ltr">tf.keras.models.Sequential</code></a></p> <h3 id="used_in_the_guide_2">Used in the guide:</h3> <ul> <li><a href="https://www.tensorflow.org/guide/keras/overview">Keras overview</a></li> <li><a href="https://www.tensorflow.org/guide/migrate">Migrate your TensorFlow 1 code to TensorFlow 2</a></li> <li><a href="https://www.tensorflow.org/guide/keras/rnn">Recurrent Neural Networks (RNN) with Keras</a></li> <li><a href="https://www.tensorflow.org/guide/distributed_training">Distributed training with TensorFlow</a></li> <li><a href="https://www.tensorflow.org/guide/eager">Eager execution</a></li> </ul> <h3 id="used_in_the_tutorials_2">Used in the tutorials:</h3> <ul> <li><a href="https://www.tensorflow.org/tutorials/keras/overfit_and_underfit">Overfit and underfit</a></li> <li><a href="https://www.tensorflow.org/tutorials/structured_data/time_series">Time series forecasting</a></li> <li><a href="https://www.tensorflow.org/tutorials/generative/cvae">Convolutional Variational Autoencoder</a></li> <li><a href="https://www.tensorflow.org/tutorials/generative/dcgan">Deep Convolutional Generative Adversarial Network</a></li> <li><a href="https://www.tensorflow.org/tutorials/generative/pix2pix">Pix2Pix</a></li> </ul> <h4 id="arguments_19">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">layers</code></b>: list of layers to add to the model.</li> </ul> <h4 id="example_3">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Optionally, the first layer can receive an `input_shape` argument:
model = Sequential()
model.add(Dense(32, input_shape=(500,)))
# Afterwards, we do automatic shape inference:
model.add(Dense(32))

# This is identical to the following:
model = Sequential()
model.add(Dense(32, input_dim=500))

# And to the following:
model = Sequential()
model.add(Dense(32, batch_input_shape=(None, 500)))

# Note that you can also omit the `input_shape` argument:
# In that case the model gets built the first time you call `fit` (or other
# training and evaluation methods).
model = Sequential()
model.add(Dense(32))
model.add(Dense(32))
model.compile(optimizer=optimizer, loss=loss)
# This builds the model for the first time:
model.fit(x, y, batch_size=32, epochs=10)

# Note that when using this delayed-build pattern (no input shape specified),
# the model doesn't have any weights until the first call
# to a training/evaluation method (since it isn't yet built):
model = Sequential()
model.add(Dense(32))
model.add(Dense(32))
model.weights  # returns []

# Whereas if you specify the input shape, the model gets built continuously
# as you are adding layers:
model = Sequential()
model.add(Dense(32, input_shape=(500,)))
model.add(Dense(32))
model.weights  # returns list of length 4

# When using the delayed-build pattern (no input shape specified), you can
# choose to manually build your model by calling `build(batch_input_shape)`:
model = Sequential()
model.add(Dense(32))
model.add(Dense(32))
model.build((None, 500))
model.weights  # returns list of length 4
</pre> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L101-L116">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    layers=None,
    name=None
)
</pre> <h2 id="properties_2">Properties</h2> <h3 id="layers"><code translate="no" dir="ltr">layers</code></h3> <h3 id="metrics_names"><code translate="no" dir="ltr">metrics_names</code></h3> <p>Returns the model's display labels for all outputs.</p> <h3 id="run_eagerly"><code translate="no" dir="ltr">run_eagerly</code></h3> <p>Settable attribute indicating whether the model should run eagerly.</p> <p>Running eagerly means that your model will be run step by step, like Python code. Your model might run slower, but it should become easier for you to debug it by stepping into individual layer calls.</p> <p>By default, we will attempt to compile your model to a static graph to deliver the best execution performance.</p> <h4 id="returns_15">Returns:</h4> <p>Boolean, whether the model should run eagerly.</p> <h3 id="sample_weights"><code translate="no" dir="ltr">sample_weights</code></h3> <h3 id="state_updates"><code translate="no" dir="ltr">state_updates</code></h3> <p>Returns the <code translate="no" dir="ltr">updates</code> from all layers that are stateful.</p> <p>This is useful for separating training updates and state updates, e.g. when we need to update a layer's internal state during prediction.</p> <h4 id="returns_16">Returns:</h4> <p>A list of update ops.</p> <h2 id="methods_2">Methods</h2> <h3 id="add"><code translate="no" dir="ltr">add</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L135-L226">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">add(layer)
</pre> <p>Adds a layer instance on top of the layer stack.</p> <h4 id="arguments_20">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">layer</code></b>: layer instance.</li> </ul> <h4 id="raises_15">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: If <code translate="no" dir="ltr">layer</code> is not a layer instance.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case the <code translate="no" dir="ltr">layer</code> argument does not know its input shape.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case the <code translate="no" dir="ltr">layer</code> argument has multiple output tensors, or is already connected somewhere else (forbidden in <code translate="no" dir="ltr">Sequential</code> models).</li> </ul> <h3 id="compile"><code translate="no" dir="ltr">compile</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L236-L471">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">compile(
    optimizer='rmsprop',
    loss=None,
    metrics=None,
    loss_weights=None,
    sample_weight_mode=None,
    weighted_metrics=None,
    target_tensors=None,
    distribute=None,
    **kwargs
)
</pre> <p>Configures the model for training.</p> <h4 id="arguments_21">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">optimizer</code></b>: String (name of optimizer) or optimizer instance. See <a href="optimizers"><code translate="no" dir="ltr">tf.keras.optimizers</code></a>.</li> <li>
<b><code translate="no" dir="ltr">loss</code></b>: String (name of objective function), objective function or <a href="losses/loss"><code translate="no" dir="ltr">tf.keras.losses.Loss</code></a> instance. See <a href="losses"><code translate="no" dir="ltr">tf.keras.losses</code></a>. An objective function is any callable with the signature <code translate="no" dir="ltr">scalar_loss = fn(y_true, y_pred)</code>. If the model has multiple outputs, you can use a different loss on each output by passing a dictionary or a list of losses. The loss value that will be minimized by the model will then be the sum of all individual losses.</li> <li>
<b><code translate="no" dir="ltr">metrics</code></b>: List of metrics to be evaluated by the model during training and testing. Typically you will use <code translate="no" dir="ltr">metrics=['accuracy']</code>. To specify different metrics for different outputs of a multi-output model, you could also pass a dictionary, such as <code translate="no" dir="ltr">metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>. You can also pass a list (len = len(outputs)) of lists of metrics such as <code translate="no" dir="ltr">metrics=[['accuracy'], ['accuracy', 'mse']]</code> or <code translate="no" dir="ltr">metrics=['accuracy', ['accuracy', 'mse']]</code>.</li> <li>
<b><code translate="no" dir="ltr">loss_weights</code></b>: Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs. The loss value that will be minimized by the model will then be the <em>weighted sum</em> of all individual losses, weighted by the <code translate="no" dir="ltr">loss_weights</code> coefficients. If a list, it is expected to have a 1:1 mapping to the model's outputs. If a tensor, it is expected to map output names (strings) to scalar coefficients.</li> <li>
<b><code translate="no" dir="ltr">sample_weight_mode</code></b>: If you need to do timestep-wise sample weighting (2D weights), set this to <code translate="no" dir="ltr">"temporal"</code>. <code translate="no" dir="ltr">None</code> defaults to sample-wise weights (1D). If the model has multiple outputs, you can use a different <code translate="no" dir="ltr">sample_weight_mode</code> on each output by passing a dictionary or a list of modes.</li> <li>
<b><code translate="no" dir="ltr">weighted_metrics</code></b>: List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.</li> <li>
<b><code translate="no" dir="ltr">target_tensors</code></b>: By default, Keras will create placeholders for the model's target, which will be fed with the target data during training. If instead you would like to use your own target tensors (in turn, Keras will not expect external Numpy data for these targets at training time), you can specify them via the <code translate="no" dir="ltr">target_tensors</code> argument. It can be a single tensor (for a single-output model), a list of tensors, or a dict mapping output names to target tensors.</li> <li>
<b><code translate="no" dir="ltr">distribute</code></b>: NOT SUPPORTED IN TF 2.0, please create and compile the model under distribution strategy scope instead of passing it to compile.</li> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: Any additional arguments.</li> </ul> <h4 id="raises_16">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of invalid arguments for <code translate="no" dir="ltr">optimizer</code>, <code translate="no" dir="ltr">loss</code>, <code translate="no" dir="ltr">metrics</code> or <code translate="no" dir="ltr">sample_weight_mode</code>.</li> </ul> <h3 id="evaluate"><code translate="no" dir="ltr">evaluate</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L821-L930">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">evaluate(
    x=None,
    y=None,
    batch_size=None,
    verbose=1,
    sample_weight=None,
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)
</pre> <p>Returns the loss value &amp; metrics values for the model in test mode.</p> <p>Computation is done in batches.</p> <h4 id="arguments_22">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance. A more detailed description of unpacking behavior for iterator types (Dataset, generator, Sequence) is given in the <code translate="no" dir="ltr">Unpacking behavior for iterator-like inputs</code> section of <code translate="no" dir="ltr">Model.fit</code>.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator/dataset).</li> <li>
<b><code translate="no" dir="ltr">batch_size</code></b>: Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> if your data is in the form of symbolic tensors, dataset, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches).</li> <li>
<b><code translate="no" dir="ltr">verbose</code></b>: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</li> <li>
<b><code translate="no" dir="ltr">sample_weight</code></b>: Optional Numpy array of weights for the test samples, used for weighting the loss function. You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape <code translate="no" dir="ltr">(samples, sequence_length)</code>, to apply a different weight to every timestep of every sample. In this case you should make sure to specify <code translate="no" dir="ltr">sample_weight_mode="temporal"</code> in <code translate="no" dir="ltr">compile()</code>. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, instead pass sample weights as the third element of <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">steps</code></b>: Integer or <code translate="no" dir="ltr">None</code>. Total number of steps (batches of samples) before declaring the evaluation round finished. Ignored with the default value of <code translate="no" dir="ltr">None</code>. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset and <code translate="no" dir="ltr">steps</code> is None, 'evaluate' will run until the dataset is exhausted. This argument is not supported with array inputs.</li> <li>
<b><code translate="no" dir="ltr">callbacks</code></b>: List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during evaluation. See <a href="callbacks">callbacks</a>.</li> <li>
<b><code translate="no" dir="ltr">max_queue_size</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10.</li> <li>
<b><code translate="no" dir="ltr">workers</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread.</li> <li>
<b><code translate="no" dir="ltr">use_multiprocessing</code></b>: Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.</li> </ul> <p>See the discussion of <code translate="no" dir="ltr">Unpacking behavior for iterator-like inputs</code> for <a href="model#fit"><code translate="no" dir="ltr">Model.fit</code></a>.</p> <h4 id="returns_17">Returns:</h4> <p>Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs.</p> <h4 id="raises_17">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: in case of invalid arguments.</li> </ul> <h3 id="evaluate_generator"><code translate="no" dir="ltr">evaluate_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1308-L1334">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">evaluate_generator(
    generator,
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False,
    verbose=0
)
</pre> <p>Evaluates the model on a data generator. (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use Model.evaluate, which supports generators.</span></aside> <h4 id="deprecated_4">DEPRECATED:</h4> <p><a href="model#evaluate"><code translate="no" dir="ltr">Model.evaluate</code></a> now supports generators, so there is no longer any need to use this endpoint.</p> <h3 id="fit"><code translate="no" dir="ltr">fit</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L596-L819">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">fit(
    x=None,
    y=None,
    batch_size=None,
    epochs=1,
    verbose=1,
    callbacks=None,
    validation_split=0.0,
    validation_data=None,
    shuffle=True,
    class_weight=None,
    sample_weight=None,
    initial_epoch=0,
    steps_per_epoch=None,
    validation_steps=None,
    validation_freq=1,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False,
    **kwargs
)
</pre> <p>Trains the model for a fixed number of epochs (iterations on a dataset).</p> <h4 id="arguments_23">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. Should return a tuple of either <code translate="no" dir="ltr">(inputs, targets)</code> or <code translate="no" dir="ltr">(inputs, targets, sample_weights)</code>.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> returning <code translate="no" dir="ltr">(inputs, targets)</code> or <code translate="no" dir="ltr">(inputs, targets, sample weights)</code>. A more detailed description of unpacking behavior for iterator types (Dataset, generator, Sequence) is given below.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, generator, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from <code translate="no" dir="ltr">x</code>).</li> <li>
<b><code translate="no" dir="ltr">batch_size</code></b>: Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> if your data is in the form of symbolic tensors, datasets, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches).</li> <li>
<b><code translate="no" dir="ltr">epochs</code></b>: Integer. Number of epochs to train the model. An epoch is an iteration over the entire <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> data provided. Note that in conjunction with <code translate="no" dir="ltr">initial_epoch</code>, <code translate="no" dir="ltr">epochs</code> is to be understood as "final epoch". The model is not trained for a number of iterations given by <code translate="no" dir="ltr">epochs</code>, but merely until the epoch of index <code translate="no" dir="ltr">epochs</code> is reached.</li> <li>
<b><code translate="no" dir="ltr">verbose</code></b>: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Note that the progress bar is not particularly useful when logged to a file, so verbose=2 is recommended when not running interactively (eg, in a production environment).</li> <li>
<b><code translate="no" dir="ltr">callbacks</code></b>: List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during training. See <a href="callbacks"><code translate="no" dir="ltr">tf.keras.callbacks</code></a>.</li> <li>
<b><code translate="no" dir="ltr">validation_split</code></b>: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code> data provided, before shuffling. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance.</li> <li>
<b><code translate="no" dir="ltr">validation_data</code></b>: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. <code translate="no" dir="ltr">validation_data</code> will override <code translate="no" dir="ltr">validation_split</code>. <code translate="no" dir="ltr">validation_data</code> could be: <ul> <li>tuple <code translate="no" dir="ltr">(x_val, y_val)</code> of Numpy arrays or tensors</li> <li>tuple <code translate="no" dir="ltr">(x_val, y_val, val_sample_weights)</code> of Numpy arrays</li> <li>dataset For the first two cases, <code translate="no" dir="ltr">batch_size</code> must be provided. For the last case, <code translate="no" dir="ltr">validation_steps</code> could be provided.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">shuffle</code></b>: Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when <code translate="no" dir="ltr">steps_per_epoch</code> is not <code translate="no" dir="ltr">None</code>.</li> <li>
<b><code translate="no" dir="ltr">class_weight</code></b>: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to "pay more attention" to samples from an under-represented class.</li> <li>
<b><code translate="no" dir="ltr">sample_weight</code></b>: Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape <code translate="no" dir="ltr">(samples, sequence_length)</code>, to apply a different weight to every timestep of every sample. In this case you should make sure to specify <code translate="no" dir="ltr">sample_weight_mode="temporal"</code> in <code translate="no" dir="ltr">compile()</code>. This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset, generator, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance, instead provide the sample_weights as the third element of <code translate="no" dir="ltr">x</code>.</li> <li>
<b><code translate="no" dir="ltr">initial_epoch</code></b>: Integer. Epoch at which to start training (useful for resuming a previous training run).</li> <li>
<b><code translate="no" dir="ltr">steps_per_epoch</code></b>: Integer or <code translate="no" dir="ltr">None</code>. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default <code translate="no" dir="ltr">None</code> is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted. This argument is not supported with array inputs.</li> <li>
<b><code translate="no" dir="ltr">validation_steps</code></b>: Only relevant if <code translate="no" dir="ltr">validation_data</code> is provided and is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. If 'validation_steps' is None, validation will run until the <code translate="no" dir="ltr">validation_data</code> dataset is exhausted. In the case of a infinite dataset, it will run into a infinite loop. If 'validation_steps' is specified and only part of the dataset will be consumed, the evaluation will start from the beginning of the dataset at each epoch. This ensures that the same validation samples are used every time.</li> <li>
<b><code translate="no" dir="ltr">validation_freq</code></b>: Only relevant if validation data is provided. Integer or <code translate="no" dir="ltr">collections_abc.Container</code> instance (e.g. list, tuple, etc.). If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. <code translate="no" dir="ltr">validation_freq=2</code> runs validation every 2 epochs. If a Container, specifies the epochs on which to run validation, e.g. <code translate="no" dir="ltr">validation_freq=[1, 2, 10]</code> runs validation at the end of the 1st, 2nd, and 10th epochs.</li> <li>
<b><code translate="no" dir="ltr">max_queue_size</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10.</li> <li>
<b><code translate="no" dir="ltr">workers</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread.</li> <li>
<b><code translate="no" dir="ltr">use_multiprocessing</code></b>: Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.</li> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: Used for backwards compatibility.</li> </ul> <p>Unpacking behavior for iterator-like inputs: A common pattern is to pass a tf.data.Dataset, generator, or tf.keras.utils.Sequence to the <code translate="no" dir="ltr">x</code> argument of fit, which will in fact yield not only features (x) but optionally targets (y) and sample weights. Keras requires that the output of such iterator-likes be unambiguous. The iterator should return a tuple of length 1, 2, or 3, where the optional second and third elements will be used for y and sample_weight respectively. Any other type provided will be wrapped in a length one tuple, effectively treating everything as 'x'. When yielding dicts, they should still adhere to the top-level tuple structure. e.g. <code translate="no" dir="ltr">({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate features, targets, and weights from the keys of a single dict. A notable unsupported data type is the namedtuple. The reason is that it behaves like both an ordered datatype (tuple) and a mapping datatype (dict). So given a namedtuple of the form: <code translate="no" dir="ltr">namedtuple("example_tuple", ["y", "x"])</code> it is ambiguous whether to reverse the order of the elements when interpreting the value. Even worse is a tuple of the form: <code translate="no" dir="ltr">namedtuple("other_tuple", ["x", "y", "z"])</code> where it is unclear if the tuple was intended to be unpacked into x, y, and sample_weight or passed through as a single element to <code translate="no" dir="ltr">x</code>. As a result the data processing code will simply raise a ValueError if it encounters a namedtuple. (Along with instructions to remedy the issue.)</p> <h4 id="returns_18">Returns:</h4> <p>A <code translate="no" dir="ltr">History</code> object. Its <code translate="no" dir="ltr">History.history</code> attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).</p> <h4 id="raises_18">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If the model was never compiled.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of mismatch between the provided input data and what the model expects.</li> </ul> <h3 id="fit_generator"><code translate="no" dir="ltr">fit_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1268-L1306">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">fit_generator(
    generator,
    steps_per_epoch=None,
    epochs=1,
    verbose=1,
    callbacks=None,
    validation_data=None,
    validation_steps=None,
    validation_freq=1,
    class_weight=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False,
    shuffle=True,
    initial_epoch=0
)
</pre> <p>Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use Model.fit, which supports generators.</span></aside> <h4 id="deprecated_5">DEPRECATED:</h4> <p><a href="model#fit"><code translate="no" dir="ltr">Model.fit</code></a> now supports generators, so there is no longer any need to use this endpoint.</p> <h3 id="get_layer"><code translate="no" dir="ltr">get_layer</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L517-L548">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">get_layer(
    name=None,
    index=None
)
</pre> <p>Retrieves a layer based on either its name (unique) or index.</p> <p>If <code translate="no" dir="ltr">name</code> and <code translate="no" dir="ltr">index</code> are both provided, <code translate="no" dir="ltr">index</code> will take precedence. Indices are based on order of horizontal graph traversal (bottom-up).</p> <h4 id="arguments_24">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: String, name of layer.</li> <li>
<b><code translate="no" dir="ltr">index</code></b>: Integer, index of layer.</li> </ul> <h4 id="returns_19">Returns:</h4> <p>A layer instance.</p> <h4 id="raises_19">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of invalid layer name or index.</li> </ul> <h3 id="load_weights"><code translate="no" dir="ltr">load_weights</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L183-L234">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">load_weights(
    filepath,
    by_name=False,
    skip_mismatch=False
)
</pre> <p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p> <p>If <code translate="no" dir="ltr">by_name</code> is False weights are loaded based on the network's topology. This means the architecture should be the same as when the weights were saved. Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.</p> <p>If <code translate="no" dir="ltr">by_name</code> is True, weights are loaded into layers only if they share the same name. This is useful for fine-tuning or transfer-learning models where some of the layers have changed.</p> <p>Only topological loading (<code translate="no" dir="ltr">by_name=False</code>) is supported when loading weights from the TensorFlow format. Note that topological loading differs slightly between TensorFlow and HDF5 formats for user-defined classes inheriting from <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a>: HDF5 loads based on a flattened list of weights, while the TensorFlow format loads based on the object-local names of attributes to which layers are assigned in the <code translate="no" dir="ltr">Model</code>'s constructor.</p> <h4 id="arguments_25">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">filepath</code></b>: String, path to the weights file to load. For weight files in TensorFlow format, this is the file prefix (the same as was passed to <code translate="no" dir="ltr">save_weights</code>).</li> <li>
<b><code translate="no" dir="ltr">by_name</code></b>: Boolean, whether to load weights by name or by topological order. Only topological loading is supported for weight files in TensorFlow format.</li> <li>
<b><code translate="no" dir="ltr">skip_mismatch</code></b>: Boolean, whether to skip loading of layers where there is a mismatch in the number of weights, or a mismatch in the shape of the weight (only valid when <code translate="no" dir="ltr">by_name=True</code>).</li> </ul> <h4 id="returns_20">Returns:</h4> <p>When loading a weight file in TensorFlow format, returns the same status object as <a href="../train/checkpoint#restore"><code translate="no" dir="ltr">tf.train.Checkpoint.restore</code></a>. When graph building, restore ops are run automatically as soon as the network is built (on first call for user-defined classes inheriting from <code translate="no" dir="ltr">Model</code>, immediately if it is already built).</p> <p>When loading weights in HDF5 format, returns <code translate="no" dir="ltr">None</code>.</p> <h4 id="raises_20">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ImportError</code></b>: If h5py is not available and the weight file is in HDF5 format.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If <code translate="no" dir="ltr">skip_mismatch</code> is set to <code translate="no" dir="ltr">True</code> when <code translate="no" dir="ltr">by_name</code> is <code translate="no" dir="ltr">False</code>.</li> </ul> <h3 id="pop"><code translate="no" dir="ltr">pop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L228-L249">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">pop()
</pre> <p>Removes the last layer in the model.</p> <h4 id="raises_21">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if there are no layers in the model.</li> </ul> <h3 id="predict"><code translate="no" dir="ltr">predict</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L932-L1013">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predict(
    x,
    batch_size=None,
    verbose=0,
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False
)
</pre> <p>Generates output predictions for the input samples.</p> <p>Computation is done in batches.</p> <h4 id="arguments_26">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input samples. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> <li>A generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instance. A more detailed description of unpacking behavior for iterator types (Dataset, generator, Sequence) is given in the <code translate="no" dir="ltr">Unpacking behavior for iterator-like inputs</code> section of <code translate="no" dir="ltr">Model.fit</code>.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">batch_size</code></b>: Integer or <code translate="no" dir="ltr">None</code>. Number of samples per gradient update. If unspecified, <code translate="no" dir="ltr">batch_size</code> will default to 32. Do not specify the <code translate="no" dir="ltr">batch_size</code> if your data is in the form of symbolic tensors, dataset, generators, or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> instances (since they generate batches).</li> <li>
<b><code translate="no" dir="ltr">verbose</code></b>: Verbosity mode, 0 or 1.</li> <li>
<b><code translate="no" dir="ltr">steps</code></b>: Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of <code translate="no" dir="ltr">None</code>. If x is a <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset and <code translate="no" dir="ltr">steps</code> is None, <code translate="no" dir="ltr">predict</code> will run until the input dataset is exhausted.</li> <li>
<b><code translate="no" dir="ltr">callbacks</code></b>: List of <a href="callbacks/callback"><code translate="no" dir="ltr">keras.callbacks.Callback</code></a> instances. List of callbacks to apply during prediction. See <a href="callbacks">callbacks</a>.</li> <li>
<b><code translate="no" dir="ltr">max_queue_size</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum size for the generator queue. If unspecified, <code translate="no" dir="ltr">max_queue_size</code> will default to 10.</li> <li>
<b><code translate="no" dir="ltr">workers</code></b>: Integer. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. Maximum number of processes to spin up when using process-based threading. If unspecified, <code translate="no" dir="ltr">workers</code> will default to 1. If 0, will execute the generator on the main thread.</li> <li>
<b><code translate="no" dir="ltr">use_multiprocessing</code></b>: Boolean. Used for generator or <a href="utils/sequence"><code translate="no" dir="ltr">keras.utils.Sequence</code></a> input only. If <code translate="no" dir="ltr">True</code>, use process-based threading. If unspecified, <code translate="no" dir="ltr">use_multiprocessing</code> will default to <code translate="no" dir="ltr">False</code>. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.</li> </ul> <p>See the discussion of <code translate="no" dir="ltr">Unpacking behavior for iterator-like inputs</code> for <a href="model#fit"><code translate="no" dir="ltr">Model.fit</code></a>. Note that Model.predict uses the same interpretation rules as <a href="model#fit"><code translate="no" dir="ltr">Model.fit</code></a> and <a href="model#evaluate"><code translate="no" dir="ltr">Model.evaluate</code></a>, so inputs must be unambiguous for all three methods.</p> <h4 id="returns_21">Returns:</h4> <p>Numpy array(s) of predictions.</p> <h4 id="raises_22">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of mismatch between the provided input data and the model's expectations, or in case a stateful model receives a number of samples that is not a multiple of the batch size.</li> </ul> <h3 id="predict_classes"><code translate="no" dir="ltr">predict_classes</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L324-L342">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predict_classes(
    x,
    batch_size=32,
    verbose=0
)
</pre> <p>Generate class predictions for the input samples.</p> <p>The input samples are processed batch by batch.</p> <h4 id="arguments_27">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: input data, as a Numpy array or list of Numpy arrays (if the model has multiple inputs).</li> <li>
<b><code translate="no" dir="ltr">batch_size</code></b>: integer.</li> <li>
<b><code translate="no" dir="ltr">verbose</code></b>: verbosity mode, 0 or 1.</li> </ul> <h4 id="returns_22">Returns:</h4> <p>A numpy array of class predictions.</p> <h3 id="predict_generator"><code translate="no" dir="ltr">predict_generator</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1336-L1360">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predict_generator(
    generator,
    steps=None,
    callbacks=None,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False,
    verbose=0
)
</pre> <p>Generates predictions for the input samples from a data generator. (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please use Model.predict, which supports generators.</span></aside> <h4 id="deprecated_6">DEPRECATED:</h4> <p><a href="model#predict"><code translate="no" dir="ltr">Model.predict</code></a> now supports generators, so there is no longer any need to use this endpoint.</p> <h3 id="predict_on_batch"><code translate="no" dir="ltr">predict_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1220-L1266">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predict_on_batch(x)
</pre> <p>Returns predictions for a single batch of samples.</p> <h4 id="arguments_28">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> </ul>
</li> </ul> <h4 id="returns_23">Returns:</h4> <p>Numpy array(s) of predictions.</p> <h4 id="raises_23">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of mismatch between given number of inputs and expectations of the model.</li> </ul> <h3 id="predict_proba"><code translate="no" dir="ltr">predict_proba</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/sequential.py#L302-L322">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">predict_proba(
    x,
    batch_size=32,
    verbose=0
)
</pre> <p>Generates class probability predictions for the input samples.</p> <p>The input samples are processed batch by batch.</p> <h4 id="arguments_29">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: input data, as a Numpy array or list of Numpy arrays (if the model has multiple inputs).</li> <li>
<b><code translate="no" dir="ltr">batch_size</code></b>: integer.</li> <li>
<b><code translate="no" dir="ltr">verbose</code></b>: verbosity mode, 0 or 1.</li> </ul> <h4 id="returns_24">Returns:</h4> <p>A Numpy array of probability predictions.</p> <h3 id="reset_metrics"><code translate="no" dir="ltr">reset_metrics</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1015-L1023">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">reset_metrics()
</pre> <p>Resets the state of metrics.</p> <h3 id="reset_states"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L455-L458">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">reset_states()
</pre> <h3 id="save"><code translate="no" dir="ltr">save</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L954-L1008">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">save(
    filepath,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=None,
    options=None
)
</pre> <p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p> <h4 id="the_savefile_includes_2">The savefile includes:</h4> <ul> <li>The model architecture, allowing to re-instantiate the model.</li> <li>The model weights.</li> <li>The state of the optimizer, allowing to resume training exactly where you left off.</li> </ul> <p>This allows you to save the entirety of the state of a model in a single file.</p> <p>Saved models can be reinstantiated via <a href="models/load_model"><code translate="no" dir="ltr">keras.models.load_model</code></a>. The model returned by <code translate="no" dir="ltr">load_model</code> is a compiled model ready to be used (unless the saved model was never compiled in the first place).</p> <p>Models built with the Sequential and Functional API can be saved to both the HDF5 and SavedModel formats. Subclassed models can only be saved with the SavedModel format.</p> <h4 id="arguments_30">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">filepath</code></b>: String, path to SavedModel or H5 file to save the model.</li> <li>
<b><code translate="no" dir="ltr">overwrite</code></b>: Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt.</li> <li>
<b><code translate="no" dir="ltr">include_optimizer</code></b>: If True, save optimizer's state together.</li> <li>
<b><code translate="no" dir="ltr">save_format</code></b>: Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X, and 'h5' in TF 1.X.</li> <li>
<b><code translate="no" dir="ltr">signatures</code></b>: Signatures to save with the SavedModel. Applicable to the 'tf' format only. Please see the <code translate="no" dir="ltr">signatures</code> argument in <a href="../saved_model/save"><code translate="no" dir="ltr">tf.saved_model.save</code></a> for details.</li> <li>
<b><code translate="no" dir="ltr">options</code></b>: Optional <a href="../saved_model/saveoptions"><code translate="no" dir="ltr">tf.saved_model.SaveOptions</code></a> object that specifies options for saving to SavedModel.</li> </ul> <h4 id="example_4">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">from keras.models import load_model

model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'
del model  # deletes the existing model

# returns a compiled model
# identical to the previous one
model = load_model('my_model.h5')
</pre> <h3 id="save_weights"><code translate="no" dir="ltr">save_weights</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L1010-L1129">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">save_weights(
    filepath,
    overwrite=True,
    save_format=None
)
</pre> <p>Saves all layer weights.</p> <p>Either saves in HDF5 or in TensorFlow format based on the <code translate="no" dir="ltr">save_format</code> argument.</p> <p>When saving in HDF5 format, the weight file has: - <code translate="no" dir="ltr">layer_names</code> (attribute), a list of strings (ordered names of model layers). - For every layer, a <code translate="no" dir="ltr">group</code> named <code translate="no" dir="ltr">layer.name</code> - For every such layer group, a group attribute <code translate="no" dir="ltr">weight_names</code>, a list of strings (ordered names of weights tensor of the layer). - For every weight in the layer, a dataset storing the weight value, named after the weight tensor.</p> <p>When saving in TensorFlow format, all objects referenced by the network are saved in the same format as <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a>, including any <code translate="no" dir="ltr">Layer</code> instances or <code translate="no" dir="ltr">Optimizer</code> instances assigned to object attributes. For networks constructed from inputs and outputs using <code translate="no" dir="ltr">tf.keras.Model(inputs, outputs)</code>, <code translate="no" dir="ltr">Layer</code> instances used by the network are tracked/saved automatically. For user-defined classes which inherit from <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a>, <code translate="no" dir="ltr">Layer</code> instances must be assigned to object attributes, typically in the constructor. See the documentation of <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> and <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a> for details.</p> <p>While the formats are the same, do not mix <code translate="no" dir="ltr">save_weights</code> and <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a>. Checkpoints saved by <a href="model#save_weights"><code translate="no" dir="ltr">Model.save_weights</code></a> should be loaded using <a href="model#load_weights"><code translate="no" dir="ltr">Model.load_weights</code></a>. Checkpoints saved using <a href="../train/checkpoint#save"><code translate="no" dir="ltr">tf.train.Checkpoint.save</code></a> should be restored using the corresponding <a href="../train/checkpoint#restore"><code translate="no" dir="ltr">tf.train.Checkpoint.restore</code></a>. Prefer <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> over <code translate="no" dir="ltr">save_weights</code> for training checkpoints.</p> <p>The TensorFlow format matches objects and variables by starting at a root object, <code translate="no" dir="ltr">self</code> for <code translate="no" dir="ltr">save_weights</code>, and greedily matching attribute names. For <a href="model#save"><code translate="no" dir="ltr">Model.save</code></a> this is the <code translate="no" dir="ltr">Model</code>, and for <a href="../train/checkpoint#save"><code translate="no" dir="ltr">Checkpoint.save</code></a> this is the <code translate="no" dir="ltr">Checkpoint</code> even if the <code translate="no" dir="ltr">Checkpoint</code> has a model attached. This means saving a <a href="model"><code translate="no" dir="ltr">tf.keras.Model</code></a> using <code translate="no" dir="ltr">save_weights</code> and loading into a <a href="../train/checkpoint"><code translate="no" dir="ltr">tf.train.Checkpoint</code></a> with a <code translate="no" dir="ltr">Model</code> attached (or vice versa) will not match the <code translate="no" dir="ltr">Model</code>'s variables. See the <a href="https://www.tensorflow.org/guide/checkpoint">guide to training checkpoints</a> for details on the TensorFlow format.</p> <h4 id="arguments_31">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">filepath</code></b>: String, path to the file to save the weights to. When saving in TensorFlow format, this is the prefix used for checkpoint files (multiple files are generated). Note that the '.h5' suffix causes weights to be saved in HDF5 format.</li> <li>
<b><code translate="no" dir="ltr">overwrite</code></b>: Whether to silently overwrite any existing file at the target location, or provide the user with a manual prompt.</li> <li>
<b><code translate="no" dir="ltr">save_format</code></b>: Either 'tf' or 'h5'. A <code translate="no" dir="ltr">filepath</code> ending in '.h5' or '.keras' will default to HDF5 if <code translate="no" dir="ltr">save_format</code> is <code translate="no" dir="ltr">None</code>. Otherwise <code translate="no" dir="ltr">None</code> defaults to 'tf'.</li> </ul> <h4 id="raises_24">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ImportError</code></b>: If h5py is not available when attempting to save in HDF5 format.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: For invalid/unknown format arguments.</li> </ul> <h3 id="summary"><code translate="no" dir="ltr">summary</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L1283-L1310">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">summary(
    line_length=None,
    positions=None,
    print_fn=None
)
</pre> <p>Prints a string summary of the network.</p> <h4 id="arguments_32">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">line_length</code></b>: Total length of printed lines (e.g. set this to adapt the display to different terminal window sizes).</li> <li>
<b><code translate="no" dir="ltr">positions</code></b>: Relative or absolute positions of log elements in each line. If not provided, defaults to <code translate="no" dir="ltr">[.33, .55, .67, 1.]</code>.</li> <li>
<b><code translate="no" dir="ltr">print_fn</code></b>: Print function to use. Defaults to <code translate="no" dir="ltr">print</code>. It will be called on each line of the summary. You can set it to a custom function in order to capture the string summary.</li> </ul> <h4 id="raises_25">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">summary()</code> is called before the model is built.</li> </ul> <h3 id="test_on_batch"><code translate="no" dir="ltr">test_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1132-L1218">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">test_on_batch(
    x,
    y=None,
    sample_weight=None,
    reset_metrics=True
)
</pre> <p>Test the model on a single batch of samples.</p> <h4 id="arguments_33">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator).</li> <li>
<b><code translate="no" dir="ltr">sample_weight</code></b>: Optional array of the same length as x, containing weights to apply to the model's loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode="temporal" in compile(). This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset.</li> <li>
<b><code translate="no" dir="ltr">reset_metrics</code></b>: If <code translate="no" dir="ltr">True</code>, the metrics returned will be only for this batch. If <code translate="no" dir="ltr">False</code>, the metrics will be statefully accumulated across batches.</li> </ul> <h4 id="returns_25">Returns:</h4> <p>Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs.</p> <h4 id="raises_26">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of invalid user-provided arguments.</li> </ul> <h3 id="to_json"><code translate="no" dir="ltr">to_json</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L1241-L1256">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">to_json(**kwargs)
</pre> <p>Returns a JSON string containing the network configuration.</p> <p>To load a network from a JSON save file, use <a href="models/model_from_json"><code translate="no" dir="ltr">keras.models.model_from_json(json_string, custom_objects={})</code></a>.</p> <h4 id="arguments_34">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: Additional keyword arguments to be passed to <code translate="no" dir="ltr">json.dumps()</code>.</li> </ul> <h4 id="returns_26">Returns:</h4> <p>A JSON string.</p> <h3 id="to_yaml"><code translate="no" dir="ltr">to_yaml</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/network.py#L1258-L1281">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">to_yaml(**kwargs)
</pre> <p>Returns a yaml string containing the network configuration.</p> <p>To load a network from a yaml save file, use <a href="models/model_from_yaml"><code translate="no" dir="ltr">keras.models.model_from_yaml(yaml_string, custom_objects={})</code></a>.</p> <p><code translate="no" dir="ltr">custom_objects</code> should be a dictionary mapping the names of custom losses / layers / etc to the corresponding functions / classes.</p> <h4 id="arguments_35">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: Additional keyword arguments to be passed to <code translate="no" dir="ltr">yaml.dump()</code>.</li> </ul> <h4 id="returns_27">Returns:</h4> <p>A YAML string.</p> <h4 id="raises_27">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ImportError</code></b>: if yaml module is not found.</li> </ul> <h3 id="train_on_batch"><code translate="no" dir="ltr">train_on_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L1025-L1130">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">train_on_batch(
    x,
    y=None,
    sample_weight=None,
    class_weight=None,
    reset_metrics=True
)
</pre> <p>Runs a single gradient update on a single batch of data.</p> <h4 id="arguments_36">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">x</code></b>: Input data. It could be: <ul> <li>A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).</li> <li>A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).</li> <li>A dict mapping input names to the corresponding array/tensors, if the model has named inputs.</li> <li>A <a href="../data"><code translate="no" dir="ltr">tf.data</code></a> dataset.</li> </ul>
</li> <li>
<b><code translate="no" dir="ltr">y</code></b>: Target data. Like the input data <code translate="no" dir="ltr">x</code>, it could be either Numpy array(s) or TensorFlow tensor(s). It should be consistent with <code translate="no" dir="ltr">x</code> (you cannot have Numpy inputs and tensor targets, or inversely). If <code translate="no" dir="ltr">x</code> is a dataset, <code translate="no" dir="ltr">y</code> should not be specified (since targets will be obtained from the iterator).</li> <li>
<b><code translate="no" dir="ltr">sample_weight</code></b>: Optional array of the same length as x, containing weights to apply to the model's loss for each sample. In the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode="temporal" in compile(). This argument is not supported when <code translate="no" dir="ltr">x</code> is a dataset.</li> <li>
<b><code translate="no" dir="ltr">class_weight</code></b>: Optional dictionary mapping class indices (integers) to a weight (float) to apply to the model's loss for the samples from this class during training. This can be useful to tell the model to "pay more attention" to samples from an under-represented class.</li> <li>
<b><code translate="no" dir="ltr">reset_metrics</code></b>: If <code translate="no" dir="ltr">True</code>, the metrics returned will be only for this batch. If <code translate="no" dir="ltr">False</code>, the metrics will be statefully accumulated across batches.</li> </ul> <h4 id="returns_28">Returns:</h4> <p>Scalar training loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute <code translate="no" dir="ltr">model.metrics_names</code> will give you the display labels for the scalar outputs.</p> <h4 id="raises_28">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: In case of invalid user-provided arguments.</li> </ul> <h2 id="compat_aliases_2">Compat aliases</h2> <ul> <li><a href="sequential"><code translate="no" dir="ltr">tf.compat.v1.keras.Sequential</code></a></li> <li><a href="sequential"><code translate="no" dir="ltr">tf.compat.v1.keras.models.Sequential</code></a></li> <li><a href="sequential"><code translate="no" dir="ltr">tf.compat.v2.keras.Sequential</code></a></li> <li><a href="sequential"><code translate="no" dir="ltr">tf.compat.v2.keras.models.Sequential</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/Sequential</a>
  </p>
</div>
