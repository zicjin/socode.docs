<h1 class="devsite-page-title">Module: tf.keras.backend</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.keras.backend"> <meta itemprop="path" content="Stable"> </div> <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/backend">  TensorFlow 1 version</a> </td> </table> <p>Keras backend API.</p> <h2 id="functions">Functions</h2> <p><a href="backend/abs"><code translate="no" dir="ltr">abs(...)</code></a>: Element-wise absolute value.</p> <p><a href="backend/all"><code translate="no" dir="ltr">all(...)</code></a>: Bitwise reduction (logical AND).</p> <p><a href="backend/any"><code translate="no" dir="ltr">any(...)</code></a>: Bitwise reduction (logical OR).</p> <p><a href="backend/arange"><code translate="no" dir="ltr">arange(...)</code></a>: Creates a 1D tensor containing a sequence of integers.</p> <p><a href="backend/argmax"><code translate="no" dir="ltr">argmax(...)</code></a>: Returns the index of the maximum value along an axis.</p> <p><a href="backend/argmin"><code translate="no" dir="ltr">argmin(...)</code></a>: Returns the index of the minimum value along an axis.</p> <p><a href="backend/backend"><code translate="no" dir="ltr">backend(...)</code></a>: Publicly accessible method for determining the current backend.</p> <p><a href="backend/batch_dot"><code translate="no" dir="ltr">batch_dot(...)</code></a>: Batchwise dot product.</p> <p><a href="backend/batch_flatten"><code translate="no" dir="ltr">batch_flatten(...)</code></a>: Turn a nD tensor into a 2D tensor with same 0th dimension.</p> <p><a href="backend/batch_get_value"><code translate="no" dir="ltr">batch_get_value(...)</code></a>: Returns the value of more than one tensor variable.</p> <p><a href="backend/batch_normalization"><code translate="no" dir="ltr">batch_normalization(...)</code></a>: Applies batch normalization on x given mean, var, beta and gamma.</p> <p><a href="backend/batch_set_value"><code translate="no" dir="ltr">batch_set_value(...)</code></a>: Sets the values of many tensor variables at once.</p> <p><a href="backend/bias_add"><code translate="no" dir="ltr">bias_add(...)</code></a>: Adds a bias vector to a tensor.</p> <p><a href="backend/binary_crossentropy"><code translate="no" dir="ltr">binary_crossentropy(...)</code></a>: Binary crossentropy between an output tensor and a target tensor.</p> <p><a href="backend/cast"><code translate="no" dir="ltr">cast(...)</code></a>: Casts a tensor to a different dtype and returns it.</p> <p><a href="backend/cast_to_floatx"><code translate="no" dir="ltr">cast_to_floatx(...)</code></a>: Cast a Numpy array to the default Keras float type.</p> <p><a href="backend/categorical_crossentropy"><code translate="no" dir="ltr">categorical_crossentropy(...)</code></a>: Categorical crossentropy between an output tensor and a target tensor.</p> <p><a href="backend/clear_session"><code translate="no" dir="ltr">clear_session(...)</code></a>: Destroys the current TF graph and creates a new one.</p> <p><a href="backend/clip"><code translate="no" dir="ltr">clip(...)</code></a>: Element-wise value clipping.</p> <p><a href="backend/concatenate"><code translate="no" dir="ltr">concatenate(...)</code></a>: Concatenates a list of tensors alongside the specified axis.</p> <p><a href="backend/constant"><code translate="no" dir="ltr">constant(...)</code></a>: Creates a constant tensor.</p> <p><a href="backend/conv1d"><code translate="no" dir="ltr">conv1d(...)</code></a>: 1D convolution.</p> <p><a href="backend/conv2d"><code translate="no" dir="ltr">conv2d(...)</code></a>: 2D convolution.</p> <p><a href="backend/conv2d_transpose"><code translate="no" dir="ltr">conv2d_transpose(...)</code></a>: 2D deconvolution (i.e.</p> <p><a href="backend/conv3d"><code translate="no" dir="ltr">conv3d(...)</code></a>: 3D convolution.</p> <p><a href="backend/cos"><code translate="no" dir="ltr">cos(...)</code></a>: Computes cos of x element-wise.</p> <p><a href="backend/count_params"><code translate="no" dir="ltr">count_params(...)</code></a>: Returns the static number of elements in a variable or tensor.</p> <p><a href="backend/ctc_batch_cost"><code translate="no" dir="ltr">ctc_batch_cost(...)</code></a>: Runs CTC loss algorithm on each batch element.</p> <p><a href="backend/ctc_decode"><code translate="no" dir="ltr">ctc_decode(...)</code></a>: Decodes the output of a softmax.</p> <p><a href="backend/ctc_label_dense_to_sparse"><code translate="no" dir="ltr">ctc_label_dense_to_sparse(...)</code></a>: Converts CTC labels from dense to sparse.</p> <p><a href="backend/cumprod"><code translate="no" dir="ltr">cumprod(...)</code></a>: Cumulative product of the values in a tensor, alongside the specified axis.</p> <p><a href="backend/cumsum"><code translate="no" dir="ltr">cumsum(...)</code></a>: Cumulative sum of the values in a tensor, alongside the specified axis.</p> <p><a href="backend/depthwise_conv2d"><code translate="no" dir="ltr">depthwise_conv2d(...)</code></a>: 2D convolution with separable filters.</p> <p><a href="backend/dot"><code translate="no" dir="ltr">dot(...)</code></a>: Multiplies 2 tensors (and/or variables) and returns a <em>tensor</em>.</p> <p><a href="backend/dropout"><code translate="no" dir="ltr">dropout(...)</code></a>: Sets entries in <code translate="no" dir="ltr">x</code> to zero at random, while scaling the entire tensor.</p> <p><a href="backend/dtype"><code translate="no" dir="ltr">dtype(...)</code></a>: Returns the dtype of a Keras tensor or variable, as a string.</p> <p><a href="backend/elu"><code translate="no" dir="ltr">elu(...)</code></a>: Exponential linear unit.</p> <p><a href="backend/epsilon"><code translate="no" dir="ltr">epsilon(...)</code></a>: Returns the value of the fuzz factor used in numeric expressions.</p> <p><a href="backend/equal"><code translate="no" dir="ltr">equal(...)</code></a>: Element-wise equality between two tensors.</p> <p><a href="backend/eval"><code translate="no" dir="ltr">eval(...)</code></a>: Evaluates the value of a variable.</p> <p><a href="backend/exp"><code translate="no" dir="ltr">exp(...)</code></a>: Element-wise exponential.</p> <p><a href="backend/expand_dims"><code translate="no" dir="ltr">expand_dims(...)</code></a>: Adds a 1-sized dimension at index "axis".</p> <p><a href="backend/eye"><code translate="no" dir="ltr">eye(...)</code></a>: Instantiate an identity matrix and returns it.</p> <p><a href="backend/flatten"><code translate="no" dir="ltr">flatten(...)</code></a>: Flatten a tensor.</p> <p><a href="backend/floatx"><code translate="no" dir="ltr">floatx(...)</code></a>: Returns the default float type, as a string.</p> <p><a href="backend/foldl"><code translate="no" dir="ltr">foldl(...)</code></a>: Reduce elems using fn to combine them from left to right.</p> <p><a href="backend/foldr"><code translate="no" dir="ltr">foldr(...)</code></a>: Reduce elems using fn to combine them from right to left.</p> <p><a href="backend/function"><code translate="no" dir="ltr">function(...)</code></a>: Instantiates a Keras function.</p> <p><a href="backend/gather"><code translate="no" dir="ltr">gather(...)</code></a>: Retrieves the elements of indices <code translate="no" dir="ltr">indices</code> in the tensor <code translate="no" dir="ltr">reference</code>.</p> <p><a href="backend/get_uid"><code translate="no" dir="ltr">get_uid(...)</code></a>: Associates a string prefix with an integer counter in a TensorFlow graph.</p> <p><a href="backend/get_value"><code translate="no" dir="ltr">get_value(...)</code></a>: Returns the value of a variable.</p> <p><a href="backend/gradients"><code translate="no" dir="ltr">gradients(...)</code></a>: Returns the gradients of <code translate="no" dir="ltr">loss</code> w.r.t. <code translate="no" dir="ltr">variables</code>.</p> <p><a href="backend/greater"><code translate="no" dir="ltr">greater(...)</code></a>: Element-wise truth value of (x &gt; y).</p> <p><a href="backend/greater_equal"><code translate="no" dir="ltr">greater_equal(...)</code></a>: Element-wise truth value of (x &gt;= y).</p> <p><a href="backend/hard_sigmoid"><code translate="no" dir="ltr">hard_sigmoid(...)</code></a>: Segment-wise linear approximation of sigmoid.</p> <p><a href="backend/image_data_format"><code translate="no" dir="ltr">image_data_format(...)</code></a>: Returns the default image data format convention.</p> <p><a href="backend/in_test_phase"><code translate="no" dir="ltr">in_test_phase(...)</code></a>: Selects <code translate="no" dir="ltr">x</code> in test phase, and <code translate="no" dir="ltr">alt</code> otherwise.</p> <p><a href="backend/in_top_k"><code translate="no" dir="ltr">in_top_k(...)</code></a>: Returns whether the <code translate="no" dir="ltr">targets</code> are in the top <code translate="no" dir="ltr">k</code> <code translate="no" dir="ltr">predictions</code>.</p> <p><a href="backend/in_train_phase"><code translate="no" dir="ltr">in_train_phase(...)</code></a>: Selects <code translate="no" dir="ltr">x</code> in train phase, and <code translate="no" dir="ltr">alt</code> otherwise.</p> <p><a href="backend/int_shape"><code translate="no" dir="ltr">int_shape(...)</code></a>: Returns the shape of tensor or variable as a tuple of int or None entries.</p> <p><a href="backend/is_keras_tensor"><code translate="no" dir="ltr">is_keras_tensor(...)</code></a>: Returns whether <code translate="no" dir="ltr">x</code> is a Keras tensor.</p> <p><a href="backend/is_sparse"><code translate="no" dir="ltr">is_sparse(...)</code></a>: Returns whether a tensor is a sparse tensor.</p> <p><a href="backend/l2_normalize"><code translate="no" dir="ltr">l2_normalize(...)</code></a>: Normalizes a tensor wrt the L2 norm alongside the specified axis.</p> <p><a href="backend/learning_phase"><code translate="no" dir="ltr">learning_phase(...)</code></a>: Returns the learning phase flag.</p> <p><a href="backend/learning_phase_scope"><code translate="no" dir="ltr">learning_phase_scope(...)</code></a>: Provides a scope within which the learning phase is equal to <code translate="no" dir="ltr">value</code>.</p> <p><a href="backend/less"><code translate="no" dir="ltr">less(...)</code></a>: Element-wise truth value of (x &lt; y).</p> <p><a href="backend/less_equal"><code translate="no" dir="ltr">less_equal(...)</code></a>: Element-wise truth value of (x &lt;= y).</p> <p><a href="backend/local_conv1d"><code translate="no" dir="ltr">local_conv1d(...)</code></a>: Apply 1D conv with un-shared weights.</p> <p><a href="backend/local_conv2d"><code translate="no" dir="ltr">local_conv2d(...)</code></a>: Apply 2D conv with un-shared weights.</p> <p><a href="backend/log"><code translate="no" dir="ltr">log(...)</code></a>: Element-wise log.</p> <p><a href="backend/manual_variable_initialization"><code translate="no" dir="ltr">manual_variable_initialization(...)</code></a>: Sets the manual variable initialization flag.</p> <p><a href="backend/map_fn"><code translate="no" dir="ltr">map_fn(...)</code></a>: Map the function fn over the elements elems and return the outputs.</p> <p><a href="backend/max"><code translate="no" dir="ltr">max(...)</code></a>: Maximum value in a tensor.</p> <p><a href="backend/maximum"><code translate="no" dir="ltr">maximum(...)</code></a>: Element-wise maximum of two tensors.</p> <p><a href="backend/mean"><code translate="no" dir="ltr">mean(...)</code></a>: Mean of a tensor, alongside the specified axis.</p> <p><a href="backend/min"><code translate="no" dir="ltr">min(...)</code></a>: Minimum value in a tensor.</p> <p><a href="backend/minimum"><code translate="no" dir="ltr">minimum(...)</code></a>: Element-wise minimum of two tensors.</p> <p><a href="backend/moving_average_update"><code translate="no" dir="ltr">moving_average_update(...)</code></a>: Compute the moving average of a variable.</p> <p><a href="backend/name_scope"><code translate="no" dir="ltr">name_scope(...)</code></a>: A context manager for use when defining a Python op.</p> <p><a href="backend/ndim"><code translate="no" dir="ltr">ndim(...)</code></a>: Returns the number of axes in a tensor, as an integer.</p> <p><a href="backend/normalize_batch_in_training"><code translate="no" dir="ltr">normalize_batch_in_training(...)</code></a>: Computes mean and std for batch then apply batch_normalization on batch.</p> <p><a href="backend/not_equal"><code translate="no" dir="ltr">not_equal(...)</code></a>: Element-wise inequality between two tensors.</p> <p><a href="backend/one_hot"><code translate="no" dir="ltr">one_hot(...)</code></a>: Computes the one-hot representation of an integer tensor.</p> <p><a href="backend/ones"><code translate="no" dir="ltr">ones(...)</code></a>: Instantiates an all-ones variable and returns it.</p> <p><a href="backend/ones_like"><code translate="no" dir="ltr">ones_like(...)</code></a>: Instantiates an all-ones variable of the same shape as another tensor.</p> <p><a href="backend/permute_dimensions"><code translate="no" dir="ltr">permute_dimensions(...)</code></a>: Permutes axes in a tensor.</p> <p><a href="backend/placeholder"><code translate="no" dir="ltr">placeholder(...)</code></a>: Instantiates a placeholder tensor and returns it.</p> <p><a href="backend/pool2d"><code translate="no" dir="ltr">pool2d(...)</code></a>: 2D Pooling.</p> <p><a href="backend/pool3d"><code translate="no" dir="ltr">pool3d(...)</code></a>: 3D Pooling.</p> <p><a href="backend/pow"><code translate="no" dir="ltr">pow(...)</code></a>: Element-wise exponentiation.</p> <p><a href="backend/print_tensor"><code translate="no" dir="ltr">print_tensor(...)</code></a>: Prints <code translate="no" dir="ltr">message</code> and the tensor value when evaluated.</p> <p><a href="backend/prod"><code translate="no" dir="ltr">prod(...)</code></a>: Multiplies the values in a tensor, alongside the specified axis.</p> <p><a href="backend/random_binomial"><code translate="no" dir="ltr">random_binomial(...)</code></a>: Returns a tensor with random binomial distribution of values.</p> <p><a href="backend/random_normal"><code translate="no" dir="ltr">random_normal(...)</code></a>: Returns a tensor with normal distribution of values.</p> <p><a href="backend/random_normal_variable"><code translate="no" dir="ltr">random_normal_variable(...)</code></a>: Instantiates a variable with values drawn from a normal distribution.</p> <p><a href="backend/random_uniform"><code translate="no" dir="ltr">random_uniform(...)</code></a>: Returns a tensor with uniform distribution of values.</p> <p><a href="backend/random_uniform_variable"><code translate="no" dir="ltr">random_uniform_variable(...)</code></a>: Instantiates a variable with values drawn from a uniform distribution.</p> <p><a href="backend/relu"><code translate="no" dir="ltr">relu(...)</code></a>: Rectified linear unit.</p> <p><a href="backend/repeat"><code translate="no" dir="ltr">repeat(...)</code></a>: Repeats a 2D tensor.</p> <p><a href="backend/repeat_elements"><code translate="no" dir="ltr">repeat_elements(...)</code></a>: Repeats the elements of a tensor along an axis, like <code translate="no" dir="ltr">np.repeat</code>.</p> <p><a href="backend/reset_uids"><code translate="no" dir="ltr">reset_uids(...)</code></a>: Resets graph identifiers.</p> <p><a href="backend/reshape"><code translate="no" dir="ltr">reshape(...)</code></a>: Reshapes a tensor to the specified shape.</p> <p><a href="backend/resize_images"><code translate="no" dir="ltr">resize_images(...)</code></a>: Resizes the images contained in a 4D tensor.</p> <p><a href="backend/resize_volumes"><code translate="no" dir="ltr">resize_volumes(...)</code></a>: Resizes the volume contained in a 5D tensor.</p> <p><a href="backend/reverse"><code translate="no" dir="ltr">reverse(...)</code></a>: Reverse a tensor along the specified axes.</p> <p><a href="backend/rnn"><code translate="no" dir="ltr">rnn(...)</code></a>: Iterates over the time dimension of a tensor.</p> <p><a href="backend/round"><code translate="no" dir="ltr">round(...)</code></a>: Element-wise rounding to the closest integer.</p> <p><a href="backend/separable_conv2d"><code translate="no" dir="ltr">separable_conv2d(...)</code></a>: 2D convolution with separable filters.</p> <p><a href="backend/set_epsilon"><code translate="no" dir="ltr">set_epsilon(...)</code></a>: Sets the value of the fuzz factor used in numeric expressions.</p> <p><a href="backend/set_floatx"><code translate="no" dir="ltr">set_floatx(...)</code></a>: Sets the default float type.</p> <p><a href="backend/set_image_data_format"><code translate="no" dir="ltr">set_image_data_format(...)</code></a>: Sets the value of the image data format convention.</p> <p><a href="backend/set_learning_phase"><code translate="no" dir="ltr">set_learning_phase(...)</code></a>: Sets the learning phase to a fixed value.</p> <p><a href="backend/set_value"><code translate="no" dir="ltr">set_value(...)</code></a>: Sets the value of a variable, from a Numpy array.</p> <p><a href="backend/shape"><code translate="no" dir="ltr">shape(...)</code></a>: Returns the symbolic shape of a tensor or variable.</p> <p><a href="backend/sigmoid"><code translate="no" dir="ltr">sigmoid(...)</code></a>: Element-wise sigmoid.</p> <p><a href="backend/sign"><code translate="no" dir="ltr">sign(...)</code></a>: Element-wise sign.</p> <p><a href="backend/sin"><code translate="no" dir="ltr">sin(...)</code></a>: Computes sin of x element-wise.</p> <p><a href="backend/softmax"><code translate="no" dir="ltr">softmax(...)</code></a>: Softmax of a tensor.</p> <p><a href="backend/softplus"><code translate="no" dir="ltr">softplus(...)</code></a>: Softplus of a tensor.</p> <p><a href="backend/softsign"><code translate="no" dir="ltr">softsign(...)</code></a>: Softsign of a tensor.</p> <p><a href="backend/sparse_categorical_crossentropy"><code translate="no" dir="ltr">sparse_categorical_crossentropy(...)</code></a>: Categorical crossentropy with integer targets.</p> <p><a href="backend/spatial_2d_padding"><code translate="no" dir="ltr">spatial_2d_padding(...)</code></a>: Pads the 2nd and 3rd dimensions of a 4D tensor.</p> <p><a href="backend/spatial_3d_padding"><code translate="no" dir="ltr">spatial_3d_padding(...)</code></a>: Pads 5D tensor with zeros along the depth, height, width dimensions.</p> <p><a href="backend/sqrt"><code translate="no" dir="ltr">sqrt(...)</code></a>: Element-wise square root.</p> <p><a href="backend/square"><code translate="no" dir="ltr">square(...)</code></a>: Element-wise square.</p> <p><a href="backend/squeeze"><code translate="no" dir="ltr">squeeze(...)</code></a>: Removes a 1-dimension from the tensor at index "axis".</p> <p><a href="backend/stack"><code translate="no" dir="ltr">stack(...)</code></a>: Stacks a list of rank <code translate="no" dir="ltr">R</code> tensors into a rank <code translate="no" dir="ltr">R+1</code> tensor.</p> <p><a href="backend/std"><code translate="no" dir="ltr">std(...)</code></a>: Standard deviation of a tensor, alongside the specified axis.</p> <p><a href="backend/stop_gradient"><code translate="no" dir="ltr">stop_gradient(...)</code></a>: Returns <code translate="no" dir="ltr">variables</code> but with zero gradient w.r.t. every other variable.</p> <p><a href="backend/sum"><code translate="no" dir="ltr">sum(...)</code></a>: Sum of the values in a tensor, alongside the specified axis.</p> <p><a href="backend/switch"><code translate="no" dir="ltr">switch(...)</code></a>: Switches between two operations depending on a scalar value.</p> <p><a href="backend/tanh"><code translate="no" dir="ltr">tanh(...)</code></a>: Element-wise tanh.</p> <p><a href="backend/temporal_padding"><code translate="no" dir="ltr">temporal_padding(...)</code></a>: Pads the middle dimension of a 3D tensor.</p> <p><a href="backend/tile"><code translate="no" dir="ltr">tile(...)</code></a>: Creates a tensor by tiling <code translate="no" dir="ltr">x</code> by <code translate="no" dir="ltr">n</code>.</p> <p><a href="backend/to_dense"><code translate="no" dir="ltr">to_dense(...)</code></a>: Converts a sparse tensor into a dense tensor and returns it.</p> <p><a href="backend/transpose"><code translate="no" dir="ltr">transpose(...)</code></a>: Transposes a tensor and returns it.</p> <p><a href="backend/truncated_normal"><code translate="no" dir="ltr">truncated_normal(...)</code></a>: Returns a tensor with truncated random normal distribution of values.</p> <p><a href="backend/update"><code translate="no" dir="ltr">update(...)</code></a></p> <p><a href="backend/update_add"><code translate="no" dir="ltr">update_add(...)</code></a>: Update the value of <code translate="no" dir="ltr">x</code> by adding <code translate="no" dir="ltr">increment</code>.</p> <p><a href="backend/update_sub"><code translate="no" dir="ltr">update_sub(...)</code></a>: Update the value of <code translate="no" dir="ltr">x</code> by subtracting <code translate="no" dir="ltr">decrement</code>.</p> <p><a href="backend/var"><code translate="no" dir="ltr">var(...)</code></a>: Variance of a tensor, alongside the specified axis.</p> <p><a href="backend/variable"><code translate="no" dir="ltr">variable(...)</code></a>: Instantiates a variable and returns it.</p> <p><a href="backend/zeros"><code translate="no" dir="ltr">zeros(...)</code></a>: Instantiates an all-zeros variable and returns it.</p> <p><a href="backend/zeros_like"><code translate="no" dir="ltr">zeros_like(...)</code></a>: Instantiates an all-zeros variable of the same shape as another tensor.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/keras/backend" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/keras/backend</a>
  </p>
</div>
