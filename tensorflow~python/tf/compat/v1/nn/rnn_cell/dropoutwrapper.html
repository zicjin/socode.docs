<h1 class="devsite-page-title">tf.compat.v1.nn.rnn_cell.DropoutWrapper</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.nn.rnn_cell.DropoutWrapper"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="graph"> <meta itemprop="property" content="output_size"> <meta itemprop="property" content="scope_name"> <meta itemprop="property" content="state_size"> <meta itemprop="property" content="wrapped_cell"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="get_initial_state"> <meta itemprop="property" content="zero_state"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/rnn_cell_impl.py#L1166-L1173">  View source on GitHub </a> </td>
</table>  <h2 id="class_dropoutwrapper">Class <code translate="no" dir="ltr">DropoutWrapper</code>
</h2> <p>Operator adding dropout to inputs and outputs of the given cell.</p>  <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/rnn_cell_impl.py#L1170-L1171">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    *args,
    **kwargs
)
</pre> <p>Create a cell with added input, state, and/or output dropout.</p> <p>If <code translate="no" dir="ltr">variational_recurrent</code> is set to <code translate="no" dir="ltr">True</code> (<strong>NOT</strong> the default behavior), then the same dropout mask is applied at every step, as described in: <a href="https://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks. Y. Gal, Z. Ghahramani</a>.</p> <p>Otherwise a different dropout mask is applied at every time step.</p> <p>Note, by default (unless a custom <code translate="no" dir="ltr">dropout_state_filter</code> is provided), the memory state (<code translate="no" dir="ltr">c</code> component of any <code translate="no" dir="ltr">LSTMStateTuple</code>) passing through a <code translate="no" dir="ltr">DropoutWrapper</code> is never modified. This behavior is described in the above article.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">cell</code></b>: an RNNCell, a projection to output_size is added to it.</li> <li>
<b><code translate="no" dir="ltr">input_keep_prob</code></b>: unit Tensor or float between 0 and 1, input keep probability; if it is constant and 1, no input dropout will be added.</li> <li>
<b><code translate="no" dir="ltr">output_keep_prob</code></b>: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added.</li> <li>
<b><code translate="no" dir="ltr">state_keep_prob</code></b>: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added. State dropout is performed on the outgoing states of the cell. <strong>Note</strong> the state components to which dropout is applied when <code translate="no" dir="ltr">state_keep_prob</code> is in <code translate="no" dir="ltr">(0, 1)</code> are also determined by the argument <code translate="no" dir="ltr">dropout_state_filter_visitor</code> (e.g. by default dropout is never applied to the <code translate="no" dir="ltr">c</code> component of an <code translate="no" dir="ltr">LSTMStateTuple</code>).</li> <li>
<b><code translate="no" dir="ltr">variational_recurrent</code></b>: Python bool. If <code translate="no" dir="ltr">True</code>, then the same dropout pattern is applied across all time steps per run call. If this parameter is set, <code translate="no" dir="ltr">input_size</code> <strong>must</strong> be provided.</li> <li>
<b><code translate="no" dir="ltr">input_size</code></b>: (optional) (possibly nested tuple of) <code translate="no" dir="ltr">TensorShape</code> objects containing the depth(s) of the input tensors expected to be passed in to the <code translate="no" dir="ltr">DropoutWrapper</code>. Required and used <strong>iff</strong> <code translate="no" dir="ltr">variational_recurrent = True</code> and <code translate="no" dir="ltr">input_keep_prob &lt; 1</code>.</li> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: (optional) The <code translate="no" dir="ltr">dtype</code> of the input, state, and output tensors. Required and used <strong>iff</strong> <code translate="no" dir="ltr">variational_recurrent = True</code>.</li> <li>
<b><code translate="no" dir="ltr">seed</code></b>: (optional) integer, the randomness seed.</li> <li>
<b><code translate="no" dir="ltr">dropout_state_filter_visitor</code></b>: (optional), default: (see below). Function that takes any hierarchical level of the state and returns a scalar or depth=1 structure of Python booleans describing which terms in the state should be dropped out. In addition, if the function returns <code translate="no" dir="ltr">True</code>, dropout is applied across this sublevel. If the function returns <code translate="no" dir="ltr">False</code>, dropout is not applied across this entire sublevel. Default behavior: perform dropout on all terms except the memory (<code translate="no" dir="ltr">c</code>) state of <code translate="no" dir="ltr">LSTMCellState</code> objects, and don't try to apply dropout to <code translate="no" dir="ltr">TensorArray</code> objects: <code translate="no" dir="ltr">def dropout_state_filter_visitor(s): if isinstance(s, LSTMCellState): # Never perform dropout on the c state. return LSTMCellState(c=False, h=True) elif isinstance(s, TensorArray): return False return True</code>
</li> <li>
<b><code translate="no" dir="ltr">**kwargs</code></b>: dict of keyword arguments for base layer.</li> </ul> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if <code translate="no" dir="ltr">cell</code> is not an <code translate="no" dir="ltr">RNNCell</code>, or <code translate="no" dir="ltr">keep_state_fn</code> is provided but not <code translate="no" dir="ltr">callable</code>.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if any of the keep_probs are not between 0 and 1.</li> </ul> <h2 id="properties">Properties</h2> <h3 id="graph"><code translate="no" dir="ltr">graph</code></h3> <p>DEPRECATED FUNCTION</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Stop using this property because tf.layers layers no longer track their graph.</span></aside> <h3 id="output_size"><code translate="no" dir="ltr">output_size</code></h3> <h3 id="scope_name"><code translate="no" dir="ltr">scope_name</code></h3> <h3 id="state_size"><code translate="no" dir="ltr">state_size</code></h3> <h3 id="wrapped_cell"><code translate="no" dir="ltr">wrapped_cell</code></h3> <h2 id="methods">Methods</h2> <h3 id="get_initial_state"><code translate="no" dir="ltr">get_initial_state</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/rnn_cell_impl.py#L281-L309">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">get_initial_state(
    inputs=None,
    batch_size=None,
    dtype=None
)
</pre> <h3 id="zero_state"><code translate="no" dir="ltr">zero_state</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/rnn_cell_wrapper_impl.py#L201-L203">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">zero_state(
    batch_size,
    dtype
)
</pre>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/rnn_cell/DropoutWrapper" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/rnn_cell/DropoutWrapper</a>
  </p>
</div>
