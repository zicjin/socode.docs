<h1 class="devsite-page-title">tf.compat.v1.train.MonitoredTrainingSession</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.train.MonitoredTrainingSession"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/monitored_session.py#L433-L604">  View source on GitHub </a> </td>
</table>  <p>Creates a <code translate="no" dir="ltr">MonitoredSession</code> for training.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.train.MonitoredTrainingSession(
    master='',
    is_chief=True,
    checkpoint_dir=None,
    scaffold=None,
    hooks=None,
    chief_only_hooks=None,
    save_checkpoint_secs=USE_DEFAULT,
    save_summaries_steps=USE_DEFAULT,
    save_summaries_secs=USE_DEFAULT,
    config=None,
    stop_grace_period_secs=120,
    log_step_count_steps=100,
    max_wait_secs=7200,
    save_checkpoint_steps=USE_DEFAULT,
    summary_dir=None,
    save_graph_def=True
)
</pre>  <p>For a chief, this utility sets proper session initializer/restorer. It also creates hooks related to checkpoint and summary saving. For workers, this utility sets proper session creator which waits for the chief to initialize/restore. Please check <a href="monitoredsession"><code translate="no" dir="ltr">tf.compat.v1.train.MonitoredSession</code></a> for more information.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">master</code></b>: <code translate="no" dir="ltr">String</code> the TensorFlow master to use.</li> <li>
<b><code translate="no" dir="ltr">is_chief</code></b>: If <code translate="no" dir="ltr">True</code>, it will take care of initialization and recovery the underlying TensorFlow session. If <code translate="no" dir="ltr">False</code>, it will wait on a chief to initialize or recover the TensorFlow session.</li> <li>
<b><code translate="no" dir="ltr">checkpoint_dir</code></b>: A string. Optional path to a directory where to restore variables.</li> <li>
<b><code translate="no" dir="ltr">scaffold</code></b>: A <code translate="no" dir="ltr">Scaffold</code> used for gathering or building supportive ops. If not specified, a default one is created. It's used to finalize the graph.</li> <li>
<b><code translate="no" dir="ltr">hooks</code></b>: Optional list of <code translate="no" dir="ltr">SessionRunHook</code> objects.</li> <li>
<b><code translate="no" dir="ltr">chief_only_hooks</code></b>: list of <code translate="no" dir="ltr">SessionRunHook</code> objects. Activate these hooks if <code translate="no" dir="ltr">is_chief==True</code>, ignore otherwise.</li> <li>
<b><code translate="no" dir="ltr">save_checkpoint_secs</code></b>: The frequency, in seconds, that a checkpoint is saved using a default checkpoint saver. If both <code translate="no" dir="ltr">save_checkpoint_steps</code> and <code translate="no" dir="ltr">save_checkpoint_secs</code> are set to <code translate="no" dir="ltr">None</code>, then the default checkpoint saver isn't used. If both are provided, then only <code translate="no" dir="ltr">save_checkpoint_secs</code> is used. Default 600.</li> <li>
<b><code translate="no" dir="ltr">save_summaries_steps</code></b>: The frequency, in number of global steps, that the summaries are written to disk using a default summary saver. If both <code translate="no" dir="ltr">save_summaries_steps</code> and <code translate="no" dir="ltr">save_summaries_secs</code> are set to <code translate="no" dir="ltr">None</code>, then the default summary saver isn't used. Default 100.</li> <li>
<b><code translate="no" dir="ltr">save_summaries_secs</code></b>: The frequency, in secs, that the summaries are written to disk using a default summary saver. If both <code translate="no" dir="ltr">save_summaries_steps</code> and <code translate="no" dir="ltr">save_summaries_secs</code> are set to <code translate="no" dir="ltr">None</code>, then the default summary saver isn't used. Default not enabled.</li> <li>
<b><code translate="no" dir="ltr">config</code></b>: an instance of <a href="../configproto"><code translate="no" dir="ltr">tf.compat.v1.ConfigProto</code></a> proto used to configure the session. It's the <code translate="no" dir="ltr">config</code> argument of constructor of <a href="../session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a>.</li> <li>
<b><code translate="no" dir="ltr">stop_grace_period_secs</code></b>: Number of seconds given to threads to stop after <code translate="no" dir="ltr">close()</code> has been called.</li> <li>
<b><code translate="no" dir="ltr">log_step_count_steps</code></b>: The frequency, in number of global steps, that the global step/sec is logged.</li> <li>
<b><code translate="no" dir="ltr">max_wait_secs</code></b>: Maximum time workers should wait for the session to become available. This should be kept relatively short to help detect incorrect code, but sometimes may need to be increased if the chief takes a while to start up.</li> <li>
<b><code translate="no" dir="ltr">save_checkpoint_steps</code></b>: The frequency, in number of global steps, that a checkpoint is saved using a default checkpoint saver. If both <code translate="no" dir="ltr">save_checkpoint_steps</code> and <code translate="no" dir="ltr">save_checkpoint_secs</code> are set to <code translate="no" dir="ltr">None</code>, then the default checkpoint saver isn't used. If both are provided, then only <code translate="no" dir="ltr">save_checkpoint_secs</code> is used. Default not enabled.</li> <li>
<b><code translate="no" dir="ltr">summary_dir</code></b>: A string. Optional path to a directory where to save summaries. If None, checkpoint_dir is used instead.</li> <li>
<b><code translate="no" dir="ltr">save_graph_def</code></b>: Whether to save the GraphDef and MetaGraphDef to <code translate="no" dir="ltr">checkpoint_dir</code>. The GraphDef is saved after the session is created as <code translate="no" dir="ltr">graph.pbtxt</code>. MetaGraphDefs are saved out for every checkpoint as <code translate="no" dir="ltr">model.ckpt-*.meta</code>.</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">MonitoredSession</code> object.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/MonitoredTrainingSession" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/MonitoredTrainingSession</a>
  </p>
</div>
