<h1 class="devsite-page-title">tf.compat.v1.train.Supervisor</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.train.Supervisor"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="coord"> <meta itemprop="property" content="global_step"> <meta itemprop="property" content="init_feed_dict"> <meta itemprop="property" content="init_op"> <meta itemprop="property" content="is_chief"> <meta itemprop="property" content="ready_for_local_init_op"> <meta itemprop="property" content="ready_op"> <meta itemprop="property" content="save_model_secs"> <meta itemprop="property" content="save_path"> <meta itemprop="property" content="save_summaries_secs"> <meta itemprop="property" content="saver"> <meta itemprop="property" content="session_manager"> <meta itemprop="property" content="summary_op"> <meta itemprop="property" content="summary_writer"> <meta itemprop="property" content="Loop"> <meta itemprop="property" content="PrepareSession"> <meta itemprop="property" content="RequestStop"> <meta itemprop="property" content="ShouldStop"> <meta itemprop="property" content="StartQueueRunners"> <meta itemprop="property" content="StartStandardServices"> <meta itemprop="property" content="Stop"> <meta itemprop="property" content="StopOnException"> <meta itemprop="property" content="SummaryComputed"> <meta itemprop="property" content="WaitForStop"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="loop"> <meta itemprop="property" content="managed_session"> <meta itemprop="property" content="prepare_or_wait_for_session"> <meta itemprop="property" content="request_stop"> <meta itemprop="property" content="should_stop"> <meta itemprop="property" content="start_queue_runners"> <meta itemprop="property" content="start_standard_services"> <meta itemprop="property" content="stop"> <meta itemprop="property" content="stop_on_exception"> <meta itemprop="property" content="summary_computed"> <meta itemprop="property" content="wait_for_stop"> <meta itemprop="property" content="USE_DEFAULT"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L44-L1023">  View source on GitHub </a> </td>
</table>  <h2 id="class_supervisor">Class <code translate="no" dir="ltr">Supervisor</code>
</h2> <p>A training helper that checkpoints models and computes summaries.</p>  <p>This class is deprecated. Please use <a href="monitoredtrainingsession"><code translate="no" dir="ltr">tf.compat.v1.train.MonitoredTrainingSession</code></a> instead.</p> <p>The Supervisor is a small wrapper around a <code translate="no" dir="ltr">Coordinator</code>, a <code translate="no" dir="ltr">Saver</code>, and a <code translate="no" dir="ltr">SessionManager</code> that takes care of common needs of TensorFlow training programs.</p> <h4 id="use_for_a_single_program">Use for a single program</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">with tf.Graph().as_default():
  ...add operations to the graph...
  # Create a Supervisor that will checkpoint the model in '/tmp/mydir'.
  sv = Supervisor(logdir='/tmp/mydir')
  # Get a TensorFlow session managed by the supervisor.
  with sv.managed_session(FLAGS.master) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op&gt;)
</pre> <p>Within the <code translate="no" dir="ltr">with sv.managed_session()</code> block all variables in the graph have been initialized. In addition, a few services have been started to checkpoint the model and add summaries to the event log.</p> <p>If the program crashes and is restarted, the managed session automatically reinitialize variables from the most recent checkpoint.</p> <p>The supervisor is notified of any exception raised by one of the services. After an exception is raised, <code translate="no" dir="ltr">should_stop()</code> returns <code translate="no" dir="ltr">True</code>. In that case the training loop should also stop. This is why the training loop has to check for <code translate="no" dir="ltr">sv.should_stop()</code>.</p> <p>Exceptions that indicate that the training inputs have been exhausted, <a href="../../../errors/outofrangeerror"><code translate="no" dir="ltr">tf.errors.OutOfRangeError</code></a>, also cause <code translate="no" dir="ltr">sv.should_stop()</code> to return <code translate="no" dir="ltr">True</code> but are not re-raised from the <code translate="no" dir="ltr">with</code> block: they indicate a normal termination.</p> <h4 id="use_for_multiple_replicas">Use for multiple replicas</h4> <p>To train with replicas you deploy the same program in a <code translate="no" dir="ltr">Cluster</code>. One of the tasks must be identified as the <em>chief</em>: the task that handles initialization, checkpoints, summaries, and recovery. The other tasks depend on the <em>chief</em> for these services.</p> <p>The only change you have to do to the single program code is to indicate if the program is running as the <em>chief</em>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Choose a task as the chief. This could be based on server_def.task_index,
# or job_def.name, or job_def.tasks. It's entirely up to the end user.
# But there can be only one *chief*.
is_chief = (server_def.task_index == 0)
server = tf.distribute.Server(server_def)

with tf.Graph().as_default():
  ...add operations to the graph...
  # Create a Supervisor that uses log directory on a shared file system.
  # Indicate if you are the 'chief'
  sv = Supervisor(logdir='/shared_directory/...', is_chief=is_chief)
  # Get a Session in a TensorFlow server on the cluster.
  with sv.managed_session(server.target) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op&gt;)
</pre> <p>In the <em>chief</em> task, the <code translate="no" dir="ltr">Supervisor</code> works exactly as in the first example above. In the other tasks <code translate="no" dir="ltr">sv.managed_session()</code> waits for the Model to have been initialized before returning a session to the training code. The non-chief tasks depend on the chief task for initializing the model.</p> <p>If one of the tasks crashes and restarts, <code translate="no" dir="ltr">managed_session()</code> checks if the Model is initialized. If yes, it just creates a session and returns it to the training code that proceeds normally. If the model needs to be initialized, the chief task takes care of reinitializing it; the other tasks just wait for the model to have been initialized.</p> <p>NOTE: This modified program still works fine as a single program. The single program marks itself as the chief.</p> <h4 id="what_master_string_to_use">What <code translate="no" dir="ltr">master</code> string to use</h4> <p>Whether you are running on your machine or in the cluster you can use the following values for the --master flag:</p> <ul> <li><p>Specifying <code translate="no" dir="ltr">''</code> requests an in-process session that does not use RPC.</p></li> <li><p>Specifying <code translate="no" dir="ltr">'local'</code> requests a session that uses the RPC-based "Master interface" to run TensorFlow programs. See <code translate="no" dir="ltr">tf.train.Server.create_local_server</code> for details.</p></li> <li><p>Specifying <code translate="no" dir="ltr">'grpc://hostname:port'</code> requests a session that uses the RPC interface to a specific host, and also allows the in-process master to access remote tensorflow workers. Often, it is appropriate to pass <code translate="no" dir="ltr">server.target</code> (for some <a href="../../../distribute/server"><code translate="no" dir="ltr">tf.distribute.Server</code></a> named `server).</p></li> </ul> <h4 id="advanced_use">Advanced use</h4> <h5 id="launching_additional_services">Launching additional services</h5> <p><code translate="no" dir="ltr">managed_session()</code> launches the Checkpoint and Summary services (threads). If you need more services to run you can simply launch them in the block controlled by <code translate="no" dir="ltr">managed_session()</code>.</p> <p>Example: Start a thread to print losses. We want this thread to run every 60 seconds, so we launch it with <code translate="no" dir="ltr">sv.loop()</code>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">...
sv = Supervisor(logdir='/tmp/mydir')
with sv.managed_session(FLAGS.master) as sess:
  sv.loop(60, print_loss, (sess, ))
  while not sv.should_stop():
    sess.run(my_train_op)
</pre> <h5 id="launching_fewer_services">Launching fewer services</h5> <p><code translate="no" dir="ltr">managed_session()</code> launches the "summary" and "checkpoint" threads which use either the optionally <code translate="no" dir="ltr">summary_op</code> and <code translate="no" dir="ltr">saver</code> passed to the constructor, or default ones created automatically by the supervisor. If you want to run your own summary and checkpointing logic, disable these services by passing <code translate="no" dir="ltr">None</code> to the <code translate="no" dir="ltr">summary_op</code> and <code translate="no" dir="ltr">saver</code> parameters.</p> <p>Example: Create summaries manually every 100 steps in the chief.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Create a Supervisor with no automatic summaries.
sv = Supervisor(logdir='/tmp/mydir', is_chief=is_chief, summary_op=None)
# As summary_op was None, managed_session() does not start the
# summary thread.
with sv.managed_session(FLAGS.master) as sess:
  for step in xrange(1000000):
    if sv.should_stop():
      break
    if is_chief and step % 100 == 0:
      # Create the summary every 100 chief steps.
      sv.summary_computed(sess, sess.run(my_summary_op))
    else:
      # Train normally
      sess.run(my_train_op)
</pre> <h5 id="custom_model_initialization">Custom model initialization</h5> <p><code translate="no" dir="ltr">managed_session()</code> only supports initializing the model by running an <code translate="no" dir="ltr">init_op</code> or restoring from the latest checkpoint. If you have special initialization needs, see how to specify a <code translate="no" dir="ltr">local_init_op</code> when creating the supervisor. You can also use the <code translate="no" dir="ltr">SessionManager</code> directly to create a session and check if it could be initialized automatically.</p> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L207-L357">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    graph=None,
    ready_op=USE_DEFAULT,
    ready_for_local_init_op=USE_DEFAULT,
    is_chief=True,
    init_op=USE_DEFAULT,
    init_feed_dict=None,
    local_init_op=USE_DEFAULT,
    logdir=None,
    summary_op=USE_DEFAULT,
    saver=USE_DEFAULT,
    global_step=USE_DEFAULT,
    save_summaries_secs=120,
    save_model_secs=600,
    recovery_wait_secs=30,
    stop_grace_secs=120,
    checkpoint_basename='model.ckpt',
    session_manager=None,
    summary_writer=USE_DEFAULT,
    init_fn=None,
    local_init_run_options=None
)
</pre> <p>Create a <code translate="no" dir="ltr">Supervisor</code>. (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Please switch to tf.train.MonitoredTrainingSession</span></aside> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">graph</code></b>: A <code translate="no" dir="ltr">Graph</code>. The graph that the model will use. Defaults to the default <code translate="no" dir="ltr">Graph</code>. The supervisor may add operations to the graph before creating a session, but the graph should not be modified by the caller after passing it to the supervisor.</li> <li>
<b><code translate="no" dir="ltr">ready_op</code></b>: 1-D string <code translate="no" dir="ltr">Tensor</code>. This tensor is evaluated by supervisors in <code translate="no" dir="ltr">prepare_or_wait_for_session()</code> to check if the model is ready to use. The model is considered ready if it returns an empty array. Defaults to the tensor returned from <a href="../report_uninitialized_variables"><code translate="no" dir="ltr">tf.compat.v1.report_uninitialized_variables()</code></a> If <code translate="no" dir="ltr">None</code>, the model is not checked for readiness.</li> <li>
<b><code translate="no" dir="ltr">ready_for_local_init_op</code></b>: 1-D string <code translate="no" dir="ltr">Tensor</code>. This tensor is evaluated by supervisors in <code translate="no" dir="ltr">prepare_or_wait_for_session()</code> to check if the model is ready to run the local_init_op. The model is considered ready if it returns an empty array. Defaults to <code translate="no" dir="ltr">None</code>. If <code translate="no" dir="ltr">None</code>, the model is not checked for readiness before running local_init_op.</li> <li>
<b><code translate="no" dir="ltr">is_chief</code></b>: If True, create a chief supervisor in charge of initializing and restoring the model. If False, create a supervisor that relies on a chief supervisor for inits and restore.</li> <li>
<b><code translate="no" dir="ltr">init_op</code></b>: <code translate="no" dir="ltr">Operation</code>. Used by chief supervisors to initialize the model when it can not be recovered. Defaults to an <code translate="no" dir="ltr">Operation</code> that initializes all global variables. If <code translate="no" dir="ltr">None</code>, no initialization is done automatically unless you pass a value for <code translate="no" dir="ltr">init_fn</code>, see below.</li> <li>
<b><code translate="no" dir="ltr">init_feed_dict</code></b>: A dictionary that maps <code translate="no" dir="ltr">Tensor</code> objects to feed values. This feed dictionary will be used when <code translate="no" dir="ltr">init_op</code> is evaluated.</li> <li>
<b><code translate="no" dir="ltr">local_init_op</code></b>: <code translate="no" dir="ltr">Operation</code>. Used by all supervisors to run initializations that should run for every new supervisor instance. By default these are table initializers and initializers for local variables. If <code translate="no" dir="ltr">None</code>, no further per supervisor-instance initialization is done automatically.</li> <li>
<b><code translate="no" dir="ltr">logdir</code></b>: A string. Optional path to a directory where to checkpoint the model and log events for the visualizer. Used by chief supervisors. The directory will be created if it does not exist.</li> <li>
<b><code translate="no" dir="ltr">summary_op</code></b>: An <code translate="no" dir="ltr">Operation</code> that returns a Summary for the event logs. Used by chief supervisors if a <code translate="no" dir="ltr">logdir</code> was specified. Defaults to the operation returned from summary.merge_all(). If <code translate="no" dir="ltr">None</code>, summaries are not computed automatically.</li> <li>
<b><code translate="no" dir="ltr">saver</code></b>: A Saver object. Used by chief supervisors if a <code translate="no" dir="ltr">logdir</code> was specified. Defaults to the saved returned by Saver(). If <code translate="no" dir="ltr">None</code>, the model is not saved automatically.</li> <li>
<b><code translate="no" dir="ltr">global_step</code></b>: An integer Tensor of size 1 that counts steps. The value from 'global_step' is used in summaries and checkpoint filenames. Default to the op named 'global_step' in the graph if it exists, is of rank 1, size 1, and of type tf.int32 or tf.int64. If <code translate="no" dir="ltr">None</code> the global step is not recorded in summaries and checkpoint files. Used by chief supervisors if a <code translate="no" dir="ltr">logdir</code> was specified.</li> <li>
<b><code translate="no" dir="ltr">save_summaries_secs</code></b>: Number of seconds between the computation of summaries for the event log. Defaults to 120 seconds. Pass 0 to disable summaries.</li> <li>
<b><code translate="no" dir="ltr">save_model_secs</code></b>: Number of seconds between the creation of model checkpoints. Defaults to 600 seconds. Pass 0 to disable checkpoints.</li> <li>
<b><code translate="no" dir="ltr">recovery_wait_secs</code></b>: Number of seconds between checks that the model is ready. Used by supervisors when waiting for a chief supervisor to initialize or restore the model. Defaults to 30 seconds.</li> <li>
<b><code translate="no" dir="ltr">stop_grace_secs</code></b>: Grace period, in seconds, given to running threads to stop when <code translate="no" dir="ltr">stop()</code> is called. Defaults to 120 seconds.</li> <li>
<b><code translate="no" dir="ltr">checkpoint_basename</code></b>: The basename for checkpoint saving.</li> <li>
<b><code translate="no" dir="ltr">session_manager</code></b>: <code translate="no" dir="ltr">SessionManager</code>, which manages Session creation and recovery. If it is <code translate="no" dir="ltr">None</code>, a default <code translate="no" dir="ltr">SessionManager</code> will be created with the set of arguments passed in for backwards compatibility.</li> <li>
<b><code translate="no" dir="ltr">summary_writer</code></b>: <code translate="no" dir="ltr">SummaryWriter</code> to use or <code translate="no" dir="ltr">USE_DEFAULT</code>. Can be <code translate="no" dir="ltr">None</code> to indicate that no summaries should be written.</li> <li>
<b><code translate="no" dir="ltr">init_fn</code></b>: Optional callable used to initialize the model. Called after the optional <code translate="no" dir="ltr">init_op</code> is called. The callable must accept one argument, the session being initialized.</li> <li>
<b><code translate="no" dir="ltr">local_init_run_options</code></b>: RunOptions to be passed as the SessionManager local_init_run_options parameter.</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">Supervisor</code>.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility">Eager Compatibility</h4> <p><code translate="no" dir="ltr">Supervisor</code>s are not supported when eager execution is enabled.</p> <h2 id="properties">Properties</h2> <h3 id="coord"><code translate="no" dir="ltr">coord</code></h3> <p>Return the Coordinator used by the Supervisor.</p> <p>The Coordinator can be useful if you want to run multiple threads during your training.</p> <h4 id="returns_2">Returns:</h4> <p>A Coordinator object.</p> <h3 id="global_step"><code translate="no" dir="ltr">global_step</code></h3> <p>Return the global_step Tensor used by the supervisor.</p> <h4 id="returns_3">Returns:</h4> <p>An integer Tensor for the global_step.</p> <h3 id="init_feed_dict"><code translate="no" dir="ltr">init_feed_dict</code></h3> <p>Return the feed dictionary used when evaluating the <code translate="no" dir="ltr">init_op</code>.</p> <h4 id="returns_4">Returns:</h4> <p>A feed dictionary or <code translate="no" dir="ltr">None</code>.</p> <h3 id="init_op"><code translate="no" dir="ltr">init_op</code></h3> <p>Return the Init Op used by the supervisor.</p> <h4 id="returns_5">Returns:</h4> <p>An Op or <code translate="no" dir="ltr">None</code>.</p> <h3 id="is_chief"><code translate="no" dir="ltr">is_chief</code></h3> <p>Return True if this is a chief supervisor.</p> <h4 id="returns_6">Returns:</h4> <p>A bool.</p> <h3 id="ready_for_local_init_op"><code translate="no" dir="ltr">ready_for_local_init_op</code></h3> <h3 id="ready_op"><code translate="no" dir="ltr">ready_op</code></h3> <p>Return the Ready Op used by the supervisor.</p> <h4 id="returns_7">Returns:</h4> <p>An Op or <code translate="no" dir="ltr">None</code>.</p> <h3 id="save_model_secs"><code translate="no" dir="ltr">save_model_secs</code></h3> <p>Return the delay between checkpoints.</p> <h4 id="returns_8">Returns:</h4> <p>A timestamp.</p> <h3 id="save_path"><code translate="no" dir="ltr">save_path</code></h3> <p>Return the save path used by the supervisor.</p> <h4 id="returns_9">Returns:</h4> <p>A string.</p> <h3 id="save_summaries_secs"><code translate="no" dir="ltr">save_summaries_secs</code></h3> <p>Return the delay between summary computations.</p> <h4 id="returns_10">Returns:</h4> <p>A timestamp.</p> <h3 id="saver"><code translate="no" dir="ltr">saver</code></h3> <p>Return the Saver used by the supervisor.</p> <h4 id="returns_11">Returns:</h4> <p>A Saver object.</p> <h3 id="session_manager"><code translate="no" dir="ltr">session_manager</code></h3> <p>Return the SessionManager used by the Supervisor.</p> <h4 id="returns_12">Returns:</h4> <p>A SessionManager object.</p> <h3 id="summary_op"><code translate="no" dir="ltr">summary_op</code></h3> <p>Return the Summary Tensor used by the chief supervisor.</p> <h4 id="returns_13">Returns:</h4> <p>A string Tensor for the summary or <code translate="no" dir="ltr">None</code>.</p> <h3 id="summary_writer"><code translate="no" dir="ltr">summary_writer</code></h3> <p>Return the SummaryWriter used by the chief supervisor.</p> <h4 id="returns_14">Returns:</h4> <p>A SummaryWriter.</p> <h2 id="methods">Methods</h2> <h3 id="Loop"><code translate="no" dir="ltr">Loop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L782-L808">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">Loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</pre> <p>Start a LooperThread that calls a function periodically.</p> <p>If <code translate="no" dir="ltr">timer_interval_secs</code> is None the thread calls <code translate="no" dir="ltr">target(*args, **kwargs)</code> repeatedly. Otherwise it calls it every <code translate="no" dir="ltr">timer_interval_secs</code> seconds. The thread terminates when a stop is requested.</p> <p>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the <code translate="no" dir="ltr">stop()</code> method.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">timer_interval_secs</code></b>: Number. Time boundaries at which to call <code translate="no" dir="ltr">target</code>.</li> <li>
<b><code translate="no" dir="ltr">target</code></b>: A callable object.</li> <li>
<b><code translate="no" dir="ltr">args</code></b>: Optional arguments to pass to <code translate="no" dir="ltr">target</code> when calling it.</li> <li>
<b><code translate="no" dir="ltr">kwargs</code></b>: Optional keyword arguments to pass to <code translate="no" dir="ltr">target</code> when calling it.</li> </ul> <h4 id="returns_15">Returns:</h4> <p>The started thread.</p> <h3 id="PrepareSession"><code translate="no" dir="ltr">PrepareSession</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L690-L745">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">PrepareSession(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</pre> <p>Make sure the model is ready to be used.</p> <p>Create a session on 'master', recovering or initializing the model as needed, or wait for a session to be ready. If running as the chief and <code translate="no" dir="ltr">start_standard_service</code> is set to True, also call the session manager to start the standard services.</p> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code translate="no" dir="ltr">config</code></b>: Optional ConfigProto proto used to configure the session, which is passed as-is to create the session.</li> <li>
<b><code translate="no" dir="ltr">wait_for_checkpoint</code></b>: Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</li> <li>
<b><code translate="no" dir="ltr">max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li> <li>
<b><code translate="no" dir="ltr">start_standard_services</code></b>: Whether to start the standard services and the queue runners.</li> </ul> <h4 id="returns_16">Returns:</h4> <p>A Session object that can be used to drive the model.</p> <h3 id="RequestStop"><code translate="no" dir="ltr">RequestStop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L849-L859">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">RequestStop(ex=None)
</pre> <p>Request that the coordinator stop the threads.</p> <p>See <a href="../../../train/coordinator#request_stop"><code translate="no" dir="ltr">Coordinator.request_stop()</code></a>.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ex</code></b>: Optional <code translate="no" dir="ltr">Exception</code>, or Python <code translate="no" dir="ltr">exc_info</code> tuple as returned by <code translate="no" dir="ltr">sys.exc_info()</code>. If this is the first call to <code translate="no" dir="ltr">request_stop()</code> the corresponding exception is recorded and re-raised from <code translate="no" dir="ltr">join()</code>.</li> </ul> <h3 id="ShouldStop"><code translate="no" dir="ltr">ShouldStop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L861-L869">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">ShouldStop()
</pre> <p>Check if the coordinator was told to stop.</p> <p>See <a href="../../../train/coordinator#should_stop"><code translate="no" dir="ltr">Coordinator.should_stop()</code></a>.</p> <h4 id="returns_17">Returns:</h4> <p>True if the coordinator was told to stop, False otherwise.</p> <h3 id="StartQueueRunners"><code translate="no" dir="ltr">StartQueueRunners</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L747-L780">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">StartQueueRunners(
    sess,
    queue_runners=None
)
</pre> <p>Start threads for <code translate="no" dir="ltr">QueueRunners</code>.</p> <p>Note that the queue runners collected in the graph key <code translate="no" dir="ltr">QUEUE_RUNNERS</code> are already started automatically when you create a session with the supervisor, so unless you have non-collected queue runners to start you do not need to call this explicitly.</p> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A <code translate="no" dir="ltr">Session</code>.</li> <li>
<b><code translate="no" dir="ltr">queue_runners</code></b>: A list of <code translate="no" dir="ltr">QueueRunners</code>. If not specified, we'll use the list of queue runners gathered in the graph under the key <code translate="no" dir="ltr">GraphKeys.QUEUE_RUNNERS</code>.</li> </ul> <h4 id="returns_18">Returns:</h4> <p>The list of threads started for the <code translate="no" dir="ltr">QueueRunners</code>.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility_2">Eager Compatibility</h4> <p>Queues are not compatible with eager execution. To ingest data when eager execution is enabled, use the <a href="../../../data"><code translate="no" dir="ltr">tf.data</code></a> API.</p> <h3 id="StartStandardServices"><code translate="no" dir="ltr">StartStandardServices</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L638-L688">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">StartStandardServices(sess)
</pre> <p>Start the standard services for 'sess'.</p> <p>This starts services in the background. The services started depend on the parameters to the constructor and may include:</p> <ul> <li>A Summary thread computing summaries every save_summaries_secs.</li> <li>A Checkpoint thread saving the model every save_model_secs.</li> <li>A StepCounter thread measure step time.</li> </ul> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A Session.</li> </ul> <h4 id="returns_19">Returns:</h4> <p>A list of threads that are running the standard services. You can use the Supervisor's Coordinator to join these threads with: sv.coord.Join(<list of threads>)</list></p> <h4 id="raises_3">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If called with a non-chief Supervisor.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If not <code translate="no" dir="ltr">logdir</code> was passed to the constructor as the services need a log directory.</li> </ul> <h3 id="Stop"><code translate="no" dir="ltr">Stop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L810-L847">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">Stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</pre> <p>Stop the services and the coordinator.</p> <p>This does not close the session.</p> <h4 id="args_7">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">threads</code></b>: Optional list of threads to join with the coordinator. If <code translate="no" dir="ltr">None</code>, defaults to the threads running the standard services, the threads started for <code translate="no" dir="ltr">QueueRunners</code>, and the threads started by the <code translate="no" dir="ltr">loop()</code> method. To wait on additional threads, pass the list in this parameter.</li> <li>
<b><code translate="no" dir="ltr">close_summary_writer</code></b>: Whether to close the <code translate="no" dir="ltr">summary_writer</code>. Defaults to <code translate="no" dir="ltr">True</code> if the summary writer was created by the supervisor, <code translate="no" dir="ltr">False</code> otherwise.</li> <li>
<b><code translate="no" dir="ltr">ignore_live_threads</code></b>: If <code translate="no" dir="ltr">True</code> ignores threads that remain running after a grace period when joining threads via the coordinator, instead of raising a RuntimeError.</li> </ul> <h3 id="StopOnException"><code translate="no" dir="ltr">StopOnException</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L871-L879">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">StopOnException()
</pre> <p>Context handler to stop the supervisor when an exception is raised.</p> <p>See <a href="../../../train/coordinator#stop_on_exception"><code translate="no" dir="ltr">Coordinator.stop_on_exception()</code></a>.</p> <h4 id="returns_20">Returns:</h4> <p>A context handler.</p> <h3 id="SummaryComputed"><code translate="no" dir="ltr">SummaryComputed</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L885-L902">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">SummaryComputed(
    sess,
    summary,
    global_step=None
)
</pre> <p>Indicate that a summary was computed.</p> <h4 id="args_8">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A <code translate="no" dir="ltr">Session</code> object.</li> <li>
<b><code translate="no" dir="ltr">summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li> <li>
<b><code translate="no" dir="ltr">global_step</code></b>: Int. global step this summary is associated with. If <code translate="no" dir="ltr">None</code>, it will try to fetch the current step.</li> </ul> <h4 id="raises_4">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if 'summary' is not a Summary proto or a string.</li> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: if the Supervisor was created without a <code translate="no" dir="ltr">logdir</code>.</li> </ul> <h3 id="WaitForStop"><code translate="no" dir="ltr">WaitForStop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L881-L883">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">WaitForStop()
</pre> <p>Block waiting for the coordinator to stop.</p> <h3 id="loop"><code translate="no" dir="ltr">loop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L782-L808">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</pre> <p>Start a LooperThread that calls a function periodically.</p> <p>If <code translate="no" dir="ltr">timer_interval_secs</code> is None the thread calls <code translate="no" dir="ltr">target(*args, **kwargs)</code> repeatedly. Otherwise it calls it every <code translate="no" dir="ltr">timer_interval_secs</code> seconds. The thread terminates when a stop is requested.</p> <p>The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the <code translate="no" dir="ltr">stop()</code> method.</p> <h4 id="args_9">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">timer_interval_secs</code></b>: Number. Time boundaries at which to call <code translate="no" dir="ltr">target</code>.</li> <li>
<b><code translate="no" dir="ltr">target</code></b>: A callable object.</li> <li>
<b><code translate="no" dir="ltr">args</code></b>: Optional arguments to pass to <code translate="no" dir="ltr">target</code> when calling it.</li> <li>
<b><code translate="no" dir="ltr">kwargs</code></b>: Optional keyword arguments to pass to <code translate="no" dir="ltr">target</code> when calling it.</li> </ul> <h4 id="returns_21">Returns:</h4> <p>The started thread.</p> <h3 id="managed_session"><code translate="no" dir="ltr">managed_session</code></h3> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">managed_session(
    *args,
    **kwds
)
</pre> <p>Returns a context manager for a managed session.</p> <p>This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the <code translate="no" dir="ltr">with</code> block or from the services and stops the supervisor as needed.</p> <p>The context manager is typically used as follows:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def train():
  sv = tf.compat.v1.train.Supervisor(...)
  with sv.managed_session(&lt;master&gt;) as sess:
    for step in xrange(..):
      if sv.should_stop():
        break
      sess.run(&lt;my training op&gt;)
      ...do other things needed at each training step...
</pre> <p>An exception raised from the <code translate="no" dir="ltr">with</code> block or one of the service threads is raised again when the block exits. This is done after stopping all threads and closing the session. For example, an <code translate="no" dir="ltr">AbortedError</code> exception, raised in case of preemption of one of the workers in a distributed model, is raised again when the block exits.</p> <p>If you want to retry the training loop in case of preemption you can do it as follows:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def main(...):
  while True
    try:
      train()
    except tf.errors.Aborted:
      pass
</pre> <p>As a special case, exceptions used for control flow, such as <code translate="no" dir="ltr">OutOfRangeError</code> which reports that input queues are exhausted, are not raised again from the <code translate="no" dir="ltr">with</code> block: they indicate a clean termination of the training loop and are considered normal termination.</p> <h4 id="args_10">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code translate="no" dir="ltr">config</code></b>: Optional <code translate="no" dir="ltr">ConfigProto</code> proto used to configure the session. Passed as-is to create the session.</li> <li>
<b><code translate="no" dir="ltr">start_standard_services</code></b>: Whether to start the standard services, such as checkpoint, summary and step counter.</li> <li>
<b><code translate="no" dir="ltr">close_summary_writer</code></b>: Whether to close the summary writer when closing the session. Defaults to True.</li> </ul> <h4 id="returns_22">Returns:</h4> <p>A context manager that yields a <code translate="no" dir="ltr">Session</code> restored from the latest checkpoint or initialized from scratch if not checkpoint exists. The session is closed when the <code translate="no" dir="ltr">with</code> block exits.</p> <h3 id="prepare_or_wait_for_session"><code translate="no" dir="ltr">prepare_or_wait_for_session</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L690-L745">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">prepare_or_wait_for_session(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</pre> <p>Make sure the model is ready to be used.</p> <p>Create a session on 'master', recovering or initializing the model as needed, or wait for a session to be ready. If running as the chief and <code translate="no" dir="ltr">start_standard_service</code> is set to True, also call the session manager to start the standard services.</p> <h4 id="args_11">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">master</code></b>: name of the TensorFlow master to use. See the <a href="../session"><code translate="no" dir="ltr">tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li> <li>
<b><code translate="no" dir="ltr">config</code></b>: Optional ConfigProto proto used to configure the session, which is passed as-is to create the session.</li> <li>
<b><code translate="no" dir="ltr">wait_for_checkpoint</code></b>: Whether we should wait for the availability of a checkpoint before creating Session. Defaults to False.</li> <li>
<b><code translate="no" dir="ltr">max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li> <li>
<b><code translate="no" dir="ltr">start_standard_services</code></b>: Whether to start the standard services and the queue runners.</li> </ul> <h4 id="returns_23">Returns:</h4> <p>A Session object that can be used to drive the model.</p> <h3 id="request_stop"><code translate="no" dir="ltr">request_stop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L849-L859">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">request_stop(ex=None)
</pre> <p>Request that the coordinator stop the threads.</p> <p>See <a href="../../../train/coordinator#request_stop"><code translate="no" dir="ltr">Coordinator.request_stop()</code></a>.</p> <h4 id="args_12">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ex</code></b>: Optional <code translate="no" dir="ltr">Exception</code>, or Python <code translate="no" dir="ltr">exc_info</code> tuple as returned by <code translate="no" dir="ltr">sys.exc_info()</code>. If this is the first call to <code translate="no" dir="ltr">request_stop()</code> the corresponding exception is recorded and re-raised from <code translate="no" dir="ltr">join()</code>.</li> </ul> <h3 id="should_stop"><code translate="no" dir="ltr">should_stop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L861-L869">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">should_stop()
</pre> <p>Check if the coordinator was told to stop.</p> <p>See <a href="../../../train/coordinator#should_stop"><code translate="no" dir="ltr">Coordinator.should_stop()</code></a>.</p> <h4 id="returns_24">Returns:</h4> <p>True if the coordinator was told to stop, False otherwise.</p> <h3 id="start_queue_runners"><code translate="no" dir="ltr">start_queue_runners</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L747-L780">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">start_queue_runners(
    sess,
    queue_runners=None
)
</pre> <p>Start threads for <code translate="no" dir="ltr">QueueRunners</code>.</p> <p>Note that the queue runners collected in the graph key <code translate="no" dir="ltr">QUEUE_RUNNERS</code> are already started automatically when you create a session with the supervisor, so unless you have non-collected queue runners to start you do not need to call this explicitly.</p> <h4 id="args_13">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A <code translate="no" dir="ltr">Session</code>.</li> <li>
<b><code translate="no" dir="ltr">queue_runners</code></b>: A list of <code translate="no" dir="ltr">QueueRunners</code>. If not specified, we'll use the list of queue runners gathered in the graph under the key <code translate="no" dir="ltr">GraphKeys.QUEUE_RUNNERS</code>.</li> </ul> <h4 id="returns_25">Returns:</h4> <p>The list of threads started for the <code translate="no" dir="ltr">QueueRunners</code>.</p> <h4 id="raises_5">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If called with eager execution enabled.</li> </ul> <h4 id="eager_compatibility_3">Eager Compatibility</h4> <p>Queues are not compatible with eager execution. To ingest data when eager execution is enabled, use the <a href="../../../data"><code translate="no" dir="ltr">tf.data</code></a> API.</p> <h3 id="start_standard_services"><code translate="no" dir="ltr">start_standard_services</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L638-L688">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">start_standard_services(sess)
</pre> <p>Start the standard services for 'sess'.</p> <p>This starts services in the background. The services started depend on the parameters to the constructor and may include:</p> <ul> <li>A Summary thread computing summaries every save_summaries_secs.</li> <li>A Checkpoint thread saving the model every save_model_secs.</li> <li>A StepCounter thread measure step time.</li> </ul> <h4 id="args_14">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A Session.</li> </ul> <h4 id="returns_26">Returns:</h4> <p>A list of threads that are running the standard services. You can use the Supervisor's Coordinator to join these threads with: sv.coord.Join(<list of threads>)</list></p> <h4 id="raises_6">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: If called with a non-chief Supervisor.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If not <code translate="no" dir="ltr">logdir</code> was passed to the constructor as the services need a log directory.</li> </ul> <h3 id="stop"><code translate="no" dir="ltr">stop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L810-L847">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</pre> <p>Stop the services and the coordinator.</p> <p>This does not close the session.</p> <h4 id="args_15">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">threads</code></b>: Optional list of threads to join with the coordinator. If <code translate="no" dir="ltr">None</code>, defaults to the threads running the standard services, the threads started for <code translate="no" dir="ltr">QueueRunners</code>, and the threads started by the <code translate="no" dir="ltr">loop()</code> method. To wait on additional threads, pass the list in this parameter.</li> <li>
<b><code translate="no" dir="ltr">close_summary_writer</code></b>: Whether to close the <code translate="no" dir="ltr">summary_writer</code>. Defaults to <code translate="no" dir="ltr">True</code> if the summary writer was created by the supervisor, <code translate="no" dir="ltr">False</code> otherwise.</li> <li>
<b><code translate="no" dir="ltr">ignore_live_threads</code></b>: If <code translate="no" dir="ltr">True</code> ignores threads that remain running after a grace period when joining threads via the coordinator, instead of raising a RuntimeError.</li> </ul> <h3 id="stop_on_exception"><code translate="no" dir="ltr">stop_on_exception</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L871-L879">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">stop_on_exception()
</pre> <p>Context handler to stop the supervisor when an exception is raised.</p> <p>See <a href="../../../train/coordinator#stop_on_exception"><code translate="no" dir="ltr">Coordinator.stop_on_exception()</code></a>.</p> <h4 id="returns_27">Returns:</h4> <p>A context handler.</p> <h3 id="summary_computed"><code translate="no" dir="ltr">summary_computed</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L885-L902">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">summary_computed(
    sess,
    summary,
    global_step=None
)
</pre> <p>Indicate that a summary was computed.</p> <h4 id="args_16">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sess</code></b>: A <code translate="no" dir="ltr">Session</code> object.</li> <li>
<b><code translate="no" dir="ltr">summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li> <li>
<b><code translate="no" dir="ltr">global_step</code></b>: Int. global step this summary is associated with. If <code translate="no" dir="ltr">None</code>, it will try to fetch the current step.</li> </ul> <h4 id="raises_7">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">TypeError</code></b>: if 'summary' is not a Summary proto or a string.</li> <li>
<b><code translate="no" dir="ltr">RuntimeError</code></b>: if the Supervisor was created without a <code translate="no" dir="ltr">logdir</code>.</li> </ul> <h3 id="wait_for_stop"><code translate="no" dir="ltr">wait_for_stop</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/supervisor.py#L881-L883">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">wait_for_stop()
</pre> <p>Block waiting for the coordinator to stop.</p> <h2 id="class_members">Class Members</h2> <ul> <li>
<code translate="no" dir="ltr">USE_DEFAULT = 0</code> 
</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/Supervisor" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/Supervisor</a>
  </p>
</div>
