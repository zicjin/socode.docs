<h1 class="devsite-page-title">tf.compat.v1.train.sdca_optimizer</h1>    <devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax>  <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.train.sdca_optimizer"> <meta itemprop="path" content="Stable"> </div>    <p>Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.train.sdca_optimizer(
    sparse_example_indices,
    sparse_feature_indices,
    sparse_feature_values,
    dense_features,
    example_weights,
    example_labels,
    sparse_indices,
    sparse_weights,
    dense_weights,
    example_state_data,
    loss_type,
    l1,
    l2,
    num_loss_partitions,
    num_inner_iterations,
    adaptative=True,
    name=None
)
</pre>  <p>linear models with L1 + L2 regularization. As global optimization objective is strongly-convex, the optimizer optimizes the dual objective at each step. The optimizer applies each update one example at a time. Examples are sampled uniformly, and the optimizer is learning rate free and enjoys linear convergence rate.</p> <p><a href="http://arxiv.org/pdf/1211.2717v1.pdf">Proximal Stochastic Dual Coordinate Ascent</a>.<br> Shai Shalev-Shwartz, Tong Zhang. 2012</p> <div> $$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$ </div> <p><a href="http://arxiv.org/abs/1502.03508">Adding vs. Averaging in Distributed Primal-Dual Optimization</a>.<br> Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richtarik, Martin Takac. 2015</p> <p><a href="https://arxiv.org/abs/1502.08053">Stochastic Dual Coordinate Ascent with Adaptive Probabilities</a>.<br> Dominik Csiba, Zheng Qu, Peter Richtarik. 2015</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sparse_example_indices</code></b>: A list of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">int64</code>. a list of vectors which contain example indices.</li> <li>
<b><code translate="no" dir="ltr">sparse_feature_indices</code></b>: A list with the same length as <code translate="no" dir="ltr">sparse_example_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">int64</code>. a list of vectors which contain feature indices.</li> <li>
<b><code translate="no" dir="ltr">sparse_feature_values</code></b>: A list of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>. a list of vectors which contains feature value associated with each feature group.</li> <li>
<b><code translate="no" dir="ltr">dense_features</code></b>: A list of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>. a list of matrices which contains the dense feature values.</li> <li>
<b><code translate="no" dir="ltr">example_weights</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. a vector which contains the weight associated with each example.</li> <li>
<b><code translate="no" dir="ltr">example_labels</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. a vector which contains the label/target associated with each example.</li> <li>
<b><code translate="no" dir="ltr">sparse_indices</code></b>: A list with the same length as <code translate="no" dir="ltr">sparse_example_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">int64</code>. a list of vectors where each value is the indices which has corresponding weights in sparse_weights. This field maybe omitted for the dense approach.</li> <li>
<b><code translate="no" dir="ltr">sparse_weights</code></b>: A list with the same length as <code translate="no" dir="ltr">sparse_example_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>. a list of vectors where each value is the weight associated with a sparse feature group.</li> <li>
<b><code translate="no" dir="ltr">dense_weights</code></b>: A list with the same length as <code translate="no" dir="ltr">dense_features</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>. a list of vectors where the values are the weights associated with a dense feature group.</li> <li>
<b><code translate="no" dir="ltr">example_state_data</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. a list of vectors containing the example state data.</li> <li>
<b><code translate="no" dir="ltr">loss_type</code></b>: A <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"</code>. Type of the primal loss. Currently SdcaSolver supports logistic, squared and hinge losses.</li> <li>
<b><code translate="no" dir="ltr">l1</code></b>: A <code translate="no" dir="ltr">float</code>. Symmetric l1 regularization strength.</li> <li>
<b><code translate="no" dir="ltr">l2</code></b>: A <code translate="no" dir="ltr">float</code>. Symmetric l2 regularization strength.</li> <li>
<b><code translate="no" dir="ltr">num_loss_partitions</code></b>: An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. Number of partitions of the global loss function.</li> <li>
<b><code translate="no" dir="ltr">num_inner_iterations</code></b>: An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. Number of iterations per mini-batch.</li> <li>
<b><code translate="no" dir="ltr">adaptative</code></b>: An optional <code translate="no" dir="ltr">bool</code>. Defaults to <code translate="no" dir="ltr">True</code>. Whether to use Adaptive SDCA for the inner loop.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>A tuple of <code translate="no" dir="ltr">Tensor</code> objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).</p> <ul> <li>
<b><code translate="no" dir="ltr">out_example_state_data</code></b>: A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>.</li> <li>
<b><code translate="no" dir="ltr">out_delta_sparse_weights</code></b>: A list with the same length as <code translate="no" dir="ltr">sparse_example_indices</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>.</li> <li>
<b><code translate="no" dir="ltr">out_delta_dense_weights</code></b>: A list with the same length as <code translate="no" dir="ltr">dense_features</code> of <code translate="no" dir="ltr">Tensor</code> objects with type <code translate="no" dir="ltr">float32</code>.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/sdca_optimizer" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/sdca_optimizer</a>
  </p>
</div>
