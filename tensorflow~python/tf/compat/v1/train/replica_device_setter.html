<h1 class="devsite-page-title">tf.compat.v1.train.replica_device_setter</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.train.replica_device_setter"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/device_setter.py#L136-L231">  View source on GitHub </a> </td>
</table>  <p>Return a <code translate="no" dir="ltr">device function</code> to use when building a Graph for replicas.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.train.replica_device_setter(
    ps_tasks=0,
    ps_device='/job:ps',
    worker_device='/job:worker',
    merge_devices=True,
    cluster=None,
    ps_ops=None,
    ps_strategy=None
)
</pre>  <p>Device Functions are used in <code translate="no" dir="ltr">with tf.device(device_function):</code> statement to automatically assign devices to <code translate="no" dir="ltr">Operation</code> objects as they are constructed, Device constraints are added from the inner-most context first, working outwards. The merging behavior adds constraints to fields that are yet unset by a more inner context. Currently the fields are (job, task, cpu/gpu).</p> <p>If <code translate="no" dir="ltr">cluster</code> is <code translate="no" dir="ltr">None</code>, and <code translate="no" dir="ltr">ps_tasks</code> is 0, the returned function is a no-op. Otherwise, the value of <code translate="no" dir="ltr">ps_tasks</code> is derived from <code translate="no" dir="ltr">cluster</code>.</p> <p>By default, only Variable ops are placed on ps tasks, and the placement strategy is round-robin over all ps tasks. A custom <code translate="no" dir="ltr">ps_strategy</code> may be used to do more intelligent placement, such as <code translate="no" dir="ltr">tf.contrib.training.GreedyLoadBalancingStrategy</code>.</p> <p>For example,</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># To build a cluster with two ps jobs on hosts ps0 and ps1, and 3 worker
# jobs on hosts worker0, worker1 and worker2.
cluster_spec = {
    "ps": ["ps0:2222", "ps1:2222"],
    "worker": ["worker0:2222", "worker1:2222", "worker2:2222"]}
with
tf.device(tf.compat.v1.train.replica_device_setter(cluster=cluster_spec)):
  # Build your graph
  v1 = tf.Variable(...)  # assigned to /job:ps/task:0
  v2 = tf.Variable(...)  # assigned to /job:ps/task:1
  v3 = tf.Variable(...)  # assigned to /job:ps/task:0
# Run compute
</pre> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ps_tasks</code></b>: Number of tasks in the <code translate="no" dir="ltr">ps</code> job. Ignored if <code translate="no" dir="ltr">cluster</code> is provided.</li> <li>
<b><code translate="no" dir="ltr">ps_device</code></b>: String. Device of the <code translate="no" dir="ltr">ps</code> job. If empty no <code translate="no" dir="ltr">ps</code> job is used. Defaults to <code translate="no" dir="ltr">ps</code>.</li> <li>
<b><code translate="no" dir="ltr">worker_device</code></b>: String. Device of the <code translate="no" dir="ltr">worker</code> job. If empty no <code translate="no" dir="ltr">worker</code> job is used.</li> <li>
<b><code translate="no" dir="ltr">merge_devices</code></b>: <code translate="no" dir="ltr">Boolean</code>. If <code translate="no" dir="ltr">True</code>, merges or only sets a device if the device constraint is completely unset. merges device specification rather than overriding them.</li> <li>
<b><code translate="no" dir="ltr">cluster</code></b>: <code translate="no" dir="ltr">ClusterDef</code> proto or <code translate="no" dir="ltr">ClusterSpec</code>.</li> <li>
<b><code translate="no" dir="ltr">ps_ops</code></b>: List of strings representing <code translate="no" dir="ltr">Operation</code> types that need to be placed on <code translate="no" dir="ltr">ps</code> devices. If <code translate="no" dir="ltr">None</code>, defaults to <code translate="no" dir="ltr">STANDARD_PS_OPS</code>.</li> <li>
<b><code translate="no" dir="ltr">ps_strategy</code></b>: A callable invoked for every ps <code translate="no" dir="ltr">Operation</code> (i.e. matched by <code translate="no" dir="ltr">ps_ops</code>), that takes the <code translate="no" dir="ltr">Operation</code> and returns the ps task index to use. If <code translate="no" dir="ltr">None</code>, defaults to a round-robin strategy across all <code translate="no" dir="ltr">ps</code> devices.</li> </ul> <h4 id="returns">Returns:</h4> <p>A function to pass to <a href="../../../device"><code translate="no" dir="ltr">tf.device()</code></a>.</p> <h4 id="raises">Raises:</h4> <p>TypeError if <code translate="no" dir="ltr">cluster</code> is not a dictionary or <code translate="no" dir="ltr">ClusterDef</code> protocol buffer, or if <code translate="no" dir="ltr">ps_strategy</code> is provided but not a callable.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/replica_device_setter" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/replica_device_setter</a>
  </p>
</div>
