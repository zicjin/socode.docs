<h1 class="devsite-page-title">tf.compat.v1.uniform_unit_scaling_initializer</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.uniform_unit_scaling_initializer"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__call__"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="from_config"> <meta itemprop="property" content="get_config"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/init_ops.py#L371-L431">  View source on GitHub </a> </td>
</table>  <h2 id="class_uniform_unit_scaling_initializer">Class <code translate="no" dir="ltr">uniform_unit_scaling_initializer</code>
</h2> <p>Initializer that generates tensors without scaling variance.</p> <p>Inherits From: <a href="keras/initializers/initializer"><code translate="no" dir="ltr">Initializer</code></a></p>  <p>When initializing a deep network, it is in principle advantageous to keep the scale of the input variance constant, so it does not explode or diminish by reaching the final layer. If the input is <code translate="no" dir="ltr">x</code> and the operation <code translate="no" dir="ltr">x * W</code>, and we want to initialize <code translate="no" dir="ltr">W</code> uniformly at random, we need to pick <code translate="no" dir="ltr">W</code> from</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]
</pre> <p>to keep the scale intact, where <code translate="no" dir="ltr">dim = W.shape[0]</code> (the size of the input). A similar calculation for convolutional networks gives an analogous result with <code translate="no" dir="ltr">dim</code> equal to the product of the first 3 dimensions. When nonlinearities are present, we need to multiply this by a constant <code translate="no" dir="ltr">factor</code>. See (Sussillo et al., 2014) for deeper motivation, experiments and the calculation of constants. In section 2.3 there, the constants were numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">factor</code></b>: Float. A multiplicative factor by which the values will be scaled.</li> <li>
<b><code translate="no" dir="ltr">seed</code></b>: A Python integer. Used to create random seeds. See <a href="set_random_seed"><code translate="no" dir="ltr">tf.compat.v1.set_random_seed</code></a> for behavior.</li> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: Default data type, used if no <code translate="no" dir="ltr">dtype</code> argument is provided when calling the initializer. Only floating point types are supported.</li> </ul> <h4 id="references">References:</h4> <p><a href="https://arxiv.org/abs/1412.6558">Sussillo et al., 2014</a> (<a href="http://arxiv.org/pdf/1412.6558.pdf">pdf</a>)</p> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/init_ops.py#L400-L409">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    factor=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
</pre> <p>DEPRECATED FUNCTION (deprecated arguments)</p> <aside class="warning"><strong>Warning:</strong><span> SOME ARGUMENTS ARE DEPRECATED: <code translate="no" dir="ltr">(dtype)</code>. They will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor</span></aside><aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.</span></aside> <h2 id="methods">Methods</h2> <h3 id="__call__"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/init_ops.py#L411-L428">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__call__(
    shape,
    dtype=None,
    partition_info=None
)
</pre> <p>Returns a tensor object initialized as specified by the initializer.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">shape</code></b>: Shape of the tensor.</li> <li>
<b><code translate="no" dir="ltr">dtype</code></b>: Optional dtype of the tensor. If not provided use the initializer dtype.</li> <li>
<b><code translate="no" dir="ltr">partition_info</code></b>: Optional information about the possible partitioning of a tensor.</li> </ul> <h3 id="from_config"><code translate="no" dir="ltr">from_config</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/init_ops.py#L78-L97">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">from_config(
    cls,
    config
)
</pre> <p>Instantiates an initializer from a configuration dictionary.</p> <h4 id="example">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">initializer = RandomUniform(-1, 1)
config = initializer.get_config()
initializer = RandomUniform.from_config(config)
</pre> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">config</code></b>: A Python dictionary. It will typically be the output of <code translate="no" dir="ltr">get_config</code>.</li> </ul> <h4 id="returns">Returns:</h4> <p>An Initializer instance.</p> <h3 id="get_config"><code translate="no" dir="ltr">get_config</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/init_ops.py#L430-L431">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">get_config()
</pre> <p>Returns the configuration of the initializer as a JSON-serializable dict.</p> <h4 id="returns_2">Returns:</h4> <p>A JSON-serializable Python dict.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="uniform_unit_scaling_initializer"><code translate="no" dir="ltr">tf.compat.v1.initializers.uniform_unit_scaling</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/uniform_unit_scaling_initializer" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/uniform_unit_scaling_initializer</a>
  </p>
</div>
