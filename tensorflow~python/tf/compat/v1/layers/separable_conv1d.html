<h1 class="devsite-page-title">tf.compat.v1.layers.separable_conv1d</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.layers.separable_conv1d"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/layers/convolutional.py#L854-L971">  View source on GitHub </a> </td>
</table>  <p>Functional interface for the depthwise separable 1D convolution layer. (deprecated)</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.layers.separable_conv1d(
    inputs,
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer=None,
    pointwise_initializer=None,
    bias_initializer=tf.zeros_initializer(),
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
</pre>  <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use <a href="../../../keras/layers/separableconv1d"><code translate="no" dir="ltr">tf.keras.layers.SeparableConv1D</code></a> instead.</span></aside> <p>This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If <code translate="no" dir="ltr">use_bias</code> is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output.</p> <h4 id="arguments">Arguments:</h4> <ul> <li>
<b><code translate="no" dir="ltr">inputs</code></b>: Input tensor.</li> <li>
<b><code translate="no" dir="ltr">filters</code></b>: Integer, the dimensionality of the output space (i.e. the number of filters in the convolution).</li> <li>
<b><code translate="no" dir="ltr">kernel_size</code></b>: A single integer specifying the spatial dimensions of the filters.</li> <li>
<b><code translate="no" dir="ltr">strides</code></b>: A single integer specifying the strides of the convolution. Specifying any <code translate="no" dir="ltr">stride</code> value != 1 is incompatible with specifying any <code translate="no" dir="ltr">dilation_rate</code> value != 1.</li> <li>
<b><code translate="no" dir="ltr">padding</code></b>: One of <code translate="no" dir="ltr">"valid"</code> or <code translate="no" dir="ltr">"same"</code> (case-insensitive).</li> <li>
<b><code translate="no" dir="ltr">data_format</code></b>: A string, one of <code translate="no" dir="ltr">channels_last</code> (default) or <code translate="no" dir="ltr">channels_first</code>. The ordering of the dimensions in the inputs. <code translate="no" dir="ltr">channels_last</code> corresponds to inputs with shape <code translate="no" dir="ltr">(batch, length, channels)</code> while <code translate="no" dir="ltr">channels_first</code> corresponds to inputs with shape <code translate="no" dir="ltr">(batch, channels, length)</code>.</li> <li>
<b><code translate="no" dir="ltr">dilation_rate</code></b>: A single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any <code translate="no" dir="ltr">dilation_rate</code> value != 1 is incompatible with specifying any stride value != 1.</li> <li>
<b><code translate="no" dir="ltr">depth_multiplier</code></b>: The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to <code translate="no" dir="ltr">num_filters_in * depth_multiplier</code>.</li> <li>
<b><code translate="no" dir="ltr">activation</code></b>: Activation function. Set it to None to maintain a linear activation.</li> <li>
<b><code translate="no" dir="ltr">use_bias</code></b>: Boolean, whether the layer uses a bias.</li> <li>
<b><code translate="no" dir="ltr">depthwise_initializer</code></b>: An initializer for the depthwise convolution kernel.</li> <li>
<b><code translate="no" dir="ltr">pointwise_initializer</code></b>: An initializer for the pointwise convolution kernel.</li> <li>
<b><code translate="no" dir="ltr">bias_initializer</code></b>: An initializer for the bias vector. If None, the default initializer will be used.</li> <li>
<b><code translate="no" dir="ltr">depthwise_regularizer</code></b>: Optional regularizer for the depthwise convolution kernel.</li> <li>
<b><code translate="no" dir="ltr">pointwise_regularizer</code></b>: Optional regularizer for the pointwise convolution kernel.</li> <li>
<b><code translate="no" dir="ltr">bias_regularizer</code></b>: Optional regularizer for the bias vector.</li> <li>
<b><code translate="no" dir="ltr">activity_regularizer</code></b>: Optional regularizer function for the output.</li> <li>
<b><code translate="no" dir="ltr">depthwise_constraint</code></b>: Optional projection function to be applied to the depthwise kernel after being updated by an <code translate="no" dir="ltr">Optimizer</code> (e.g. used for norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training.</li> <li>
<b><code translate="no" dir="ltr">pointwise_constraint</code></b>: Optional projection function to be applied to the pointwise kernel after being updated by an <code translate="no" dir="ltr">Optimizer</code>.</li> <li>
<b><code translate="no" dir="ltr">bias_constraint</code></b>: Optional projection function to be applied to the bias after being updated by an <code translate="no" dir="ltr">Optimizer</code>.</li> <li>
<b><code translate="no" dir="ltr">trainable</code></b>: Boolean, if <code translate="no" dir="ltr">True</code> also add variables to the graph collection <code translate="no" dir="ltr">GraphKeys.TRAINABLE_VARIABLES</code> (see <a href="../../../variable"><code translate="no" dir="ltr">tf.Variable</code></a>).</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A string, the name of the layer.</li> <li>
<b><code translate="no" dir="ltr">reuse</code></b>: Boolean, whether to reuse the weights of a previous layer by the same name.</li> </ul> <h4 id="returns">Returns:</h4> <p>Output tensor.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if eager execution is enabled.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/separable_conv1d" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/separable_conv1d</a>
  </p>
</div>
