<h1 class="devsite-page-title">tf.compat.v1.batch_scatter_update</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.batch_scatter_update"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/state_ops.py#L818-L915">  View source on GitHub </a> </td>
</table>  <p>Generalization of <a href="scatter_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> to axis different than 0. (deprecated)</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.batch_scatter_update(
    ref,
    indices,
    updates,
    use_locking=True,
    name=None
)
</pre>  <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed after 2018-11-29. Instructions for updating: Use the batch_scatter_update method of Variable instead.</span></aside> <p>Analogous to <code translate="no" dir="ltr">batch_gather</code>. This assumes that <code translate="no" dir="ltr">ref</code>, <code translate="no" dir="ltr">indices</code> and <code translate="no" dir="ltr">updates</code> have a series of leading dimensions that are the same for all of them, and the updates are performed on the last dimension of indices. In other words, the dimensions should be the following:</p> <p><code translate="no" dir="ltr">num_prefix_dims = indices.ndims - 1</code> <code translate="no" dir="ltr">batch_dim = num_prefix_dims + 1</code> <code translate="no" dir="ltr">updates.shape = indices.shape + var.shape[batch_dim:]</code></p> <p>where</p> <p><code translate="no" dir="ltr">updates.shape[:num_prefix_dims]</code> <code translate="no" dir="ltr">== indices.shape[:num_prefix_dims]</code> <code translate="no" dir="ltr">== var.shape[:num_prefix_dims]</code></p> <p>And the operation performed can be expressed as:</p> <p><code translate="no" dir="ltr">var[i_1, ..., i_n, indices[i_1, ..., i_n, j]] = updates[i_1, ..., i_n, j]</code></p> <p>When indices is a 1D tensor, this operation is equivalent to <a href="scatter_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a>.</p> <p>To avoid this operation there would be 2 alternatives: 1) Reshaping the variable by merging the first <code translate="no" dir="ltr">ndims</code> dimensions. However, this is not possible because <a href="../../reshape"><code translate="no" dir="ltr">tf.reshape</code></a> returns a Tensor, which we cannot use <a href="scatter_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> on. 2) Looping over the first <code translate="no" dir="ltr">ndims</code> of the variable and using <a href="scatter_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> on the subtensors that result of slicing the first dimension. This is a valid option for <code translate="no" dir="ltr">ndims = 1</code>, but less efficient than this implementation.</p> <p>See also <a href="scatter_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_update</code></a> and <a href="scatter_nd_update"><code translate="no" dir="ltr">tf.compat.v1.scatter_nd_update</code></a>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ref</code></b>: <code translate="no" dir="ltr">Variable</code> to scatter onto.</li> <li>
<b><code translate="no" dir="ltr">indices</code></b>: Tensor containing indices as described above.</li> <li>
<b><code translate="no" dir="ltr">updates</code></b>: Tensor of updates to apply to <code translate="no" dir="ltr">ref</code>.</li> <li>
<b><code translate="no" dir="ltr">use_locking</code></b>: Boolean indicating whether to lock the writing operation.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Optional scope name string.</li> </ul> <h4 id="returns">Returns:</h4> <p>Ref to <code translate="no" dir="ltr">variable</code> after it has been modified.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If the initial <code translate="no" dir="ltr">ndims</code> of <code translate="no" dir="ltr">ref</code>, <code translate="no" dir="ltr">indices</code>, and <code translate="no" dir="ltr">updates</code> are not the same.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/batch_scatter_update" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/batch_scatter_update</a>
  </p>
</div>
