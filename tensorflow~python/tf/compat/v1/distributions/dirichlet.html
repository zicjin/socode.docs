<h1 class="devsite-page-title">tf.compat.v1.distributions.Dirichlet</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.distributions.Dirichlet"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="allow_nan_stats"> <meta itemprop="property" content="batch_shape"> <meta itemprop="property" content="concentration"> <meta itemprop="property" content="dtype"> <meta itemprop="property" content="event_shape"> <meta itemprop="property" content="name"> <meta itemprop="property" content="parameters"> <meta itemprop="property" content="reparameterization_type"> <meta itemprop="property" content="total_concentration"> <meta itemprop="property" content="validate_args"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="batch_shape_tensor"> <meta itemprop="property" content="cdf"> <meta itemprop="property" content="copy"> <meta itemprop="property" content="covariance"> <meta itemprop="property" content="cross_entropy"> <meta itemprop="property" content="entropy"> <meta itemprop="property" content="event_shape_tensor"> <meta itemprop="property" content="is_scalar_batch"> <meta itemprop="property" content="is_scalar_event"> <meta itemprop="property" content="kl_divergence"> <meta itemprop="property" content="log_cdf"> <meta itemprop="property" content="log_prob"> <meta itemprop="property" content="log_survival_function"> <meta itemprop="property" content="mean"> <meta itemprop="property" content="mode"> <meta itemprop="property" content="param_shapes"> <meta itemprop="property" content="param_static_shapes"> <meta itemprop="property" content="prob"> <meta itemprop="property" content="quantile"> <meta itemprop="property" content="sample"> <meta itemprop="property" content="stddev"> <meta itemprop="property" content="survival_function"> <meta itemprop="property" content="variance"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/dirichlet.py#L49-L331">  View source on GitHub </a> </td>
</table>  <h2 id="class_dirichlet">Class <code translate="no" dir="ltr">Dirichlet</code>
</h2> <p>Dirichlet distribution.</p> <p>Inherits From: <a href="distribution"><code translate="no" dir="ltr">Distribution</code></a></p>  <p>The Dirichlet distribution is defined over the <a href="https://en.wikipedia.org/wiki/Simplex"><code translate="no" dir="ltr">(k-1)</code>-simplex</a> using a positive, length-<code translate="no" dir="ltr">k</code> vector <code translate="no" dir="ltr">concentration</code> (<code translate="no" dir="ltr">k &gt; 1</code>). The Dirichlet is identically the Beta distribution when <code translate="no" dir="ltr">k = 2</code>.</p> <h4 id="mathematical_details">Mathematical Details</h4> <p>The Dirichlet is a distribution over the open <code translate="no" dir="ltr">(k-1)</code>-simplex, i.e.,</p> <pre translate="no" dir="ltr" data-language="python">S^{k-1} = { (x_0, ..., x_{k-1}) in R^k : sum_j x_j = 1 and all_j x_j &gt; 0 }.
</pre> <p>The probability density function (pdf) is,</p> <pre translate="no" dir="ltr" data-language="python">pdf(x; alpha) = prod_j x_j**(alpha_j - 1) / Z
Z = prod_j Gamma(alpha_j) / Gamma(sum_j alpha_j)
</pre> <p>where:</p> <ul> <li>
<code translate="no" dir="ltr">x in S^{k-1}</code>, i.e., the <code translate="no" dir="ltr">(k-1)</code>-simplex,</li> <li>
<code translate="no" dir="ltr">concentration = alpha = [alpha_0, ..., alpha_{k-1}]</code>, <code translate="no" dir="ltr">alpha_j &gt; 0</code>,</li> <li>
<code translate="no" dir="ltr">Z</code> is the normalization constant aka the <a href="https://en.wikipedia.org/wiki/Beta_function#Multivariate_beta_function">multivariate beta function</a>, and,</li> <li>
<code translate="no" dir="ltr">Gamma</code> is the <a href="https://en.wikipedia.org/wiki/Gamma_function">gamma function</a>.</li> </ul> <p>The <code translate="no" dir="ltr">concentration</code> represents mean total counts of class occurrence, i.e.,</p> <pre translate="no" dir="ltr" data-language="python">concentration = alpha = mean * total_concentration
</pre> <p>where <code translate="no" dir="ltr">mean</code> in <code translate="no" dir="ltr">S^{k-1}</code> and <code translate="no" dir="ltr">total_concentration</code> is a positive real number representing a mean total count.</p> <p>Distribution parameters are automatically broadcast in all functions; see examples for details.</p> <aside class="warning"><strong>Warning:</strong><span> Some components of the samples can be zero due to finite precision. This happens more often when some of the concentrations are very small. Make sure to round the samples to <code translate="no" dir="ltr">np.finfo(dtype).tiny</code> before computing the density.</span></aside> <p>Samples of this distribution are reparameterized (pathwise differentiable). The derivatives are computed using the approach described in the paper</p> <p><a href="https://arxiv.org/abs/1805.08498">Michael Figurnov, Shakir Mohamed, Andriy Mnih. Implicit Reparameterization Gradients, 2018</a></p> <h4 id="examples">Examples</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">import tensorflow_probability as tfp
tfd = tfp.distributions

# Create a single trivariate Dirichlet, with the 3rd class being three times
# more frequent than the first. I.e., batch_shape=[], event_shape=[3].
alpha = [1., 2, 3]
dist = tfd.Dirichlet(alpha)

dist.sample([4, 5])  # shape: [4, 5, 3]

# x has one sample, one batch, three classes:
x = [.2, .3, .5]   # shape: [3]
dist.prob(x)       # shape: []

# x has two samples from one batch:
x = [[.1, .4, .5],
     [.2, .3, .5]]
dist.prob(x)         # shape: [2]

# alpha will be broadcast to shape [5, 7, 3] to match x.
x = [[...]]   # shape: [5, 7, 3]
dist.prob(x)  # shape: [5, 7]
</pre>
<pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Create batch_shape=[2], event_shape=[3]:
alpha = [[1., 2, 3],
         [4, 5, 6]]   # shape: [2, 3]
dist = tfd.Dirichlet(alpha)

dist.sample([4, 5])  # shape: [4, 5, 2, 3]

x = [.2, .3, .5]
# x will be broadcast as [[.2, .3, .5],
#                         [.2, .3, .5]],
# thus matching batch_shape [2, 3].
dist.prob(x)         # shape: [2]
</pre> <p>Compute the gradients of samples w.r.t. the parameters:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">alpha = tf.constant([1.0, 2.0, 3.0])
dist = tfd.Dirichlet(alpha)
samples = dist.sample(5)  # Shape [5, 3]
loss = tf.reduce_mean(tf.square(samples))  # Arbitrary loss function
# Unbiased stochastic gradients of the loss function
grads = tf.gradients(loss, alpha)
</pre> <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/dirichlet.py#L160-L206">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__(
    concentration,
    validate_args=False,
    allow_nan_stats=True,
    name='Dirichlet'
)
</pre> <p>Initialize a batch of Dirichlet distributions. (deprecated)</p> <aside class="warning"><strong>Warning:</strong><span> THIS FUNCTION IS DEPRECATED. It will be removed after 2019-01-01. Instructions for updating: The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions"><code translate="no" dir="ltr">tfp.distributions</code></a> instead of <code translate="no" dir="ltr">tf.distributions</code>.</span></aside> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">concentration</code></b>: Positive floating-point <code translate="no" dir="ltr">Tensor</code> indicating mean number of class occurrences; aka "alpha". Implies <code translate="no" dir="ltr">self.dtype</code>, and <code translate="no" dir="ltr">self.batch_shape</code>, <code translate="no" dir="ltr">self.event_shape</code>, i.e., if <code translate="no" dir="ltr">concentration.shape = [N1, N2, ..., Nm, k]</code> then <code translate="no" dir="ltr">batch_shape = [N1, N2, ..., Nm]</code> and <code translate="no" dir="ltr">event_shape = [k]</code>.</li> <li>
<b><code translate="no" dir="ltr">validate_args</code></b>: Python <code translate="no" dir="ltr">bool</code>, default <code translate="no" dir="ltr">False</code>. When <code translate="no" dir="ltr">True</code> distribution parameters are checked for validity despite possibly degrading runtime performance. When <code translate="no" dir="ltr">False</code> invalid inputs may silently render incorrect outputs.</li> <li>
<b><code translate="no" dir="ltr">allow_nan_stats</code></b>: Python <code translate="no" dir="ltr">bool</code>, default <code translate="no" dir="ltr">True</code>. When <code translate="no" dir="ltr">True</code>, statistics (e.g., mean, mode, variance) use the value "<code translate="no" dir="ltr">NaN</code>" to indicate the result is undefined. When <code translate="no" dir="ltr">False</code>, an exception is raised if one or more of the statistic's batch members are undefined.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> name prefixed to Ops created by this class.</li> </ul> <h2 id="properties">Properties</h2> <h3 id="allow_nan_stats"><code translate="no" dir="ltr">allow_nan_stats</code></h3> <p>Python <code translate="no" dir="ltr">bool</code> describing behavior when a stat is undefined.</p> <p>Stats return +/- infinity when it makes sense. E.g., the variance of a Cauchy distribution is infinity. However, sometimes the statistic is undefined, e.g., if a distribution's pdf does not achieve a maximum within the support of the distribution, the mode is undefined. If the mean is undefined, then by definition the variance is undefined. E.g. the mean for Student's T for df = 1 is undefined (no clear way to say it is either + or - infinity), so the variance = E[(X - mean)**2] is also undefined.</p> <h4 id="returns">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">allow_nan_stats</code></b>: Python <code translate="no" dir="ltr">bool</code>.</li> </ul> <h3 id="batch_shape"><code translate="no" dir="ltr">batch_shape</code></h3> <p>Shape of a single sample from a single event index as a <code translate="no" dir="ltr">TensorShape</code>.</p> <p>May be partially defined or unknown.</p> <p>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</p> <h4 id="returns_2">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">batch_shape</code></b>: <code translate="no" dir="ltr">TensorShape</code>, possibly unknown.</li> </ul> <h3 id="concentration"><code translate="no" dir="ltr">concentration</code></h3> <p>Concentration parameter; expected counts for that coordinate.</p> <h3 id="dtype"><code translate="no" dir="ltr">dtype</code></h3> <p>The <code translate="no" dir="ltr">DType</code> of <code translate="no" dir="ltr">Tensor</code>s handled by this <code translate="no" dir="ltr">Distribution</code>.</p> <h3 id="event_shape"><code translate="no" dir="ltr">event_shape</code></h3> <p>Shape of a single sample from a single batch as a <code translate="no" dir="ltr">TensorShape</code>.</p> <p>May be partially defined or unknown.</p> <h4 id="returns_3">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">event_shape</code></b>: <code translate="no" dir="ltr">TensorShape</code>, possibly unknown.</li> </ul> <h3 id="name"><code translate="no" dir="ltr">name</code></h3> <p>Name prepended to all ops created by this <code translate="no" dir="ltr">Distribution</code>.</p> <h3 id="parameters"><code translate="no" dir="ltr">parameters</code></h3> <p>Dictionary of parameters used to instantiate this <code translate="no" dir="ltr">Distribution</code>.</p> <h3 id="reparameterization_type"><code translate="no" dir="ltr">reparameterization_type</code></h3> <p>Describes how samples from the distribution are reparameterized.</p> <p>Currently this is one of the static instances <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions#FULLY_REPARAMETERIZED"><code translate="no" dir="ltr">distributions.FULLY_REPARAMETERIZED</code></a> or <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions#NOT_REPARAMETERIZED"><code translate="no" dir="ltr">distributions.NOT_REPARAMETERIZED</code></a>.</p> <h4 id="returns_4">Returns:</h4> <p>An instance of <code translate="no" dir="ltr">ReparameterizationType</code>.</p> <h3 id="total_concentration"><code translate="no" dir="ltr">total_concentration</code></h3> <p>Sum of last dim of concentration parameter.</p> <h3 id="validate_args"><code translate="no" dir="ltr">validate_args</code></h3> <p>Python <code translate="no" dir="ltr">bool</code> indicating possibly expensive checks are enabled.</p> <h2 id="methods">Methods</h2> <h3 id="batch_shape_tensor"><code translate="no" dir="ltr">batch_shape_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L637-L654">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">batch_shape_tensor(name='batch_shape_tensor')
</pre> <p>Shape of a single sample from a single event index as a 1-D <code translate="no" dir="ltr">Tensor</code>.</p> <p>The batch dimensions are indexes into independent, non-identical parameterizations of this distribution.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: name to give to the op</li> </ul> <h4 id="returns_5">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">batch_shape</code></b>: <code translate="no" dir="ltr">Tensor</code>.</li> </ul> <h3 id="cdf"><code translate="no" dir="ltr">cdf</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L881-L898">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">cdf(
    value,
    name='cdf'
)
</pre> <p>Cumulative distribution function.</p> <p>Given random variable <code translate="no" dir="ltr">X</code>, the cumulative distribution function <code translate="no" dir="ltr">cdf</code> is:</p> <pre translate="no" dir="ltr" data-language="python">cdf(x) := P[X &lt;= x]
</pre> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_6">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">cdf</code></b>: a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</li> </ul> <h3 id="copy"><code translate="no" dir="ltr">copy</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L615-L631">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">copy(**override_parameters_kwargs)
</pre> <p>Creates a deep copy of the distribution.</p> <blockquote class="note">
<strong>Note:</strong><span> the copy distribution may continue to depend on the original initialization arguments.</span>
</blockquote> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">**override_parameters_kwargs</code></b>: String/value dictionary of initialization arguments to override with new values.</li> </ul> <h4 id="returns_7">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">distribution</code></b>: A new instance of <code translate="no" dir="ltr">type(self)</code> initialized from the union of self.parameters and override_parameters_kwargs, i.e., <code translate="no" dir="ltr">dict(self.parameters, **override_parameters_kwargs)</code>.</li> </ul> <h3 id="covariance"><code translate="no" dir="ltr">covariance</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1094-L1131">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">covariance(name='covariance')
</pre> <p>Covariance.</p> <p>Covariance is (possibly) defined only for non-scalar-event distributions.</p> <p>For example, for a length-<code translate="no" dir="ltr">k</code>, vector-valued distribution, it is calculated as,</p> <pre translate="no" dir="ltr" data-language="python">Cov[i, j] = Covariance(X_i, X_j) = E[(X_i - E[X_i]) (X_j - E[X_j])]
</pre> <p>where <code translate="no" dir="ltr">Cov</code> is a (batch of) <code translate="no" dir="ltr">k x k</code> matrix, <code translate="no" dir="ltr">0 &lt;= (i, j) &lt; k</code>, and <code translate="no" dir="ltr">E</code> denotes expectation.</p> <p>Alternatively, for non-vector, multivariate distributions (e.g., matrix-valued, Wishart), <code translate="no" dir="ltr">Covariance</code> shall return a (batch of) matrices under some vectorization of the events, i.e.,</p> <pre translate="no" dir="ltr" data-language="python">Cov[i, j] = Covariance(Vec(X)_i, Vec(X)_j) = [as above]
</pre> <p>where <code translate="no" dir="ltr">Cov</code> is a (batch of) <code translate="no" dir="ltr">k' x k'</code> matrices, <code translate="no" dir="ltr">0 &lt;= (i, j) &lt; k' = reduce_prod(event_shape)</code>, and <code translate="no" dir="ltr">Vec</code> is some function mapping indices of this distribution's event dimensions to indices of a length-<code translate="no" dir="ltr">k'</code> vector.</p> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_8">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">covariance</code></b>: Floating-point <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[B1, ..., Bn, k', k']</code> where the first <code translate="no" dir="ltr">n</code> dimensions are batch coordinates and <code translate="no" dir="ltr">k' = reduce_prod(self.event_shape)</code>.</li> </ul> <h3 id="cross_entropy"><code translate="no" dir="ltr">cross_entropy</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1146-L1169">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">cross_entropy(
    other,
    name='cross_entropy'
)
</pre> <p>Computes the (Shannon) cross entropy.</p> <p>Denote this distribution (<code translate="no" dir="ltr">self</code>) by <code translate="no" dir="ltr">P</code> and the <code translate="no" dir="ltr">other</code> distribution by <code translate="no" dir="ltr">Q</code>. Assuming <code translate="no" dir="ltr">P, Q</code> are absolutely continuous with respect to one another and permit densities <code translate="no" dir="ltr">p(x) dr(x)</code> and <code translate="no" dir="ltr">q(x) dr(x)</code>, (Shanon) cross entropy is defined as:</p> <pre translate="no" dir="ltr" data-language="python">H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x)
</pre> <p>where <code translate="no" dir="ltr">F</code> denotes the support of the random variable <code translate="no" dir="ltr">X ~ P</code>.</p> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">other</code></b>: <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution"><code translate="no" dir="ltr">tfp.distributions.Distribution</code></a> instance.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_9">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">cross_entropy</code></b>: <code translate="no" dir="ltr">self.dtype</code> <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[B1, ..., Bn]</code> representing <code translate="no" dir="ltr">n</code> different calculations of (Shanon) cross entropy.</li> </ul> <h3 id="entropy"><code translate="no" dir="ltr">entropy</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L982-L985">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">entropy(name='entropy')
</pre> <p>Shannon entropy in nats.</p> <h3 id="event_shape_tensor"><code translate="no" dir="ltr">event_shape_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L677-L691">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">event_shape_tensor(name='event_shape_tensor')
</pre> <p>Shape of a single sample from a single batch as a 1-D int32 <code translate="no" dir="ltr">Tensor</code>.</p> <h4 id="args_7">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: name to give to the op</li> </ul> <h4 id="returns_10">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">event_shape</code></b>: <code translate="no" dir="ltr">Tensor</code>.</li> </ul> <h3 id="is_scalar_batch"><code translate="no" dir="ltr">is_scalar_batch</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L721-L733">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">is_scalar_batch(name='is_scalar_batch')
</pre> <p>Indicates that <code translate="no" dir="ltr">batch_shape == []</code>.</p> <h4 id="args_8">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_11">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">is_scalar_batch</code></b>: <code translate="no" dir="ltr">bool</code> scalar <code translate="no" dir="ltr">Tensor</code>.</li> </ul> <h3 id="is_scalar_event"><code translate="no" dir="ltr">is_scalar_event</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L707-L719">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">is_scalar_event(name='is_scalar_event')
</pre> <p>Indicates that <code translate="no" dir="ltr">event_shape == []</code>.</p> <h4 id="args_9">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_12">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">is_scalar_event</code></b>: <code translate="no" dir="ltr">bool</code> scalar <code translate="no" dir="ltr">Tensor</code>.</li> </ul> <h3 id="kl_divergence"><code translate="no" dir="ltr">kl_divergence</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1175-L1201">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">kl_divergence(
    other,
    name='kl_divergence'
)
</pre> <p>Computes the Kullback--Leibler divergence.</p> <p>Denote this distribution (<code translate="no" dir="ltr">self</code>) by <code translate="no" dir="ltr">p</code> and the <code translate="no" dir="ltr">other</code> distribution by <code translate="no" dir="ltr">q</code>. Assuming <code translate="no" dir="ltr">p, q</code> are absolutely continuous with respect to reference measure <code translate="no" dir="ltr">r</code>, the KL divergence is defined as:</p> <pre translate="no" dir="ltr" data-language="python">KL[p, q] = E_p[log(p(X)/q(X))]
         = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x)
         = H[p, q] - H[p]
</pre> <p>where <code translate="no" dir="ltr">F</code> denotes the support of the random variable <code translate="no" dir="ltr">X ~ p</code>, <code translate="no" dir="ltr">H[., .]</code> denotes (Shanon) cross entropy, and <code translate="no" dir="ltr">H[.]</code> denotes (Shanon) entropy.</p> <h4 id="args_10">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">other</code></b>: <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution"><code translate="no" dir="ltr">tfp.distributions.Distribution</code></a> instance.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_13">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">kl_divergence</code></b>: <code translate="no" dir="ltr">self.dtype</code> <code translate="no" dir="ltr">Tensor</code> with shape <code translate="no" dir="ltr">[B1, ..., Bn]</code> representing <code translate="no" dir="ltr">n</code> different calculations of the Kullback-Leibler divergence.</li> </ul> <h3 id="log_cdf"><code translate="no" dir="ltr">log_cdf</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L842-L863">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">log_cdf(
    value,
    name='log_cdf'
)
</pre> <p>Log cumulative distribution function.</p> <p>Given random variable <code translate="no" dir="ltr">X</code>, the cumulative distribution function <code translate="no" dir="ltr">cdf</code> is:</p> <pre translate="no" dir="ltr" data-language="python">log_cdf(x) := Log[ P[X &lt;= x] ]
</pre> <p>Often, a numerical approximation can be used for <code translate="no" dir="ltr">log_cdf(x)</code> that yields a more accurate answer than simply taking the logarithm of the <code translate="no" dir="ltr">cdf</code> when <code translate="no" dir="ltr">x &lt;&lt; -1</code>.</p> <h4 id="args_11">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_14">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">logcdf</code></b>: a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</li> </ul> <h3 id="log_prob"><code translate="no" dir="ltr">log_prob</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L784-L795">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">log_prob(
    value,
    name='log_prob'
)
</pre> <p>Log probability density/mass function.</p> <p>Additional documentation from <code translate="no" dir="ltr">Dirichlet</code>:</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">value</code> must be a non-negative tensor with dtype <code translate="no" dir="ltr">self.dtype</code> and be in the <code translate="no" dir="ltr">(self.event_shape() - 1)</code>-simplex, i.e., <code translate="no" dir="ltr">tf.reduce_sum(value, -1) = 1</code>. It must have a shape compatible with <code translate="no" dir="ltr">self.batch_shape() + self.event_shape()</code>.</span>
</blockquote> <h4 id="args_12">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_15">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">log_prob</code></b>: a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</li> </ul> <h3 id="log_survival_function"><code translate="no" dir="ltr">log_survival_function</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L917-L939">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">log_survival_function(
    value,
    name='log_survival_function'
)
</pre> <p>Log survival function.</p> <p>Given random variable <code translate="no" dir="ltr">X</code>, the survival function is defined:</p> <pre translate="no" dir="ltr" data-language="python">log_survival_function(x) = Log[ P[X &gt; x] ]
                         = Log[ 1 - P[X &lt;= x] ]
                         = Log[ 1 - cdf(x) ]
</pre> <p>Typically, different numerical approximations can be used for the log survival function, which are more accurate than <code translate="no" dir="ltr">1 - cdf(x)</code> when <code translate="no" dir="ltr">x &gt;&gt; 1</code>.</p> <h4 id="args_13">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_16">Returns:</h4> <p><code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</p> <h3 id="mean"><code translate="no" dir="ltr">mean</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L991-L994">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">mean(name='mean')
</pre> <p>Mean.</p> <h3 id="mode"><code translate="no" dir="ltr">mode</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1137-L1140">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">mode(name='mode')
</pre> <p>Mode.</p> <p>Additional documentation from <code translate="no" dir="ltr">Dirichlet</code>:</p> <blockquote class="note">
<strong>Note:</strong><span> The mode is undefined when any <code translate="no" dir="ltr">concentration &lt;= 1</code>. If <code translate="no" dir="ltr">self.allow_nan_stats</code> is <code translate="no" dir="ltr">True</code>, <code translate="no" dir="ltr">NaN</code> is used for undefined modes. If <code translate="no" dir="ltr">self.allow_nan_stats</code> is <code translate="no" dir="ltr">False</code> an exception is raised when one or more modes are undefined.</span>
</blockquote> <h3 id="param_shapes"><code translate="no" dir="ltr">param_shapes</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L497-L516">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">param_shapes(
    cls,
    sample_shape,
    name='DistributionParamShapes'
)
</pre> <p>Shapes of parameters given the desired shape of a call to <code translate="no" dir="ltr">sample()</code>.</p> <p>This is a class method that describes what key/value arguments are required to instantiate the given <code translate="no" dir="ltr">Distribution</code> so that a particular shape is returned for that instance's call to <code translate="no" dir="ltr">sample()</code>.</p> <p>Subclasses should override class method <code translate="no" dir="ltr">_param_shapes</code>.</p> <h4 id="args_14">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sample_shape</code></b>: <code translate="no" dir="ltr">Tensor</code> or python list/tuple. Desired shape of a call to <code translate="no" dir="ltr">sample()</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: name to prepend ops with.</li> </ul> <h4 id="returns_17">Returns:</h4> <p><code translate="no" dir="ltr">dict</code> of parameter name to <code translate="no" dir="ltr">Tensor</code> shapes.</p> <h3 id="param_static_shapes"><code translate="no" dir="ltr">param_static_shapes</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L518-L555">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">param_static_shapes(
    cls,
    sample_shape
)
</pre> <p>param_shapes with static (i.e. <code translate="no" dir="ltr">TensorShape</code>) shapes.</p> <p>This is a class method that describes what key/value arguments are required to instantiate the given <code translate="no" dir="ltr">Distribution</code> so that a particular shape is returned for that instance's call to <code translate="no" dir="ltr">sample()</code>. Assumes that the sample's shape is known statically.</p> <p>Subclasses should override class method <code translate="no" dir="ltr">_param_shapes</code> to return constant-valued tensors when constant values are fed.</p> <h4 id="args_15">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sample_shape</code></b>: <code translate="no" dir="ltr">TensorShape</code> or python list/tuple. Desired shape of a call to <code translate="no" dir="ltr">sample()</code>.</li> </ul> <h4 id="returns_18">Returns:</h4> <p><code translate="no" dir="ltr">dict</code> of parameter name to <code translate="no" dir="ltr">TensorShape</code>.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">sample_shape</code> is a <code translate="no" dir="ltr">TensorShape</code> and is not fully defined.</li> </ul> <h3 id="prob"><code translate="no" dir="ltr">prob</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L813-L824">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">prob(
    value,
    name='prob'
)
</pre> <p>Probability density/mass function.</p> <p>Additional documentation from <code translate="no" dir="ltr">Dirichlet</code>:</p> <blockquote class="note">
<strong>Note:</strong><span> <code translate="no" dir="ltr">value</code> must be a non-negative tensor with dtype <code translate="no" dir="ltr">self.dtype</code> and be in the <code translate="no" dir="ltr">(self.event_shape() - 1)</code>-simplex, i.e., <code translate="no" dir="ltr">tf.reduce_sum(value, -1) = 1</code>. It must have a shape compatible with <code translate="no" dir="ltr">self.batch_shape() + self.event_shape()</code>.</span>
</blockquote> <h4 id="args_16">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_19">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">prob</code></b>: a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</li> </ul> <h3 id="quantile"><code translate="no" dir="ltr">quantile</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1006-L1023">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">quantile(
    value,
    name='quantile'
)
</pre> <p>Quantile function. Aka "inverse cdf" or "percent point function".</p> <p>Given random variable <code translate="no" dir="ltr">X</code> and <code translate="no" dir="ltr">p in [0, 1]</code>, the <code translate="no" dir="ltr">quantile</code> is:</p> <pre translate="no" dir="ltr" data-language="python">quantile(p) := x such that P[X &lt;= x] == p
</pre> <h4 id="args_17">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_20">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">quantile</code></b>: a <code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</li> </ul> <h3 id="sample"><code translate="no" dir="ltr">sample</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L752-L766">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">sample(
    sample_shape=(),
    seed=None,
    name='sample'
)
</pre> <p>Generate samples of the specified shape.</p> <p>Note that a call to <code translate="no" dir="ltr">sample()</code> without arguments will generate a single sample.</p> <h4 id="args_18">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">sample_shape</code></b>: 0D or 1D <code translate="no" dir="ltr">int32</code> <code translate="no" dir="ltr">Tensor</code>. Shape of the generated samples.</li> <li>
<b><code translate="no" dir="ltr">seed</code></b>: Python integer seed for RNG</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: name to give to the op.</li> </ul> <h4 id="returns_21">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">samples</code></b>: a <code translate="no" dir="ltr">Tensor</code> with prepended dimensions <code translate="no" dir="ltr">sample_shape</code>.</li> </ul> <h3 id="stddev"><code translate="no" dir="ltr">stddev</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1061-L1088">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">stddev(name='stddev')
</pre> <p>Standard deviation.</p> <p>Standard deviation is defined as,</p> <pre translate="no" dir="ltr" data-language="python">stddev = E[(X - E[X])**2]**0.5
</pre> <p>where <code translate="no" dir="ltr">X</code> is the random variable associated with this distribution, <code translate="no" dir="ltr">E</code> denotes expectation, and <code translate="no" dir="ltr">stddev.shape = batch_shape + event_shape</code>.</p> <h4 id="args_19">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_22">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">stddev</code></b>: Floating-point <code translate="no" dir="ltr">Tensor</code> with shape identical to <code translate="no" dir="ltr">batch_shape + event_shape</code>, i.e., the same shape as <code translate="no" dir="ltr">self.mean()</code>.</li> </ul> <h3 id="survival_function"><code translate="no" dir="ltr">survival_function</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L957-L976">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">survival_function(
    value,
    name='survival_function'
)
</pre> <p>Survival function.</p> <p>Given random variable <code translate="no" dir="ltr">X</code>, the survival function is defined:</p> <pre translate="no" dir="ltr" data-language="python">survival_function(x) = P[X &gt; x]
                     = 1 - P[X &lt;= x]
                     = 1 - cdf(x).
</pre> <h4 id="args_20">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">value</code></b>: <code translate="no" dir="ltr">float</code> or <code translate="no" dir="ltr">double</code> <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_23">Returns:</h4> <p><code translate="no" dir="ltr">Tensor</code> of shape <code translate="no" dir="ltr">sample_shape(x) + self.batch_shape</code> with values of type <code translate="no" dir="ltr">self.dtype</code>.</p> <h3 id="variance"><code translate="no" dir="ltr">variance</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/distributions/distribution.py#L1029-L1055">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">variance(name='variance')
</pre> <p>Variance.</p> <p>Variance is defined as,</p> <pre translate="no" dir="ltr" data-language="python">Var = E[(X - E[X])**2]
</pre> <p>where <code translate="no" dir="ltr">X</code> is the random variable associated with this distribution, <code translate="no" dir="ltr">E</code> denotes expectation, and <code translate="no" dir="ltr">Var.shape = batch_shape + event_shape</code>.</p> <h4 id="args_21">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">name</code></b>: Python <code translate="no" dir="ltr">str</code> prepended to names of ops created by this function.</li> </ul> <h4 id="returns_24">Returns:</h4> <ul> <li>
<b><code translate="no" dir="ltr">variance</code></b>: Floating-point <code translate="no" dir="ltr">Tensor</code> with shape identical to <code translate="no" dir="ltr">batch_shape + event_shape</code>, i.e., the same shape as <code translate="no" dir="ltr">self.mean()</code>.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/distributions/Dirichlet" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/distributions/Dirichlet</a>
  </p>
</div>
