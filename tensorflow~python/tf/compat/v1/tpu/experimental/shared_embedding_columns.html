<h1 class="devsite-page-title">tf.compat.v1.tpu.experimental.shared_embedding_columns</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.tpu.experimental.shared_embedding_columns"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/tpu/feature_column_v2.py#L190-L380">  View source on GitHub </a> </td>
</table>  <p>TPU version of <a href="../../feature_column/shared_embedding_columns"><code translate="no" dir="ltr">tf.compat.v1.feature_column.shared_embedding_columns</code></a>.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.tpu.experimental.shared_embedding_columns(
    categorical_columns,
    dimension,
    combiner='mean',
    initializer=None,
    shared_embedding_collection_name=None,
    max_sequence_lengths=None,
    learning_rate_fn=None,
    embedding_lookup_device=None,
    tensor_core_shape=None
)
</pre>  <p>Note that the interface for <code translate="no" dir="ltr">tf.tpu.experimental.shared_embedding_columns</code> is different from that of <a href="../../feature_column/shared_embedding_columns"><code translate="no" dir="ltr">tf.compat.v1.feature_column.shared_embedding_columns</code></a>: The following arguments are NOT supported: <code translate="no" dir="ltr">ckpt_to_load_from</code>, <code translate="no" dir="ltr">tensor_name_in_ckpt</code>, <code translate="no" dir="ltr">max_norm</code> and <code translate="no" dir="ltr">trainable</code>.</p> <p>Use this function in place of tf.compat.v1.feature_column.shared_embedding_columns` when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">column_a = tf.feature_column.categorical_column_with_identity(...)
column_b = tf.feature_column.categorical_column_with_identity(...)
tpu_columns = tf.tpu.experimental.shared_embedding_columns(
    [column_a, column_b], 10)
...
def model_fn(features):
  dense_feature = tf.keras.layers.DenseFeature(tpu_columns)
  embedded_feature = dense_feature(features)
  ...

estimator = tf.estimator.tpu.TPUEstimator(
    model_fn=model_fn,
    ...
    embedding_config_spec=tf.estimator.tpu.experimental.EmbeddingConfigSpec(
        column=tpu_columns,
        ...))
</pre> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">categorical_columns</code></b>: A list of categorical columns returned from <code translate="no" dir="ltr">categorical_column_with_identity</code>, <code translate="no" dir="ltr">weighted_categorical_column</code>, <code translate="no" dir="ltr">categorical_column_with_vocabulary_file</code>, <code translate="no" dir="ltr">categorical_column_with_vocabulary_list</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_identity</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_vocabulary_file</code>, <code translate="no" dir="ltr">sequence_categorical_column_with_vocabulary_list</code>
</li> <li>
<b><code translate="no" dir="ltr">dimension</code></b>: An integer specifying dimension of the embedding, must be &gt; 0.</li> <li>
<b><code translate="no" dir="ltr">combiner</code></b>: A string specifying how to reduce if there are multiple entries in a single row for a non-sequence column. For more information, see <a href="../../../../feature_column/embedding_column"><code translate="no" dir="ltr">tf.feature_column.embedding_column</code></a>.</li> <li>
<b><code translate="no" dir="ltr">initializer</code></b>: A variable initializer function to be used in embedding variable initialization. If not specified, defaults to <code translate="no" dir="ltr">tf.truncated_normal_initializer</code> with mean <code translate="no" dir="ltr">0.0</code> and standard deviation <code translate="no" dir="ltr">1/sqrt(dimension)</code>.</li> <li>
<b><code translate="no" dir="ltr">shared_embedding_collection_name</code></b>: Optional name of the collection where shared embedding weights are added. If not given, a reasonable name will be chosen based on the names of <code translate="no" dir="ltr">categorical_columns</code>. This is also used in <code translate="no" dir="ltr">variable_scope</code> when creating shared embedding weights.</li> <li>
<b><code translate="no" dir="ltr">max_sequence_lengths</code></b>: An list of non-negative integers, either None or empty or the same length as the argument categorical_columns. Entries corresponding to non-sequence columns must be 0 and entries corresponding to sequence columns specify the max sequence length for the column. Any sequence shorter then this will be padded with 0 embeddings and any sequence longer will be truncated.</li> <li>
<b><code translate="no" dir="ltr">learning_rate_fn</code></b>: A function that takes global step and returns learning rate for the embedding table.</li> <li>
<b><code translate="no" dir="ltr">embedding_lookup_device</code></b>: The device on which to run the embedding lookup. Valid options are "cpu", "tpu_tensor_core", and "tpu_embedding_core". If specifying "tpu_tensor_core", a tensor_core_shape must be supplied. Defaults to "cpu". If not specified, the default behavior is embedding lookup on "tpu_embedding_core" for training and "cpu" for inference. Valid options for training : ["tpu_embedding_core", "tpu_tensor_core"] Valid options for serving : ["cpu", "tpu_tensor_core"] For training, tpu_embedding_core is good for large embedding vocab (&gt;1M), otherwise, tpu_tensor_core is often sufficient. For serving, doing embedding lookup on tpu_tensor_core during serving is a way to reduce host cpu usage in cases where that is a bottleneck.</li> <li>
<b><code translate="no" dir="ltr">tensor_core_shape</code></b>: If supplied, a list of integers which specifies the intended dense shape to run embedding lookup for this feature on TensorCore. The batch dimension can be left None or -1 to indicate a dynamic shape. Only rank 2 shapes currently supported.</li> </ul> <h4 id="returns">Returns:</h4> <p>A list of <code translate="no" dir="ltr">_TPUSharedEmbeddingColumnV2</code>.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">dimension</code> not &gt; 0.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">initializer</code> is specified but not callable.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">max_sequence_lengths</code> is specified and not the same length as <code translate="no" dir="ltr">categorical_columns</code>.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">max_sequence_lengths</code> is positive for a non sequence column or 0 for a sequence column.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/tpu/experimental/shared_embedding_columns" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/tpu/experimental/shared_embedding_columns</a>
  </p>
</div>
