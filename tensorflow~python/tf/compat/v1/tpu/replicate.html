<h1 class="devsite-page-title">tf.compat.v1.tpu.replicate</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.tpu.replicate"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/tpu/tpu.py#L749-L810">  View source on GitHub </a> </td>
</table>  <p>Builds a graph operator that runs a replicated TPU computation.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.tpu.replicate(
    computation,
    inputs=None,
    infeed_queue=None,
    device_assignment=None,
    name=None,
    maximum_shapes=None
)
</pre>  <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">computation</code></b>: A Python function that builds the computation to replicate.</li> <li>
<b><code translate="no" dir="ltr">inputs</code></b>: A list of lists of input tensors or <code translate="no" dir="ltr">None</code> (equivalent to <code translate="no" dir="ltr">[[]]</code>), indexed by <code translate="no" dir="ltr">[replica_num][input_num]</code>. All replicas must have the same number of inputs. Each input can be a nested structure containing values that are convertible to tensors. Note that passing an N-dimension list of compatible values will result in a N-dimension list of scalar tensors rather than a single Rank-N tensors. If you need different behavior, convert part of inputs to tensors with <a href="../../../convert_to_tensor"><code translate="no" dir="ltr">tf.convert_to_tensor</code></a>.</li> <li>
<b><code translate="no" dir="ltr">infeed_queue</code></b>: If not <code translate="no" dir="ltr">None</code>, the <code translate="no" dir="ltr">InfeedQueue</code> from which to append a tuple of arguments as inputs to computation.</li> <li>
<b><code translate="no" dir="ltr">device_assignment</code></b>: If not <code translate="no" dir="ltr">None</code>, a <code translate="no" dir="ltr">DeviceAssignment</code> describing the mapping between logical cores in the computation with physical cores in the TPU topology. Uses a default device assignment if <code translate="no" dir="ltr">None</code>. The <code translate="no" dir="ltr">DeviceAssignment</code> may be omitted if each replica of the computation uses only one core, and there is either only one replica, or the number of replicas is equal to the number of cores in the TPU system.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: (Deprecated) Does nothing.</li> <li>
<b><code translate="no" dir="ltr">maximum_shapes</code></b>: A nested structure of tf.TensorShape representing the shape to which the respective component of each input element in each replica should be padded. Any unknown dimensions (e.g. tf.compat.v1.Dimension(None) in a tf.TensorShape or -1 in a tensor-like object) will be padded to the maximum size of that dimension over all replicas. The structure of <code translate="no" dir="ltr">maximum_shapes</code> needs to be the same as <code translate="no" dir="ltr">inputs[0]</code>.</li> </ul> <h4 id="returns">Returns:</h4> <p>A list of outputs, indexed by <code translate="no" dir="ltr">[replica_num]</code> each output can be a nested structure same as what computation() returns with a few exceptions.</p> <p>Exceptions include: 1) None output: a NoOp would be returned which control-depends on computation. 2) Single value output: A tuple containing the value would be returned. 3) Operation-only outputs: a NoOp would be returned which control-depends on computation. TODO(b/121383831): Investigate into removing these special cases.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If all replicas do not have equal numbers of input tensors.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If the number of inputs per replica does not match the number of formal parameters to <code translate="no" dir="ltr">computation</code>.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If the static <code translate="no" dir="ltr">inputs</code> dimensions don't match with the values given in <code translate="no" dir="ltr">maximum_shapes</code>.</li> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: If the structure of inputs per replica does not match the structure of <code translate="no" dir="ltr">maximum_shapes</code>.</li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/tpu/replicate" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/tpu/replicate</a>
  </p>
</div>
