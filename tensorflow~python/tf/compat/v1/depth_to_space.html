<h1 class="devsite-page-title">tf.compat.v1.depth_to_space</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.compat.v1.depth_to_space"> <meta itemprop="path" content="Stable"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/array_ops.py#L3375-L3378">  View source on GitHub </a> </td>
</table>  <p>DepthToSpace for tensors of type T.</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">tf.compat.v1.depth_to_space(
    input,
    block_size,
    name=None,
    data_format='NHWC'
)
</pre>  <p>Rearranges data from depth into blocks of spatial data. This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of the input tensor where values from the <code translate="no" dir="ltr">depth</code> dimension are moved in spatial blocks to the <code translate="no" dir="ltr">height</code> and <code translate="no" dir="ltr">width</code> dimensions. The attr <code translate="no" dir="ltr">block_size</code> indicates the input block size and how the data is moved.</p> <ul> <li>Chunks of data of size <code translate="no" dir="ltr">block_size * block_size</code> from depth are rearranged into non-overlapping blocks of size <code translate="no" dir="ltr">block_size x block_size</code>
</li> <li>The width the output tensor is <code translate="no" dir="ltr">input_depth * block_size</code>, whereas the height is <code translate="no" dir="ltr">input_height * block_size</code>.</li> <li>The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.</li> <li>The depth of the input tensor must be divisible by <code translate="no" dir="ltr">block_size * block_size</code>.</li> </ul> <p>The <code translate="no" dir="ltr">data_format</code> attr specifies the layout of the input and output tensors with the following options: "NHWC": <code translate="no" dir="ltr">[ batch, height, width, channels ]</code> "NCHW": <code translate="no" dir="ltr">[ batch, channels, height, width ]</code> "NCHW_VECT_C": <code translate="no" dir="ltr">qint8 [ batch, channels / 4, height, width, 4 ]</code></p> <p>It is useful to consider the operation as transforming a 6-D Tensor. e.g. for data_format = NHWC, Each element in the input tensor can be specified via 6 coordinates, ordered by decreasing memory layout significance as: n,iY,iX,bY,bX,oC (where n=batch index, iX, iY means X or Y coordinates within the input image, bX, bY means coordinates within the output block, oC means output channels). The output would be the input transposed to the following layout: n,iY,bY,iX,bX,oC</p> <p>This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.</p> <p>For example, given an input of shape <code translate="no" dir="ltr">[1, 1, 1, 4]</code>, data_format = "NHWC" and block_size = 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1, 2, 3, 4]]]]

</pre> <p>This operation will output a tensor of shape <code translate="no" dir="ltr">[1, 2, 2, 1]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1], [2]],
  [[3], [4]]]]
</pre> <p>Here, the input has a batch of 1 and each batch element has shape <code translate="no" dir="ltr">[1, 1, 4]</code>, the corresponding output will have 2x2 elements and will have a depth of 1 channel (1 = <code translate="no" dir="ltr">4 / (block_size * block_size)</code>). The output element shape is <code translate="no" dir="ltr">[2, 2, 1]</code>.</p> <p>For an input tensor with larger depth, here of shape <code translate="no" dir="ltr">[1, 1, 1, 12]</code>, e.g.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
</pre> <p>This operation, for block size of 2, will return the following tensor of shape <code translate="no" dir="ltr">[1, 2, 2, 3]</code></p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">[[[[1, 2, 3], [4, 5, 6]],
  [[7, 8, 9], [10, 11, 12]]]]

</pre> <p>Similarly, for the following input of shape <code translate="no" dir="ltr">[1 2 2 4]</code>, and a block size of 2:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x =  [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]
</pre> <p>the operator will return the following tensor of shape <code translate="no" dir="ltr">[1 4 4 1]</code>:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="python">x = [[[ [1],   [2],  [5],  [6]],
      [ [3],   [4],  [7],  [8]],
      [ [9],  [10], [13],  [14]],
      [ [11], [12], [15],  [16]]]]

</pre> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">input</code></b>: A <code translate="no" dir="ltr">Tensor</code>.</li> <li>
<b><code translate="no" dir="ltr">block_size</code></b>: An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 2</code>. The size of the spatial block, same as in Space2Depth.</li> <li>
<b><code translate="no" dir="ltr">data_format</code></b>: An optional <code translate="no" dir="ltr">string</code> from: <code translate="no" dir="ltr">"NHWC", "NCHW", "NCHW_VECT_C"</code>. Defaults to <code translate="no" dir="ltr">"NHWC"</code>.</li> <li>
<b><code translate="no" dir="ltr">name</code></b>: A name for the operation (optional).</li> </ul> <h4 id="returns">Returns:</h4> <p>A <code translate="no" dir="ltr">Tensor</code>. Has the same type as <code translate="no" dir="ltr">input</code>.</p> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="depth_to_space"><code translate="no" dir="ltr">tf.compat.v1.nn.depth_to_space</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/depth_to_space" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/compat/v1/depth_to_space</a>
  </p>
</div>
