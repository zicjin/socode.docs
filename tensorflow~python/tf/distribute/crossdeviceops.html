<h1 class="devsite-page-title">tf.distribute.CrossDeviceOps</h1>     <div itemscope itemtype="http://developers.google.com/ReferenceObject"> <meta itemprop="name" content="tf.distribute.CrossDeviceOps"> <meta itemprop="path" content="Stable"> <meta itemprop="property" content="__init__"> <meta itemprop="property" content="batch_reduce"> <meta itemprop="property" content="batch_reduce_implementation"> <meta itemprop="property" content="broadcast"> <meta itemprop="property" content="broadcast_implementation"> <meta itemprop="property" content="reduce"> <meta itemprop="property" content="reduce_implementation"> </div>  <table class="tfo-notebook-buttons tfo-api" align="left"> <td> <a target="_blank" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/distribute/CrossDeviceOps">  TensorFlow 1 version</a> </td> <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L237-L403">  View source on GitHub </a> </td>
</table>  <h2 id="class_crossdeviceops">Class <code translate="no" dir="ltr">CrossDeviceOps</code>
</h2> <p>Base class for cross-device reduction and broadcasting algorithms.</p>  <h2 id="__init__"><code translate="no" dir="ltr">__init__</code></h2> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L240-L241">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">__init__()
</pre> <p>Initialize self. See help(type(self)) for accurate signature.</p> <h2 id="methods">Methods</h2> <h3 id="batch_reduce"><code translate="no" dir="ltr">batch_reduce</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L284-L327">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">batch_reduce(
    reduce_op,
    value_destination_pairs
)
</pre> <p>Reduce PerReplica objects in a batch.</p> <p>Reduce each first element in <code translate="no" dir="ltr">value_destination_pairs</code> to each second element which indicates the destinations.</p> <p>This can be faster than multiple individual <code translate="no" dir="ltr">reduce</code>s because we can fuse several tensors into one or multiple packs before reduction.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">reduce_op</code></b>: An instance of <a href="reduceop"><code translate="no" dir="ltr">tf.distribute.ReduceOp</code></a> that indicates how the <code translate="no" dir="ltr">per_replica_value</code> will be reduced.</li> <li>
<b><code translate="no" dir="ltr">value_destination_pairs</code></b>: a list or a tuple of PerReplica objects (or tensors with device set if there is one device) and destinations.</li> </ul> <h4 id="returns">Returns:</h4> <p>a list of Mirrored objects.</p> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">value_destination_pairs</code> is not an iterable of tuples of PerReplica objects and destinations.</li> </ul> <h3 id="batch_reduce_implementation"><code translate="no" dir="ltr">batch_reduce_implementation</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L367-L390">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">batch_reduce_implementation(
    reduce_op,
    value_destination_pairs
)
</pre> <p>Implementation of reduce PerReplica objects in a batch.</p> <p>Overriding this method is useful for subclass implementers.</p> <p>Reduce each first element in <code translate="no" dir="ltr">value_destination_pairs</code> to each second element which indicates the destinations.</p> <h4 id="args_2">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">reduce_op</code></b>: An instance of <a href="reduceop"><code translate="no" dir="ltr">tf.distribute.ReduceOp</code></a> that indicates how per_replica_value will be reduced.</li> <li>
<b><code translate="no" dir="ltr">value_destination_pairs</code></b>: an iterable of tuples of PerReplica objects (or tensors with device set if there is one device) and destinations.</li> </ul> <h4 id="returns_2">Returns:</h4> <p>a list of Mirrored objects.</p> <h4 id="raises_2">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if <code translate="no" dir="ltr">value_destination_pairs</code> is not an iterable of tuples of PerReplica objects and destinations</li> </ul> <h3 id="broadcast"><code translate="no" dir="ltr">broadcast</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L329-L340">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">broadcast(
    tensor,
    destinations
)
</pre> <p>Broadcast the <code translate="no" dir="ltr">tensor</code> to destinations.</p> <h4 id="args_3">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">tensor</code></b>: the tensor to broadcast.</li> <li>
<b><code translate="no" dir="ltr">destinations</code></b>: the broadcast destinations.</li> </ul> <h4 id="returns_3">Returns:</h4> <p>a Mirrored object.</p> <h3 id="broadcast_implementation"><code translate="no" dir="ltr">broadcast_implementation</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L392-L403">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">broadcast_implementation(
    tensor,
    destinations
)
</pre> <p>Implementation of broadcast the <code translate="no" dir="ltr">tensor</code> to destinations.</p> <h4 id="args_4">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">tensor</code></b>: the tensor to broadcast.</li> <li>
<b><code translate="no" dir="ltr">destinations</code></b>: the broadcast destinations.</li> </ul> <h4 id="returns_4">Returns:</h4> <p>a Mirrored object.</p> <h3 id="reduce"><code translate="no" dir="ltr">reduce</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L248-L282">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">reduce(
    reduce_op,
    per_replica_value,
    destinations
)
</pre> <p>Reduce <code translate="no" dir="ltr">per_replica_value</code> to <code translate="no" dir="ltr">destinations</code>.</p> <p>It runs the reduction operation defined by <code translate="no" dir="ltr">reduce_op</code> and put the result on <code translate="no" dir="ltr">destinations</code>.</p> <h4 id="args_5">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">reduce_op</code></b>: An instance of <a href="reduceop"><code translate="no" dir="ltr">tf.distribute.ReduceOp</code></a> that indicates how per_replica_value will be reduced.</li> <li>
<b><code translate="no" dir="ltr">per_replica_value</code></b>: a PerReplica object or a tensor with device set.</li> <li>
<b><code translate="no" dir="ltr">destinations</code></b>: the reduction destinations.</li> </ul> <h4 id="returns_5">Returns:</h4> <p>a Mirrored object.</p> <h4 id="raises_3">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if per_replica_value can't be converted to a PerReplica object or if destinations aren't strings, Variables or DistributedValues</li> </ul> <h3 id="reduce_implementation"><code translate="no" dir="ltr">reduce_implementation</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/distribute/cross_device_ops.py#L342-L365">View source</a></p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">reduce_implementation(
    reduce_op,
    per_replica_value,
    destinations
)
</pre> <p>The implementation of reduce of <code translate="no" dir="ltr">per_replica_value</code> to <code translate="no" dir="ltr">destinations</code>.</p> <p>Overriding this method is useful for subclass implementers.</p> <p>It runs the reduction operation defined by <code translate="no" dir="ltr">reduce_op</code> and put the result on <code translate="no" dir="ltr">destinations</code>.</p> <h4 id="args_6">Args:</h4> <ul> <li>
<b><code translate="no" dir="ltr">reduce_op</code></b>: An instance <a href="reduceop"><code translate="no" dir="ltr">tf.distribute.ReduceOp</code></a> that indicates of how per_replica_value will be reduced.</li> <li>
<b><code translate="no" dir="ltr">per_replica_value</code></b>: a PerReplica object or a tensor with device set.</li> <li>
<b><code translate="no" dir="ltr">destinations</code></b>: the reduction destinations.</li> </ul> <h4 id="returns_6">Returns:</h4> <p>a Mirrored object.</p> <h4 id="raises_4">Raises:</h4> <ul> <li>
<b><code translate="no" dir="ltr">ValueError</code></b>: if per_replica_value can't be converted to a PerReplica object.</li> </ul> <h2 id="compat_aliases">Compat aliases</h2> <ul> <li><a href="crossdeviceops"><code translate="no" dir="ltr">tf.compat.v1.distribute.CrossDeviceOps</code></a></li> <li><a href="crossdeviceops"><code translate="no" dir="ltr">tf.compat.v2.distribute.CrossDeviceOps</code></a></li> </ul>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/CrossDeviceOps" class="_attribution-link">https://www.tensorflow.org/api_docs/python/tf/distribute/CrossDeviceOps</a>
  </p>
</div>
