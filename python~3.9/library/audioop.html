<h1 id="audioop-manipulate-raw-audio-data">audioop — Manipulate raw audio data</h1>  <p id="module-audioop">The <a class="reference internal" href="#module-audioop" title="audioop: Manipulate raw audio data."><code>audioop</code></a> module contains some useful operations on sound fragments. It operates on sound fragments consisting of signed integer samples 8, 16, 24 or 32 bits wide, stored in <a class="reference internal" href="https://docs.python.org/3.9/glossary.html#term-bytes-like-object"><span class="xref std std-term">bytes-like objects</span></a>. All scalar items are integers, unless specified otherwise.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 3.4: </span>Support for 24-bit samples was added. All functions now accept any <a class="reference internal" href="https://docs.python.org/3.9/glossary.html#term-bytes-like-object"><span class="xref std std-term">bytes-like object</span></a>. String input now results in an immediate error.</p> </div> <p id="index-0">This module provides support for a-LAW, u-LAW and Intel/DVI ADPCM encodings.</p> <p>A few of the more complicated operations only take 16-bit samples, otherwise the sample size (in bytes) is always a parameter of the operation.</p> <p>The module defines the following variables and functions:</p> <dl class="exception"> <dt id="audioop.error">
<code>exception audioop.error</code> </dt> <dd>
<p>This exception is raised on all errors, such as unknown number of bytes per sample, etc.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.add">
<code>audioop.add(fragment1, fragment2, width)</code> </dt> <dd>
<p>Return a fragment which is the addition of the two samples passed as parameters. <em>width</em> is the sample width in bytes, either <code>1</code>, <code>2</code>, <code>3</code> or <code>4</code>. Both fragments should have the same length. Samples are truncated in case of overflow.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.adpcm2lin">
<code>audioop.adpcm2lin(adpcmfragment, width, state)</code> </dt> <dd>
<p>Decode an Intel/DVI ADPCM coded fragment to a linear fragment. See the description of <a class="reference internal" href="#audioop.lin2adpcm" title="audioop.lin2adpcm"><code>lin2adpcm()</code></a> for details on ADPCM coding. Return a tuple <code>(sample, newstate)</code> where the sample has the width specified in <em>width</em>.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.alaw2lin">
<code>audioop.alaw2lin(fragment, width)</code> </dt> <dd>
<p>Convert sound fragments in a-LAW encoding to linearly encoded sound fragments. a-LAW encoding always uses 8 bits samples, so <em>width</em> refers only to the sample width of the output fragment here.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.avg">
<code>audioop.avg(fragment, width)</code> </dt> <dd>
<p>Return the average over all samples in the fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.avgpp">
<code>audioop.avgpp(fragment, width)</code> </dt> <dd>
<p>Return the average peak-peak value over all samples in the fragment. No filtering is done, so the usefulness of this routine is questionable.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.bias">
<code>audioop.bias(fragment, width, bias)</code> </dt> <dd>
<p>Return a fragment that is the original fragment with a bias added to each sample. Samples wrap around in case of overflow.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.byteswap">
<code>audioop.byteswap(fragment, width)</code> </dt> <dd>
<p>“Byteswap” all samples in a fragment and returns the modified fragment. Converts big-endian samples to little-endian and vice versa.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 3.4.</span></p> </div> </dd>
</dl> <dl class="function"> <dt id="audioop.cross">
<code>audioop.cross(fragment, width)</code> </dt> <dd>
<p>Return the number of zero crossings in the fragment passed as an argument.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.findfactor">
<code>audioop.findfactor(fragment, reference)</code> </dt> <dd>
<p>Return a factor <em>F</em> such that <code>rms(add(fragment, mul(reference, -F)))</code> is minimal, i.e., return the factor with which you should multiply <em>reference</em> to make it match as well as possible to <em>fragment</em>. The fragments should both contain 2-byte samples.</p> <p>The time taken by this routine is proportional to <code>len(fragment)</code>.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.findfit">
<code>audioop.findfit(fragment, reference)</code> </dt> <dd>
<p>Try to match <em>reference</em> as well as possible to a portion of <em>fragment</em> (which should be the longer fragment). This is (conceptually) done by taking slices out of <em>fragment</em>, using <a class="reference internal" href="#audioop.findfactor" title="audioop.findfactor"><code>findfactor()</code></a> to compute the best match, and minimizing the result. The fragments should both contain 2-byte samples. Return a tuple <code>(offset, factor)</code> where <em>offset</em> is the (integer) offset into <em>fragment</em> where the optimal match started and <em>factor</em> is the (floating-point) factor as per <a class="reference internal" href="#audioop.findfactor" title="audioop.findfactor"><code>findfactor()</code></a>.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.findmax">
<code>audioop.findmax(fragment, length)</code> </dt> <dd>
<p>Search <em>fragment</em> for a slice of length <em>length</em> samples (not bytes!) with maximum energy, i.e., return <em>i</em> for which <code>rms(fragment[i*2:(i+length)*2])</code> is maximal. The fragments should both contain 2-byte samples.</p> <p>The routine takes time proportional to <code>len(fragment)</code>.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.getsample">
<code>audioop.getsample(fragment, width, index)</code> </dt> <dd>
<p>Return the value of sample <em>index</em> from the fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.lin2adpcm">
<code>audioop.lin2adpcm(fragment, width, state)</code> </dt> <dd>
<p>Convert samples to 4 bit Intel/DVI ADPCM encoding. ADPCM coding is an adaptive coding scheme, whereby each 4 bit number is the difference between one sample and the next, divided by a (varying) step. The Intel/DVI ADPCM algorithm has been selected for use by the IMA, so it may well become a standard.</p> <p><em>state</em> is a tuple containing the state of the coder. The coder returns a tuple <code>(adpcmfrag, newstate)</code>, and the <em>newstate</em> should be passed to the next call of <a class="reference internal" href="#audioop.lin2adpcm" title="audioop.lin2adpcm"><code>lin2adpcm()</code></a>. In the initial call, <code>None</code> can be passed as the state. <em>adpcmfrag</em> is the ADPCM coded fragment packed 2 4-bit values per byte.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.lin2alaw">
<code>audioop.lin2alaw(fragment, width)</code> </dt> <dd>
<p>Convert samples in the audio fragment to a-LAW encoding and return this as a bytes object. a-LAW is an audio encoding format whereby you get a dynamic range of about 13 bits using only 8 bit samples. It is used by the Sun audio hardware, among others.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.lin2lin">
<code>audioop.lin2lin(fragment, width, newwidth)</code> </dt> <dd>
<p>Convert samples between 1-, 2-, 3- and 4-byte formats.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>In some audio formats, such as .WAV files, 16, 24 and 32 bit samples are signed, but 8 bit samples are unsigned. So when converting to 8 bit wide samples for these formats, you need to also add 128 to the result:</p> <pre data-language="python">new_frames = audioop.lin2lin(frames, old_width, 1)
new_frames = audioop.bias(new_frames, 1, 128)
</pre> <p>The same, in reverse, has to be applied when converting from 8 to 16, 24 or 32 bit width samples.</p> </div> </dd>
</dl> <dl class="function"> <dt id="audioop.lin2ulaw">
<code>audioop.lin2ulaw(fragment, width)</code> </dt> <dd>
<p>Convert samples in the audio fragment to u-LAW encoding and return this as a bytes object. u-LAW is an audio encoding format whereby you get a dynamic range of about 14 bits using only 8 bit samples. It is used by the Sun audio hardware, among others.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.max">
<code>audioop.max(fragment, width)</code> </dt> <dd>
<p>Return the maximum of the <em>absolute value</em> of all samples in a fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.maxpp">
<code>audioop.maxpp(fragment, width)</code> </dt> <dd>
<p>Return the maximum peak-peak value in the sound fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.minmax">
<code>audioop.minmax(fragment, width)</code> </dt> <dd>
<p>Return a tuple consisting of the minimum and maximum values of all samples in the sound fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.mul">
<code>audioop.mul(fragment, width, factor)</code> </dt> <dd>
<p>Return a fragment that has all samples in the original fragment multiplied by the floating-point value <em>factor</em>. Samples are truncated in case of overflow.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.ratecv">
<code>audioop.ratecv(fragment, width, nchannels, inrate, outrate, state[, weightA[, weightB]])</code> </dt> <dd>
<p>Convert the frame rate of the input fragment.</p> <p><em>state</em> is a tuple containing the state of the converter. The converter returns a tuple <code>(newfragment, newstate)</code>, and <em>newstate</em> should be passed to the next call of <a class="reference internal" href="#audioop.ratecv" title="audioop.ratecv"><code>ratecv()</code></a>. The initial call should pass <code>None</code> as the state.</p> <p>The <em>weightA</em> and <em>weightB</em> arguments are parameters for a simple digital filter and default to <code>1</code> and <code>0</code> respectively.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.reverse">
<code>audioop.reverse(fragment, width)</code> </dt> <dd>
<p>Reverse the samples in a fragment and returns the modified fragment.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.rms">
<code>audioop.rms(fragment, width)</code> </dt> <dd>
<p>Return the root-mean-square of the fragment, i.e. <code>sqrt(sum(S_i^2)/n)</code>.</p> <p>This is a measure of the power in an audio signal.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.tomono">
<code>audioop.tomono(fragment, width, lfactor, rfactor)</code> </dt> <dd>
<p>Convert a stereo fragment to a mono fragment. The left channel is multiplied by <em>lfactor</em> and the right channel by <em>rfactor</em> before adding the two channels to give a mono signal.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.tostereo">
<code>audioop.tostereo(fragment, width, lfactor, rfactor)</code> </dt> <dd>
<p>Generate a stereo fragment from a mono fragment. Each pair of samples in the stereo fragment are computed from the mono sample, whereby left channel samples are multiplied by <em>lfactor</em> and right channel samples by <em>rfactor</em>.</p> </dd>
</dl> <dl class="function"> <dt id="audioop.ulaw2lin">
<code>audioop.ulaw2lin(fragment, width)</code> </dt> <dd>
<p>Convert sound fragments in u-LAW encoding to linearly encoded sound fragments. u-LAW encoding always uses 8 bits samples, so <em>width</em> refers only to the sample width of the output fragment here.</p> </dd>
</dl> <p>Note that operations such as <a class="reference internal" href="#audioop.mul" title="audioop.mul"><code>mul()</code></a> or <a class="reference internal" href="#audioop.max" title="audioop.max"><code>max()</code></a> make no distinction between mono and stereo fragments, i.e. all samples are treated equal. If this is a problem the stereo fragment should be split into two mono fragments first and recombined later. Here is an example of how to do that:</p> <pre data-language="python">def mul_stereo(sample, width, lfactor, rfactor):
    lsample = audioop.tomono(sample, width, 1, 0)
    rsample = audioop.tomono(sample, width, 0, 1)
    lsample = audioop.mul(lsample, width, lfactor)
    rsample = audioop.mul(rsample, width, rfactor)
    lsample = audioop.tostereo(lsample, width, 1, 0)
    rsample = audioop.tostereo(rsample, width, 0, 1)
    return audioop.add(lsample, rsample, width)
</pre> <p>If you use the ADPCM coder to build network packets and you want your protocol to be stateless (i.e. to be able to tolerate packet loss) you should not only transmit the data but also the state. Note that you should send the <em>initial</em> state (the one you passed to <a class="reference internal" href="#audioop.lin2adpcm" title="audioop.lin2adpcm"><code>lin2adpcm()</code></a>) along to the decoder, not the final state (as returned by the coder). If you want to use <a class="reference internal" href="struct#struct.Struct" title="struct.Struct"><code>struct.Struct</code></a> to store the state in binary you can code the first element (the predicted value) in 16 bits and the second (the delta index) in 8.</p> <p>The ADPCM coders have never been tried against other ADPCM coders, only against themselves. It could well be that I misinterpreted the standards in which case they will not be interoperable with the respective standards.</p> <p>The <code>find*()</code> routines might look a bit funny at first sight. They are primarily meant to do echo cancellation. A reasonably fast way to do this is to pick the most energetic piece of the output sample, locate that in the input sample and subtract the whole output sample from the input sample:</p> <pre data-language="python">def echocancel(outputdata, inputdata):
    pos = audioop.findmax(outputdata, 800)    # one tenth second
    out_test = outputdata[pos*2:]
    in_test = inputdata[pos*2:]
    ipos, factor = audioop.findfit(in_test, out_test)
    # Optional (for better cancellation):
    # factor = audioop.findfactor(in_test[ipos*2:ipos*2+len(out_test)],
    #              out_test)
    prefill = '\0'*(pos+ipos)*2
    postfill = '\0'*(len(inputdata)-len(prefill)-len(outputdata))
    outputdata = prefill + audioop.mul(outputdata, 2, -factor) + postfill
    return audioop.add(inputdata, outputdata, 2)
</pre><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2001&ndash;2021 Python Software Foundation<br>Licensed under the PSF License.<br>
    <a href="https://docs.python.org/3.9/library/audioop.html" class="_attribution-link">https://docs.python.org/3.9/library/audioop.html</a>
  </p>
</div>
