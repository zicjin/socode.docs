<h1 class="devsite-page-title">tf.keras.layers.experimental.preprocessing.IntegerLookup</h1>       <p>Maps integers from a vocabulary to integer indices.</p> <p>Inherits From: <a href="preprocessinglayer"><code translate="no" dir="ltr">PreprocessingLayer</code></a>, <a href="../../layer"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../../module"><code translate="no" dir="ltr">Module</code></a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.layers.experimental.preprocessing.IntegerLookup(
    max_values=None, num_oov_indices=1, mask_value=0, oov_value=-1, vocabulary=None,
    invert=False, **kwargs
)
</pre>  <p>This layer translates a set of arbitrary integers into an integer output via a table-based lookup, with optional out-of-vocabulary handling.</p> <p>If desired, the user can call this layer's <code translate="no" dir="ltr">adapt()</code> method on a data set, which will analyze the data set, determine the frequency of individual string values, and create a vocabulary from them. This vocabulary can have unlimited size or be capped, depending on the configuration options for this layer; if there are more unique values in the input than the maximum vocabulary size, the most frequent terms will be used to create the vocabulary.</p> <h4 id="examples" data-text="Examples:">Examples:</h4> <p>Creating a lookup layer with a known vocabulary</p> <p>This example creates a lookup layer with a pre-existing vocabulary.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
vocab = [12, 36, 1138, 42]
data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
layer = IntegerLookup(vocabulary=vocab)
layer(data)
&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=
array([[2, 4, 5],
       [5, 1, 3]])&gt;
</pre> <p>Creating a lookup layer with an adapted vocabulary</p> <p>This example creates a lookup layer and generates the vocabulary by analyzing the dataset.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
layer = IntegerLookup()
layer.adapt(data)
layer.get_vocabulary()
[0, -1, 42, 1138, 1000, 36, 12]
</pre> <p>Note how the mask value 0 and the OOV value -1 have been added to the vocabulary. The remaining values are sorted by frequency (1138, which has 2 occurrences, is first) then by inverse sort order.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
layer = IntegerLookup()
layer.adapt(data)
layer(data)
&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=
array([[6, 3, 2],
       [2, 4, 5]])&gt;
</pre> <p>Lookups with multiple OOV tokens.</p> <p>This example demonstrates how to use a lookup layer with multiple OOV tokens. When a layer is created with more than one OOV token, any OOV values are hashed into the number of OOV buckets, distributing OOV values in a deterministic fashion across the set.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
vocab = [12, 36, 1138, 42]
data = tf.constant([[12, 1138, 42], [37, 1000, 36]])
layer = IntegerLookup(vocabulary=vocab, num_oov_indices=2)
layer(data)
&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=
array([[3, 5, 6],
       [2, 1, 4]])&gt;
</pre> <p>Note that the output for OOV value 37 is 2, while the output for OOV value 1000 is 1. The in-vocab terms have their output index increased by 1 from earlier examples (12 maps to 3, etc) in order to make space for the extra OOV value.</p> <p>Inverse lookup</p> <p>This example demonstrates how to map indices to values using this layer. (You can also use adapt() with inverse=True, but for simplicity we'll pass the vocab in this example.)</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
vocab = [12, 36, 1138, 42]
data = tf.constant([[1, 3, 4], [4, 5, 2]])
layer = IntegerLookup(vocabulary=vocab, invert=True)
layer(data)
&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=
array([[  12, 1138,   42],
       [  42,   -1,   36]])&gt;
</pre> <p>Note that the integer 5, which is out of the vocabulary space, returns an OOV token.</p> <p>Forward and inverse lookup pairs</p> <p>This example demonstrates how to use the vocabulary of a standard lookup layer to create an inverse lookup layer.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
vocab = [12, 36, 1138, 42]
data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
layer = IntegerLookup(vocabulary=vocab)
i_layer = IntegerLookup(vocabulary=layer.get_vocabulary(), invert=True)
int_data = layer(data)
i_layer(int_data)
&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=
array([[  12, 1138,   42],
       [  42,   -1,   36]])&gt;
</pre> <p>In this example, the input value 1000 resulted in an output of -1, since 1000 was not in the vocabulary - it got represented as an OOV, and all OOV values are returned as -1 in the inverse layer. Also, note that for the inverse to work, you must have already set the forward layer vocabulary either directly or via fit() before calling get_vocabulary().</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">max_values</code> </td> <td> The maximum size of the vocabulary for this layer. If None, there is no cap on the size of the vocabulary. Note that this vocabulary includes the OOV and mask values, so the effective number of values is (max_values - num_oov_values - (1 if mask_token else 0)) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_oov_indices</code> </td> <td> The number of out-of-vocabulary values to use; defaults to <ol> <li>If this value is more than 1, OOV inputs are modulated to determine their OOV value; if this value is 0, passing an OOV input will result in a '-1' being returned for that value in the output tensor. (Note that, because the value is -1 and not 0, this will allow you to effectively drop OOV values from categorical encodings.) </li>
</ol>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">mask_value</code> </td> <td> A value that represents masked inputs, and which is mapped to index 0. Defaults to 0. If set to None, no mask term will be added and the OOV values, if any, will be indexed from (0...num_oov_values) instead of (1...num_oov_values+1). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">oov_value</code> </td> <td> The value representing an out-of-vocabulary value. Defaults to -1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">vocabulary</code> </td> <td> An optional list of values, or a path to a text file containing a vocabulary to load into this layer. The file should contain one value per line. If the list or file contains the same token multiple times, an error will be thrown. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">invert</code> </td> <td> If true, this layer will map indices to vocabulary items instead of mapping vocabulary items to indices. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="adapt" data-text="adapt"><code translate="no" dir="ltr">adapt</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L178-L193">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
adapt(
    data, reset_state=True
)
</pre> <p>Fits the state of the preprocessing layer to the dataset.</p> <p>Overrides the default adapt method to apply relevant preprocessing to the inputs before passing to the combiner.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">data</code> </td> <td> The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reset_state</code> </td> <td> Optional argument specifying whether to clear the state of the layer at the start of the call to <code translate="no" dir="ltr">adapt</code>. This must be True for this layer, which does not support repeated calls to <code translate="no" dir="ltr">adapt</code>. </td> </tr> </table> <h3 id="get_vocabulary" data-text="get_vocabulary"><code translate="no" dir="ltr">get_vocabulary</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L195-L206">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_vocabulary()
</pre> <h3 id="set_vocabulary" data-text="set_vocabulary"><code translate="no" dir="ltr">set_vocabulary</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L345-L363">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_vocabulary(
    vocab
)
</pre> <p>Sets vocabulary data for this layer with inverse=False.</p> <p>This method sets the vocabulary for this layer directly, instead of analyzing a dataset through 'adapt'. It should be used whenever the vocab information is already known. If vocabulary data is already present in the layer, this method will either replace it</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">vocab</code> </td> <td> An array of string tokens. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If there are too many inputs, the inputs do not match, or input data is missing. </td> </tr> </table> <h3 id="vocab_size" data-text="vocab_size"><code translate="no" dir="ltr">vocab_size</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L208-L209">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
vocab_size()
</pre>  <devsite-thumb-rating position="footer"> <template class="thumb-down-categories"> [{ "type": "thumb-down", "id": "missingTheInformationINeed", "label":"Missing the information I need" },{ "type": "thumb-down", "id": "tooComplicatedTooManySteps", "label":"Too complicated / too many steps" },{ "type": "thumb-down", "id": "outOfDate", "label":"Out of date" },{ "type": "thumb-down", "id": "samplesCodeIssue", "label":"Samples / code issue" },{ "type": "thumb-down", "id": "otherDown", "label":"Other" }] </template> <template class="thumb-up-categories"> [{ "type": "thumb-up", "id": "easyToUnderstand", "label":"Easy to understand" },{ "type": "thumb-up", "id": "solvedMyProblem", "label":"Solved my problem" },{ "type": "thumb-up", "id": "otherUp", "label":"Other" }] </template> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup</a>
  </p>
</div>
