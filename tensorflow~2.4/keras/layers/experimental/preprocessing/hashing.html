<h1 class="devsite-page-title">tf.keras.layers.experimental.preprocessing.Hashing</h1>       <p>Implements categorical feature hashing, also known as "hashing trick".</p> <p>Inherits From: <a href="preprocessinglayer"><code translate="no" dir="ltr">PreprocessingLayer</code></a>, <a href="../../layer"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../../../module"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Hashing"><code translate="no" dir="ltr">tf.compat.v1.keras.layers.experimental.preprocessing.Hashing</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.layers.experimental.preprocessing.Hashing(
    num_bins, salt=None, name=None, **kwargs
)
</pre>  <p>This layer transforms single or multiple categorical inputs to hashed output. It converts a sequence of int or string to a sequence of int. The stable hash function uses tensorflow::ops::Fingerprint to produce universal output that is consistent across platforms.</p> <p>This layer uses <a href="https://github.com/google/farmhash">FarmHash64</a> by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly.</p> <p>If you want to obfuscate the hashed output, you can also pass a random <code translate="no" dir="ltr">salt</code> argument in the constructor. In that case, the layer will use the <a href="https://github.com/google/highwayhash">SipHash64</a> hash function, with the <code translate="no" dir="ltr">salt</code> value serving as additional input to the hash function.</p> <p>Example (FarmHash64):</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=3)
inp = [['A'], ['B'], ['C'], ['D'], ['E']]
layer(inp)
&lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
  array([[1],
         [0],
         [1],
         [1],
         [2]])&gt;
</pre> <p>Example (FarmHash64) with list of inputs:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">&gt;&gt;&gt; layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=3)
&gt;&gt;&gt; inp_1 = [['A'], ['B'], ['C'], ['D'], ['E']]
&gt;&gt;&gt; inp_2 = np.asarray([[5], [4], [3], [2], [1]])
&gt;&gt;&gt; layer([inp_1, inp_2])
&lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
  array([[1],
         [1],
         [0],
         [2],
         [0]])&gt;
</pre> <p>Example (SipHash64):</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=3,
   salt=[133, 137])
inp = [['A'], ['B'], ['C'], ['D'], ['E']]
layer(inp)
&lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
  array([[1],
         [2],
         [1],
         [0],
         [2]])&gt;
</pre> <p>Example (Siphash64 with a single integer, same as <code translate="no" dir="ltr">salt=[133, 133]</code></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=3,
   salt=133)
inp = [['A'], ['B'], ['C'], ['D'], ['E']]
layer(inp)
&lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
  array([[0],
         [0],
         [2],
         [1],
         [0]])&gt;
</pre> <p>Reference: <a href="https://www.131002.net/siphash/siphash.pdf">SipHash with salt</a></p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">num_bins</code> </td> <td> Number of hash bins. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">salt</code> </td> <td> A single unsigned integer or None. If passed, the hash function used will be SipHash64, with these values used as an additional input (known as a "salt" in cryptography). These should be non-zero. Defaults to <code translate="no" dir="ltr">None</code> (in that case, the FarmHash64 hash function is used). It also supports tuple/list of 2 unsigned integer numbers, see reference paper for details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Name to give to the layer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Keyword arguments to construct a layer. </td> </tr> </table> <p>Input shape: A single or list of string, int32 or int64 <code translate="no" dir="ltr">Tensor</code>, <code translate="no" dir="ltr">SparseTensor</code> or <code translate="no" dir="ltr">RaggedTensor</code> of shape <code translate="no" dir="ltr">[batch_size, ...,]</code></p> <p>Output shape: An int64 <code translate="no" dir="ltr">Tensor</code>, <code translate="no" dir="ltr">SparseTensor</code> or <code translate="no" dir="ltr">RaggedTensor</code> of shape <code translate="no" dir="ltr">[batch_size, ...]</code>. If any input is <code translate="no" dir="ltr">RaggedTensor</code> then output is <code translate="no" dir="ltr">RaggedTensor</code>, otherwise if any input is <code translate="no" dir="ltr">SparseTensor</code> then output is <code translate="no" dir="ltr">SparseTensor</code>, otherwise the output is <code translate="no" dir="ltr">Tensor</code>.</p> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="adapt" data-text="adapt"><code translate="no" dir="ltr">adapt</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/engine/base_preprocessing_layer.py#L53-L66">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
adapt(
    data, reset_state=True
)
</pre> <p>Fits the state of the preprocessing layer to the data being passed.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">data</code> </td> <td> The data to train on. It can be passed either as a tf.data Dataset, or as a numpy array. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">reset_state</code> </td> <td> Optional argument specifying whether to clear the state of the layer at the start of the call to <code translate="no" dir="ltr">adapt</code>, or whether to start from the existing state. This argument may not be relevant to all preprocessing layers: a subclass of PreprocessingLayer may choose to throw if 'reset_state' is set to False. </td> </tr> </table>  <devsite-thumb-rating position="footer"> <template class="thumb-down-categories"> [{ "type": "thumb-down", "id": "missingTheInformationINeed", "label":"Missing the information I need" },{ "type": "thumb-down", "id": "tooComplicatedTooManySteps", "label":"Too complicated / too many steps" },{ "type": "thumb-down", "id": "outOfDate", "label":"Out of date" },{ "type": "thumb-down", "id": "samplesCodeIssue", "label":"Samples / code issue" },{ "type": "thumb-down", "id": "otherDown", "label":"Other" }] </template> <template class="thumb-up-categories"> [{ "type": "thumb-up", "id": "easyToUnderstand", "label":"Easy to understand" },{ "type": "thumb-up", "id": "solvedMyProblem", "label":"Solved my problem" },{ "type": "thumb-up", "id": "otherUp", "label":"Other" }] </template> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/experimental/preprocessing/Hashing" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/experimental/preprocessing/Hashing</a>
  </p>
</div>
