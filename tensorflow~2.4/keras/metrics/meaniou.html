<h1 class="devsite-page-title">tf.keras.metrics.MeanIoU</h1>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L2722-L2850">  View source on GitHub </a> </td> </table> <p>Computes the mean Intersection-Over-Union metric.</p> <p>Inherits From: <a href="metric"><code translate="no" dir="ltr">Metric</code></a>, <a href="../layers/layer"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../module"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU"><code translate="no" dir="ltr">tf.metrics.MeanIoU</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU"><code translate="no" dir="ltr">tf.compat.v1.keras.metrics.MeanIoU</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.metrics.MeanIoU(
    num_classes, name=None, dtype=None
)
</pre>  <p>Mean Intersection-Over-Union is a common evaluation metric for semantic image segmentation, which first computes the IOU for each semantic class and then computes the average over classes. IOU is defined as follows: IOU = true_positive / (true_positive + false_positive + false_negative). The predictions are accumulated in a confusion matrix, weighted by <code translate="no" dir="ltr">sample_weight</code> and the metric is then calculated from it.</p> <p>If <code translate="no" dir="ltr">sample_weight</code> is <code translate="no" dir="ltr">None</code>, weights default to 1. Use <code translate="no" dir="ltr">sample_weight</code> of 0 to mask values.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">num_classes</code> </td> <td> The possible number of labels the prediction task can have. This value must be provided, since a confusion matrix of dimension = [num_classes, num_classes] will be allocated. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (Optional) string name of the metric instance. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> (Optional) data type of the metric result. </td> </tr> </table> <h4 id="standalone_usage" data-text="Standalone usage:">Standalone usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# cm = [[1, 1],
#        [1, 1]]
# sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]
# iou = true_positives / (sum_row + sum_col - true_positives))
# result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2 = 0.33
m = tf.keras.metrics.MeanIoU(num_classes=2)
m.update_state([0, 0, 1, 1], [0, 1, 0, 1])
m.result().numpy()
0.33333334
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m.reset_states()
m.update_state([0, 0, 1, 1], [0, 1, 0, 1],
               sample_weight=[0.3, 0.3, 0.3, 0.1])
m.result().numpy()
0.23809525
</pre> <p>Usage with <code translate="no" dir="ltr">compile()</code> API:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">model.compile(
  optimizer='sgd',
  loss='mse',
  metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])
</pre> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="reset_states" data-text="reset_states"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L2844-L2845">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
reset_states()
</pre> <p>Resets all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> <h3 id="result" data-text="result"><code translate="no" dir="ltr">result</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L2820-L2842">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
result()
</pre> <p>Compute the mean intersection-over-union via the confusion matrix.</p> <h3 id="update_state" data-text="update_state"><code translate="no" dir="ltr">update_state</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L2782-L2818">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
update_state(
    y_true, y_pred, sample_weight=None
)
</pre> <p>Accumulates the confusion matrix statistics.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">y_true</code> </td> <td> The ground truth values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y_pred</code> </td> <td> The predicted values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional weighting of each example. Defaults to 1. Can be a <code translate="no" dir="ltr">Tensor</code> whose rank is either 0, or the same rank as <code translate="no" dir="ltr">y_true</code>, and must be broadcastable to <code translate="no" dir="ltr">y_true</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Update op. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> <template class="thumb-down-categories"> [{ "type": "thumb-down", "id": "missingTheInformationINeed", "label":"Missing the information I need" },{ "type": "thumb-down", "id": "tooComplicatedTooManySteps", "label":"Too complicated / too many steps" },{ "type": "thumb-down", "id": "outOfDate", "label":"Out of date" },{ "type": "thumb-down", "id": "samplesCodeIssue", "label":"Samples / code issue" },{ "type": "thumb-down", "id": "otherDown", "label":"Other" }] </template> <template class="thumb-up-categories"> [{ "type": "thumb-up", "id": "easyToUnderstand", "label":"Easy to understand" },{ "type": "thumb-up", "id": "solvedMyProblem", "label":"Solved my problem" },{ "type": "thumb-up", "id": "otherUp", "label":"Other" }] </template> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/MeanIoU" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/MeanIoU</a>
  </p>
</div>
