<h1 class="devsite-page-title">Module: tf.compat.v1.metrics</h1>       <p>Evaluation-related metrics.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="metrics/accuracy"><code translate="no" dir="ltr">accuracy(...)</code></a>: Calculates how often <code translate="no" dir="ltr">predictions</code> matches <code translate="no" dir="ltr">labels</code>.</p> <p><a href="metrics/auc"><code translate="no" dir="ltr">auc(...)</code></a>: Computes the approximate AUC via a Riemann sum. (deprecated)</p> <p><a href="metrics/average_precision_at_k"><code translate="no" dir="ltr">average_precision_at_k(...)</code></a>: Computes average precision@k of predictions with respect to sparse labels.</p> <p><a href="metrics/false_negatives"><code translate="no" dir="ltr">false_negatives(...)</code></a>: Computes the total number of false negatives.</p> <p><a href="metrics/false_negatives_at_thresholds"><code translate="no" dir="ltr">false_negatives_at_thresholds(...)</code></a>: Computes false negatives at provided threshold values.</p> <p><a href="metrics/false_positives"><code translate="no" dir="ltr">false_positives(...)</code></a>: Sum the weights of false positives.</p> <p><a href="metrics/false_positives_at_thresholds"><code translate="no" dir="ltr">false_positives_at_thresholds(...)</code></a>: Computes false positives at provided threshold values.</p> <p><a href="metrics/mean"><code translate="no" dir="ltr">mean(...)</code></a>: Computes the (weighted) mean of the given values.</p> <p><a href="metrics/mean_absolute_error"><code translate="no" dir="ltr">mean_absolute_error(...)</code></a>: Computes the mean absolute error between the labels and predictions.</p> <p><a href="metrics/mean_cosine_distance"><code translate="no" dir="ltr">mean_cosine_distance(...)</code></a>: Computes the cosine distance between the labels and predictions.</p> <p><a href="metrics/mean_iou"><code translate="no" dir="ltr">mean_iou(...)</code></a>: Calculate per-step mean Intersection-Over-Union (mIOU).</p> <p><a href="metrics/mean_per_class_accuracy"><code translate="no" dir="ltr">mean_per_class_accuracy(...)</code></a>: Calculates the mean of the per-class accuracies.</p> <p><a href="metrics/mean_relative_error"><code translate="no" dir="ltr">mean_relative_error(...)</code></a>: Computes the mean relative error by normalizing with the given values.</p> <p><a href="metrics/mean_squared_error"><code translate="no" dir="ltr">mean_squared_error(...)</code></a>: Computes the mean squared error between the labels and predictions.</p> <p><a href="metrics/mean_tensor"><code translate="no" dir="ltr">mean_tensor(...)</code></a>: Computes the element-wise (weighted) mean of the given tensors.</p> <p><a href="metrics/percentage_below"><code translate="no" dir="ltr">percentage_below(...)</code></a>: Computes the percentage of values less than the given threshold.</p> <p><a href="metrics/precision"><code translate="no" dir="ltr">precision(...)</code></a>: Computes the precision of the predictions with respect to the labels.</p> <p><a href="metrics/precision_at_k"><code translate="no" dir="ltr">precision_at_k(...)</code></a>: Computes precision@k of the predictions with respect to sparse labels.</p> <p><a href="metrics/precision_at_thresholds"><code translate="no" dir="ltr">precision_at_thresholds(...)</code></a>: Computes precision values for different <code translate="no" dir="ltr">thresholds</code> on <code translate="no" dir="ltr">predictions</code>.</p> <p><a href="metrics/precision_at_top_k"><code translate="no" dir="ltr">precision_at_top_k(...)</code></a>: Computes precision@k of the predictions with respect to sparse labels.</p> <p><a href="metrics/recall"><code translate="no" dir="ltr">recall(...)</code></a>: Computes the recall of the predictions with respect to the labels.</p> <p><a href="metrics/recall_at_k"><code translate="no" dir="ltr">recall_at_k(...)</code></a>: Computes recall@k of the predictions with respect to sparse labels.</p> <p><a href="metrics/recall_at_thresholds"><code translate="no" dir="ltr">recall_at_thresholds(...)</code></a>: Computes various recall values for different <code translate="no" dir="ltr">thresholds</code> on <code translate="no" dir="ltr">predictions</code>.</p> <p><a href="metrics/recall_at_top_k"><code translate="no" dir="ltr">recall_at_top_k(...)</code></a>: Computes recall@k of top-k predictions with respect to sparse labels.</p> <p><a href="metrics/root_mean_squared_error"><code translate="no" dir="ltr">root_mean_squared_error(...)</code></a>: Computes the root mean squared error between the labels and predictions.</p> <p><a href="metrics/sensitivity_at_specificity"><code translate="no" dir="ltr">sensitivity_at_specificity(...)</code></a>: Computes the specificity at a given sensitivity.</p> <p><a href="metrics/sparse_average_precision_at_k"><code translate="no" dir="ltr">sparse_average_precision_at_k(...)</code></a>: Renamed to <code translate="no" dir="ltr">average_precision_at_k</code>, please use that method instead. (deprecated)</p> <p><a href="metrics/sparse_precision_at_k"><code translate="no" dir="ltr">sparse_precision_at_k(...)</code></a>: Renamed to <code translate="no" dir="ltr">precision_at_k</code>, please use that method instead. (deprecated)</p> <p><a href="metrics/specificity_at_sensitivity"><code translate="no" dir="ltr">specificity_at_sensitivity(...)</code></a>: Computes the specificity at a given sensitivity.</p> <p><a href="metrics/true_negatives"><code translate="no" dir="ltr">true_negatives(...)</code></a>: Sum the weights of true_negatives.</p> <p><a href="metrics/true_negatives_at_thresholds"><code translate="no" dir="ltr">true_negatives_at_thresholds(...)</code></a>: Computes true negatives at provided threshold values.</p> <p><a href="metrics/true_positives"><code translate="no" dir="ltr">true_positives(...)</code></a>: Sum the weights of true_positives.</p> <p><a href="metrics/true_positives_at_thresholds"><code translate="no" dir="ltr">true_positives_at_thresholds(...)</code></a>: Computes true positives at provided threshold values.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/metrics" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/metrics</a>
  </p>
</div>
