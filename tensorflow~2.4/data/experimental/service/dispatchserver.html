<h1 class="devsite-page-title">tf.data.experimental.service.DispatchServer</h1>       <p>An in-process tf.data service dispatch server.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.data.experimental.service.DispatchServer(
    config=None, start=True
)
</pre>  <p>A <a href="dispatchserver"><code translate="no" dir="ltr">tf.data.experimental.service.DispatchServer</code></a> coordinates a cluster of <a href="workerserver"><code translate="no" dir="ltr">tf.data.experimental.service.WorkerServer</code></a>s. When the workers start, they register themselves with the dispatcher.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
dispatcher = tf.data.experimental.service.DispatchServer()
dispatcher_address = dispatcher.target.split("://")[1]
worker = tf.data.experimental.service.WorkerServer(WorkerConfig(
    dispatcher_address=dispatcher_address))
dataset = tf.data.Dataset.range(10)
dataset = dataset.apply(tf.data.experimental.service.distribute(
    processing_mode="parallel_epochs", service=dispatcher.target))
print(list(dataset.as_numpy_iterator()))
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
</pre> <p>When starting a dedicated tf.data dispatch process, use join() to block indefinitely after starting up the server.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">dispatcher = tf.data.experimental.service.DispatchServer(
    tf.data.experimental.service.DispatcherConfig(port=5050))
dispatcher.join()
</pre> <p>To start a <code translate="no" dir="ltr">DispatchServer</code> in fault-tolerant mode, set <code translate="no" dir="ltr">work_dir</code> and <code translate="no" dir="ltr">fault_tolerant_mode</code> like below:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">dispatcher = tf.data.experimental.service.DispatchServer(
    tf.data.experimental.service.DispatcherConfig(
        port=5050,
        work_dir="gs://my-bucket/dispatcher/work_dir",
        fault_tolerant_mode=True))
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">config</code> </td> <td> (Optional.) A <a href="dispatcherconfig"><code translate="no" dir="ltr">tf.data.experimental.service.DispatcherConfig</code></a> configration. If <code translate="no" dir="ltr">None</code>, the dispatcher will use default configuration values. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">start</code> </td> <td> (Optional.) Boolean, indicating whether to start the server after creating it. Defaults to True. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">target</code> </td> <td> Returns a target that can be used to connect to the server. <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
dispatcher = tf.data.experimental.service.DispatchServer()
dataset = tf.data.Dataset.range(10)
dataset = dataset.apply(tf.data.experimental.service.distribute(
    processing_mode="parallel_epochs", service=dispatcher.target))
</pre> <p>The returned string will be in the form protocol://address, e.g. "grpc://localhost:5050". </p>
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="join" data-text="join"><code translate="no" dir="ltr">join</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/data/experimental/service/server_lib.py#L159-L174">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
join()
</pre> <p>Blocks until the server has shut down.</p> <p>This is useful when starting a dedicated dispatch process.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">dispatcher = tf.data.experimental.service.DispatchServer(
    tf.data.experimental.service.DispatcherConfig(port=5050))
dispatcher.join()
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <a href="https://www.tensorflow.org/api_docs/python/tf/errors/OpError"><code translate="no" dir="ltr">tf.errors.OpError</code></a> </td> <td> Or one of its subclasses if an error occurs while joining the server. </td> </tr> </table> <h3 id="start" data-text="start"><code translate="no" dir="ltr">start</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/data/experimental/service/server_lib.py#L147-L157">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
start()
</pre> <p>Starts this server.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
dispatcher = tf.data.experimental.service.DispatchServer(start=False)
dispatcher.start()
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <a href="https://www.tensorflow.org/api_docs/python/tf/errors/OpError"><code translate="no" dir="ltr">tf.errors.OpError</code></a> </td> <td> Or one of its subclasses if an error occurs while starting the server. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/data/experimental/service/DispatchServer" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/data/experimental/service/DispatchServer</a>
  </p>
</div>
