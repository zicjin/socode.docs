<h1 class="devsite-page-title">tf.lite.Interpreter</h1>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L160-L565">  View source on GitHub </a> </td> </table> <p>Interpreter interface for TensorFlow Lite Models.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter"><code translate="no" dir="ltr">tf.compat.v1.lite.Interpreter</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.lite.Interpreter(
    model_path=None, model_content=None, experimental_delegates=None,
    num_threads=None
)
</pre>  <p>This makes the TensorFlow Lite interpreter accessible in Python. It is possible to use this interpreter in a multithreaded Python environment, but you must be sure to call functions of a particular instance from only one thread at a time. So if you want to have 4 threads running different inferences simultaneously, create an interpreter for each one as thread-local data. Similarly, if you are calling invoke() in one thread on a single interpreter but you want to use tensor() on another thread once it is done, you must use a synchronization primitive between the threads to ensure invoke has returned before calling tensor().</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">model_path</code> </td> <td> Path to TF-Lite Flatbuffer file. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">model_content</code> </td> <td> Content of model. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_delegates</code> </td> <td> Experimental. Subject to change. List of <a href="https://www.tensorflow.org/lite/performance/delegates">TfLiteDelegate</a> objects returned by lite.load_delegate(). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_threads</code> </td> <td> Sets the number of threads used by the interpreter and available to CPU kernels. If not set, the interpreter will use an implementation-dependent default number of threads. Currently, only a subset of kernels, such as conv, support multi-threading. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the interpreter was unable to create. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="allocate_tensors" data-text="allocate_tensors"><code translate="no" dir="ltr">allocate_tensors</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L257-L259">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
allocate_tensors()
</pre> <h3 id="get_input_details" data-text="get_input_details"><code translate="no" dir="ltr">get_input_details</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L397-L405">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_input_details()
</pre> <p>Gets model input details.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of input details. </td> </tr> 
</table> <h3 id="get_output_details" data-text="get_output_details"><code translate="no" dir="ltr">get_output_details</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L452-L460">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_output_details()
</pre> <p>Gets model output details.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of output details. </td> </tr> 
</table> <h3 id="get_tensor" data-text="get_tensor"><code translate="no" dir="ltr">get_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L462-L475">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_tensor(
    tensor_index
)
</pre> <p>Gets the value of the input tensor (get a copy).</p> <p>If you wish to avoid the copy, use <code translate="no" dir="ltr">tensor()</code>. This function cannot be used to read intermediate results.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor_index</code> </td> <td> Tensor index of tensor to get. This value can be gotten from the 'index' field in get_output_details. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> a numpy array. </td> </tr> 
</table> <h3 id="get_tensor_details" data-text="get_tensor_details"><code translate="no" dir="ltr">get_tensor_details</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L380-L395">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
get_tensor_details()
</pre> <p>Gets tensor details for every tensor with valid tensor details.</p> <p>Tensors where required information about the tensor is not found are not added to the list. This includes temporary tensors without a name.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of dictionaries containing tensor information. </td> </tr> 
</table> <h3 id="invoke" data-text="invoke"><code translate="no" dir="ltr">invoke</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L527-L540">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
invoke()
</pre> <p>Invoke the interpreter.</p> <p>Be sure to set the input sizes, allocate tensors and fill values before calling this. Also, note that this function releases the GIL so heavy computation can be done in the background while the Python interpreter continues. No other function on this object should be called while the invoke() call has not finished.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> When the underlying interpreter fails raise ValueError. </td> </tr> </table> <h3 id="reset_all_variables" data-text="reset_all_variables"><code translate="no" dir="ltr">reset_all_variables</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L542-L543">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
reset_all_variables()
</pre> <h3 id="resize_tensor_input" data-text="resize_tensor_input"><code translate="no" dir="ltr">resize_tensor_input</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L425-L450">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
resize_tensor_input(
    input_index, tensor_size, strict=False
)
</pre> <p>Resizes an input tensor.</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">interpreter = Interpreter(model_content=tflite_model)
interpreter.resize_tensor_input(0, [1, 224, 224, 3], strict=True)
interpreter.allocate_tensors()
interpreter.invoke()
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">input_index</code> </td> <td> Tensor index of input to set. This value can be gotten from the 'index' field in get_input_details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">tensor_size</code> </td> <td> The tensor_shape to resize the input to. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">strict</code> </td> <td> Only unknown dimensions can be resized when <code translate="no" dir="ltr">strict</code> is True. Unknown dimensions are indicated as <code translate="no" dir="ltr">-1</code> in the <code translate="no" dir="ltr">shape_signature</code> attribute of a given tensor. (default False) </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the interpreter could not resize the input tensor. </td> </tr> </table> <h3 id="set_tensor" data-text="set_tensor"><code translate="no" dir="ltr">set_tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L407-L423">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
set_tensor(
    tensor_index, value
)
</pre> <p>Sets the value of the input tensor.</p> <p>Note this copies data in <code translate="no" dir="ltr">value</code>.</p> <p>If you want to avoid copying, you can use the <code translate="no" dir="ltr">tensor()</code> function to get a numpy buffer pointing to the input buffer in the tflite interpreter.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor_index</code> </td> <td> Tensor index of tensor to set. This value can be gotten from the 'index' field in get_input_details. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">value</code> </td> <td> Value of tensor to set. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If the interpreter could not set the tensor. </td> </tr> </table> <h3 id="tensor" data-text="tensor"><code translate="no" dir="ltr">tensor</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/python/interpreter.py#L477-L525">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tensor(
    tensor_index
)
</pre> <p>Returns function that gives a numpy view of the current tensor buffer.</p> <p>This allows reading and writing to this tensors w/o copies. This more closely mirrors the C++ Interpreter class interface's tensor() member, hence the name. Be careful to not hold these output references through calls to <code translate="no" dir="ltr">allocate_tensors()</code> and <code translate="no" dir="ltr">invoke()</code>. This function cannot be used to read intermediate results.</p> <h4 id="usage" data-text="Usage:">Usage:</h4> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">interpreter.allocate_tensors()
input = interpreter.tensor(interpreter.get_input_details()[0]["index"])
output = interpreter.tensor(interpreter.get_output_details()[0]["index"])
for i in range(10):
  input().fill(3.)
  interpreter.invoke()
  print("inference %s" % output())
</pre> <p>Notice how this function avoids making a numpy array directly. This is because it is important to not hold actual numpy views to the data longer than necessary. If you do, then the interpreter can no longer be invoked, because it is possible the interpreter would resize and invalidate the referenced tensors. The NumPy API doesn't allow any mutability of the the underlying buffers.</p> <h4 id="wrong" data-text="WRONG:">WRONG:</h4> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">input = interpreter.tensor(interpreter.get_input_details()[0]["index"])()
output = interpreter.tensor(interpreter.get_output_details()[0]["index"])()
interpreter.allocate_tensors()  # This will throw RuntimeError
for i in range(10):
  input.fill(3.)
  interpreter.invoke()  # this will throw RuntimeError since input,output
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">tensor_index</code> </td> <td> Tensor index of tensor to get. This value can be gotten from the 'index' field in get_output_details. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A function that can return a new numpy array pointing to the internal TFLite tensor state at any point. It is safe to hold the function forever, but it is not safe to hold the numpy array forever. </td> </tr> 
</table>  <devsite-thumb-rating position="footer"> <template class="thumb-down-categories"> [{ "type": "thumb-down", "id": "missingTheInformationINeed", "label":"Missing the information I need" },{ "type": "thumb-down", "id": "tooComplicatedTooManySteps", "label":"Too complicated / too many steps" },{ "type": "thumb-down", "id": "outOfDate", "label":"Out of date" },{ "type": "thumb-down", "id": "samplesCodeIssue", "label":"Samples / code issue" },{ "type": "thumb-down", "id": "otherDown", "label":"Other" }] </template> <template class="thumb-up-categories"> [{ "type": "thumb-up", "id": "easyToUnderstand", "label":"Easy to understand" },{ "type": "thumb-up", "id": "solvedMyProblem", "label":"Solved my problem" },{ "type": "thumb-up", "id": "otherUp", "label":"Other" }] </template> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/lite/Interpreter" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/lite/Interpreter</a>
  </p>
</div>
