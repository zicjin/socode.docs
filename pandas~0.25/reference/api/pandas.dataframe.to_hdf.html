<h1 id="pandas-dataframe-to-hdf">pandas.DataFrame.to_hdf</h1> <dl class="method"> <dt id="pandas.DataFrame.to_hdf">
<code>DataFrame.to_hdf(self, path_or_buf, key, **kwargs)</code> <a class="reference external" href="http://github.com/pandas-dev/pandas/blob/v0.25.0/pandas/core/generic.py#L2428-L2531"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Write the contained data to an HDF5 file using HDFStore.</p> <p>Hierarchical Data Format (HDF) is self-describing, allowing an application to interpret the structure and contents of a file with no outside information. One HDF file can hold a mix of related objects which can be accessed as a group or as individual objects.</p> <p>In order to add another DataFrame or Series to an existing HDF file please use append mode and a different a key.</p> <p>For more information see the <a class="reference internal" href="../../user_guide/io#io-hdf5"><span class="std std-ref">user guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr>
<th class="field-name">Parameters:</th>
<td class="field-body">
<dl class="first last docutils"> <dt>
<code>path_or_buf : str or pandas.HDFStore</code> </dt> <dd>
<p class="first last">File path or HDFStore object.</p> </dd> <dt>
<code>key : str</code> </dt> <dd>
<p class="first last">Identifier for the group in the store.</p> </dd> <dt>
<code>mode : {‘a’, ‘w’, ‘r+’}, default ‘a’</code> </dt> <dd>
<p class="first">Mode to open file:</p> <ul class="last simple"> <li>‘w’: write, a new file is created (an existing file with the same name would be deleted).</li> <li>‘a’: append, an existing file is opened for reading and writing, and if the file does not exist it is created.</li> <li>‘r+’: similar to ‘a’, but the file must already exist.</li> </ul> </dd> <dt>
<code>format : {‘fixed’, ‘table’}, default ‘fixed’</code> </dt> <dd>
<p class="first">Possible values:</p> <ul class="last simple"> <li>‘fixed’: Fixed format. Fast writing/reading. Not-appendable, nor searchable.</li> <li>‘table’: Table format. Write as a PyTables Table structure which may perform worse but allow more flexible operations like searching / selecting subsets of the data.</li> </ul> </dd> <dt>
<code>append : bool, default False</code> </dt> <dd>
<p class="first last">For Table formats, append the input data to the existing.</p> </dd> <dt>
<code>data_columns : list of columns or True, optional</code> </dt> <dd>
<p class="first last">List of columns to create as indexed data columns for on-disk queries, or True to use all columns. By default only the axes of the object are indexed. See <a class="reference internal" href="../../user_guide/io#io-hdf5-query-data-columns"><span class="std std-ref">Query via data columns</span></a>. Applicable only to format=’table’.</p> </dd> <dt>
<code>complevel : {0-9}, optional</code> </dt> <dd>
<p class="first last">Specifies a compression level for data. A value of 0 disables compression.</p> </dd> <dt>
<code>complib : {‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’</code> </dt> <dd>
<p class="first last">Specifies the compression library to be used. As of v0.20.2 these additional compressors for Blosc are supported (default if no compressor specified: ‘blosc:blosclz’): {‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’, ‘blosc:zlib’, ‘blosc:zstd’}. Specifying a compression library which is not available issues a ValueError.</p> </dd> <dt>
<code>fletcher32 : bool, default False</code> </dt> <dd>
<p class="first last">If applying compression use the fletcher32 checksum.</p> </dd> <dt>
<code>dropna : bool, default False</code> </dt> <dd>
<p class="first last">If true, ALL nan rows will not be written to store.</p> </dd> <dt>
<code>errors : str, default ‘strict’</code> </dt> <dd>
<p class="first last">Specifies how encoding and decoding errors are to be handled. See the errors argument for <a class="reference external" href="https://docs.python.org/3/library/functions.html#open" title="(in Python v3.7)"><code>open()</code></a> for a full list of options.</p> </dd> </dl> </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
<code>DataFrame.read_hdf</code> </dt> <dd>Read from HDF file.</dd> <dt>
 <a class="reference internal" href="pandas.dataframe.to_parquet#pandas.DataFrame.to_parquet" title="pandas.DataFrame.to_parquet"><code>DataFrame.to_parquet</code></a>
</dt> <dd>Write a DataFrame to the binary parquet format.</dd> <dt>
 <a class="reference internal" href="pandas.dataframe.to_sql#pandas.DataFrame.to_sql" title="pandas.DataFrame.to_sql"><code>DataFrame.to_sql</code></a>
</dt> <dd>Write to a sql table.</dd> <dt>
 <a class="reference internal" href="pandas.dataframe.to_feather#pandas.DataFrame.to_feather" title="pandas.DataFrame.to_feather"><code>DataFrame.to_feather</code></a>
</dt> <dd>Write out feather-format for DataFrames.</dd> <dt>
 <a class="reference internal" href="pandas.dataframe.to_csv#pandas.DataFrame.to_csv" title="pandas.DataFrame.to_csv"><code>DataFrame.to_csv</code></a>
</dt> <dd>Write out to a csv file.</dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])
&gt;&gt;&gt; df.to_hdf('data.h5', key='df', mode='w')
</pre> <p>We can add another object to the same file:</p> <pre data-language="python">&gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
&gt;&gt;&gt; s.to_hdf('data.h5', key='s')
</pre> <p>Reading from HDF file:</p> <pre data-language="python">&gt;&gt;&gt; pd.read_hdf('data.h5', 'df')
A  B
a  1  4
b  2  5
c  3  6
&gt;&gt;&gt; pd.read_hdf('data.h5', 's')
0    1
1    2
2    3
3    4
dtype: int64
</pre> <p>Deleting file with data:</p> <pre data-language="python">&gt;&gt;&gt; import os
&gt;&gt;&gt; os.remove('data.h5')
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2008&ndash;2012, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.to_hdf.html" class="_attribution-link">https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/api/pandas.DataFrame.to_hdf.html</a>
  </p>
</div>
