<h1 class="devsite-page-title">Module: tf.keras.optimizers.experimental</h1>        <p>Public API for tf.keras.optimizers.experimental namespace.</p> <h2 id="classes" data-text="Classes">Classes</h2> <p><a href="experimental/adadelta"><code translate="no" dir="ltr">class Adadelta</code></a>: Optimizer that implements the Adadelta algorithm.</p> <p><a href="experimental/adagrad"><code translate="no" dir="ltr">class Adagrad</code></a>: Optimizer that implements the Adagrad algorithm.</p> <p><a href="experimental/adam"><code translate="no" dir="ltr">class Adam</code></a>: Optimizer that implements the Adam algorithm.</p> <p><a href="experimental/adamw"><code translate="no" dir="ltr">class AdamW</code></a>: Optimizer that implements the AdamW algorithm.</p> <p><a href="experimental/adamax"><code translate="no" dir="ltr">class Adamax</code></a>: Optimizer that implements the Adamax algorithm.</p> <p><a href="experimental/ftrl"><code translate="no" dir="ltr">class Ftrl</code></a>: Optimizer that implements the FTRL algorithm.</p> <p><a href="experimental/nadam"><code translate="no" dir="ltr">class Nadam</code></a>: Optimizer that implements the Nadam algorithm.</p> <p><a href="experimental/optimizer"><code translate="no" dir="ltr">class Optimizer</code></a>: Abstract optimizer base class.</p> <p><a href="experimental/rmsprop"><code translate="no" dir="ltr">class RMSprop</code></a>: Optimizer that implements the RMSprop algorithm.</p> <p><a href="experimental/sgd"><code translate="no" dir="ltr">class SGD</code></a>: Gradient descent (with momentum) optimizer.</p>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/optimizers/experimental" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/optimizers/experimental</a>
  </p>
</div>
