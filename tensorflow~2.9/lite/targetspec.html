<h1 class="devsite-page-title">tf.lite.TargetSpec</h1>       <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.9.0/tensorflow/lite/python/lite.py#L185-L229">  View source on GitHub </a> </td> </table> <p>Specification of target device used to optimize the model.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/lite/TargetSpec"><code translate="no" dir="ltr">tf.compat.v1.lite.TargetSpec</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.lite.TargetSpec(
    supported_ops=None,
    supported_types=None,
    experimental_select_user_tf_ops=None,
    experimental_supported_backends=None
)
</pre>   
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">supported_ops</code> </td> <td> Experimental flag, subject to change. Set of <a href="opsset"><code translate="no" dir="ltr">tf.lite.OpsSet</code></a> options, where each option represents a set of operators supported by the target device. (default {tf.lite.OpsSet.TFLITE_BUILTINS})) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">supported_types</code> </td> <td> Set of <a href="../dtypes/dtype"><code translate="no" dir="ltr">tf.dtypes.DType</code></a> data types supported on the target device. If initialized, optimization might be driven by the smallest type in this set. (default set()) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_select_user_tf_ops</code> </td> <td> Experimental flag, subject to change. Set of user's TensorFlow operators' names that are required in the TensorFlow Lite runtime. These ops will be exported as select TensorFlow ops in the model (in conjunction with the tf.lite.OpsSet.SELECT_TF_OPS flag). This is an advanced feature that should only be used if the client is using TF ops that may not be linked in by default with the TF ops that are provided when using the SELECT_TF_OPS path. The client is responsible for linking these ops into the target runtime. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">experimental_supported_backends</code> </td> <td> Experimental flag, subject to change. Set containing names of supported backends. Currently only "GPU" is supported, more options will be available later. </td> </tr> </table>  <devsite-thumb-rating position="footer"> </devsite-thumb-rating><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/lite/TargetSpec" class="_attribution-link" target="_blank">https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/lite/TargetSpec</a>
  </p>
</div>
