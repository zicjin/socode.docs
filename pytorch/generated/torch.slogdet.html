<h1 id="torch-slogdet">torch.slogdet</h1> <dl class="function"> <dt id="torch.slogdet">
<code>torch.slogdet(input) -&gt; (Tensor, Tensor)</code> </dt> <dd>
<p>Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a> is deprecated. Please use <a class="reference internal" href="../linalg#torch.linalg.slogdet" title="torch.linalg.slogdet"><code>torch.linalg.slogdet()</code></a> instead.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>If <code>input</code> has zero determinant, this returns <code>(0, -inf)</code>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Backward through <a class="reference internal" href="#torch.slogdet" title="torch.slogdet"><code>slogdet()</code></a> internally uses SVD results when <code>input</code> is not invertible. In this case, double backward through <a class="reference internal" href="#torch.slogdet" title="torch.slogdet"><code>slogdet()</code></a> will be unstable in when <code>input</code> doesn’t have distinct singular values. See <a class="reference internal" href="torch.svd#torch.svd" title="torch.svd"><code>svd()</code></a> for details.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor of size <code>(*, n, n)</code> where <code>*</code> is zero or more batch dimensions.</p> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>A namedtuple (sign, logabsdet) containing the sign of the determinant, and the log value of the absolute determinant.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(3, 3)
&gt;&gt;&gt; A
tensor([[ 0.0032, -0.2239, -1.1219],
        [-0.6690,  0.1161,  0.4053],
        [-1.6218, -0.9273, -0.0082]])
&gt;&gt;&gt; torch.det(A)
tensor(-0.7576)
&gt;&gt;&gt; torch.logdet(A)
tensor(nan)
&gt;&gt;&gt; torch.slogdet(A)
torch.return_types.slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.slogdet.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.slogdet.html</a>
  </p>
</div>
