<h1 id="torch-flip">torch.flip</h1> <dl class="function"> <dt id="torch.flip">
<code>torch.flip(input, dims) → Tensor</code> </dt> <dd>
<p>Reverse the order of a n-D tensor along given axis in dims.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p><code>torch.flip</code> makes a copy of <code>input</code>’s data. This is different from NumPy’s <code>np.flip</code>, which returns a view in constant time. Since copying a tensor’s data is more work than viewing that data, <code>torch.flip</code> is expected to be slower than <code>np.flip</code>.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>dims</strong> (<em>a list</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a>) – axis to flip on</li> </ul> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.arange(8).view(2, 2, 2)
&gt;&gt;&gt; x
tensor([[[ 0,  1],
         [ 2,  3]],

        [[ 4,  5],
         [ 6,  7]]])
&gt;&gt;&gt; torch.flip(x, [0, 1])
tensor([[[ 6,  7],
         [ 4,  5]],

        [[ 2,  3],
         [ 0,  1]]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.flip.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.flip.html</a>
  </p>
</div>
