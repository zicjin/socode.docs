<h1 id="torch-pinverse">torch.pinverse</h1> <dl class="function"> <dt id="torch.pinverse">
<code>torch.pinverse(input, rcond=1e-15) → Tensor</code> </dt> <dd>
<p>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor. Please look at <a class="reference external" href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">Moore-Penrose inverse</a> for more details</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a> is deprecated. Please use <a class="reference internal" href="../linalg#torch.linalg.pinv" title="torch.linalg.pinv"><code>torch.linalg.pinv()</code></a> instead which includes new parameters <code>hermitian</code> and <code>out</code>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This method is implemented using the Singular Value Decomposition.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The pseudo-inverse is not necessarily a continuous function in the elements of the matrix <a class="reference external" href="https://epubs.siam.org/doi/10.1137/0117004">[1]</a>. Therefore, derivatives are not always existent, and exist for a constant rank only <a class="reference external" href="https://www.jstor.org/stable/2156365">[2]</a>. However, this method is backprop-able due to the implementation by using SVD results, and could be unstable. Double-backward will also be unstable due to the usage of SVD internally. See <a class="reference internal" href="torch.svd#torch.svd" title="torch.svd"><code>svd()</code></a> for more details.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Supports real and complex inputs. Batched version for complex inputs is only supported on the CPU.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – The input tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, m, n)</annotation></semantics></math></span></span> </span> where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span> </span> is zero or more batch dimensions.</li> <li>
<strong>rcond</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)">float</a><em>, </em><em>optional</em>) – A floating point value to determine the cutoff for small singular values. Default: <code>1e-15</code>.</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>The pseudo-inverse of <code>input</code> of dimensions <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, n, m)</annotation></semantics></math></span></span> </span></p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; input = torch.randn(3, 5)
&gt;&gt;&gt; input
tensor([[ 0.5495,  0.0979, -1.4092, -0.1128,  0.4132],
        [-1.1143, -0.3662,  0.3042,  1.6374, -0.9294],
        [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]])
&gt;&gt;&gt; torch.pinverse(input)
tensor([[ 0.0600, -0.1933, -0.2090],
        [-0.0903, -0.0817, -0.4752],
        [-0.7124, -0.1631, -0.2272],
        [ 0.1356,  0.3933, -0.5023],
        [-0.0308, -0.1725, -0.5216]])
&gt;&gt;&gt; # Batched pinverse example
&gt;&gt;&gt; a = torch.randn(2,6,3)
&gt;&gt;&gt; b = torch.pinverse(a)
&gt;&gt;&gt; torch.matmul(b, a)
tensor([[[ 1.0000e+00,  1.6391e-07, -1.1548e-07],
        [ 8.3121e-08,  1.0000e+00, -2.7567e-07],
        [ 3.5390e-08,  1.4901e-08,  1.0000e+00]],

        [[ 1.0000e+00, -8.9407e-08,  2.9802e-08],
        [-2.2352e-07,  1.0000e+00,  1.1921e-07],
        [ 0.0000e+00,  8.9407e-08,  1.0000e+00]]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.pinverse.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.pinverse.html</a>
  </p>
</div>
