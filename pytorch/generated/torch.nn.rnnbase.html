<h1 id="rnnbase">RNNBase</h1> <dl class="class"> <dt id="torch.nn.RNNBase">
<code>class torch.nn.RNNBase(mode, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0)</code> <a class="reference internal" href="https://pytorch.org/docs/1.8.0/_modules/torch/nn/modules/rnn.html#RNNBase"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="method"> <dt id="torch.nn.RNNBase.flatten_parameters">
<code>flatten_parameters()</code> <a class="reference internal" href="https://pytorch.org/docs/1.8.0/_modules/torch/nn/modules/rnn.html#RNNBase.flatten_parameters"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Resets parameter data pointer so that they can use faster code paths.</p> <p>Right now, this works only if the module is on the GPU and cuDNN is enabled. Otherwise, itâ€™s a no-op.</p> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.nn.RNNBase.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.nn.RNNBase.html</a>
  </p>
</div>
