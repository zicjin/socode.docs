<h1 id="torch-inverse">torch.inverse</h1> <dl class="function"> <dt id="torch.inverse">
<code>torch.inverse(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Takes the inverse of the square matrix <code>input</code>. <code>input</code> can be batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses.</p> <p>Supports real and complex input.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a> is deprecated. Please use <a class="reference internal" href="../linalg#torch.linalg.inv" title="torch.linalg.inv"><code>torch.linalg.inv()</code></a> instead.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Irrespective of the original strides, the returned tensors will be transposed, i.e. with strides like <code>input.contiguous().transpose(-2, -1).stride()</code></p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, n, n)</annotation></semantics></math></span></span> </span> where <code>*</code> is zero or more batch dimensions</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.rand(4, 4)
&gt;&gt;&gt; y = torch.inverse(x)
&gt;&gt;&gt; z = torch.mm(x, y)
&gt;&gt;&gt; z
tensor([[ 1.0000, -0.0000, -0.0000,  0.0000],
        [ 0.0000,  1.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000, -0.0000, -0.0000,  1.0000]])
&gt;&gt;&gt; torch.max(torch.abs(z - torch.eye(4))) # Max non-zero
tensor(1.1921e-07)

&gt;&gt;&gt; # Batched inverse example
&gt;&gt;&gt; x = torch.randn(2, 3, 4, 4)
&gt;&gt;&gt; y = torch.inverse(x)
&gt;&gt;&gt; z = torch.matmul(x, y)
&gt;&gt;&gt; torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero
tensor(1.9073e-06)

&gt;&gt;&gt; x = torch.rand(4, 4, dtype=torch.cdouble)
&gt;&gt;&gt; y = torch.inverse(x)
&gt;&gt;&gt; z = torch.mm(x, y)
&gt;&gt;&gt; z
tensor([[ 1.0000e+00+0.0000e+00j, -1.3878e-16+3.4694e-16j,
        5.5511e-17-1.1102e-16j,  0.0000e+00-1.6653e-16j],
        [ 5.5511e-16-1.6653e-16j,  1.0000e+00+6.9389e-17j,
        2.2204e-16-1.1102e-16j, -2.2204e-16+1.1102e-16j],
        [ 3.8858e-16-1.2490e-16j,  2.7756e-17+3.4694e-17j,
        1.0000e+00+0.0000e+00j, -4.4409e-16+5.5511e-17j],
        [ 4.4409e-16+5.5511e-16j, -3.8858e-16+1.8041e-16j,
        2.2204e-16+0.0000e+00j,  1.0000e+00-3.4694e-16j]],
    dtype=torch.complex128)
&gt;&gt;&gt; torch.max(torch.abs(z - torch.eye(4, dtype=torch.cdouble))) # Max non-zero
tensor(7.5107e-16, dtype=torch.float64)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.inverse.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.inverse.html</a>
  </p>
</div>
