<h1 id="torch-lu-unpack">torch.lu_unpack</h1> <dl class="function"> <dt id="torch.lu_unpack">
<code>torch.lu_unpack(LU_data, LU_pivots, unpack_data=True, unpack_pivots=True)</code> <a class="reference internal" href="https://pytorch.org/docs/1.8.0/_modules/torch/functional.html#lu_unpack"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Unpacks the data and pivots from a LU factorization of a tensor.</p> <p>Returns a tuple of tensors as <code>(the pivots, the L tensor, the U tensor)</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>LU_data</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the packed LU factorization data</li> <li>
<strong>LU_pivots</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the packed LU factorization pivots</li> <li>
<strong>unpack_data</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – flag indicating if the data should be unpacked</li> <li>
<strong>unpack_pivots</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – flag indicating if the pivots should be unpacked</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(2, 3, 3)
&gt;&gt;&gt; A_LU, pivots = A.lu()
&gt;&gt;&gt; P, A_L, A_U = torch.lu_unpack(A_LU, pivots)
&gt;&gt;&gt;
&gt;&gt;&gt; # can recover A from factorization
&gt;&gt;&gt; A_ = torch.bmm(P, torch.bmm(A_L, A_U))

&gt;&gt;&gt; # LU factorization of a rectangular matrix:
&gt;&gt;&gt; A = torch.randn(2, 3, 2)
&gt;&gt;&gt; A_LU, pivots = A.lu()
&gt;&gt;&gt; P, A_L, A_U = torch.lu_unpack(A_LU, pivots)
&gt;&gt;&gt; P
tensor([[[1., 0., 0.],
         [0., 1., 0.],
         [0., 0., 1.]],

        [[0., 0., 1.],
         [0., 1., 0.],
         [1., 0., 0.]]])
&gt;&gt;&gt; A_L
tensor([[[ 1.0000,  0.0000],
         [ 0.4763,  1.0000],
         [ 0.3683,  0.1135]],

        [[ 1.0000,  0.0000],
         [ 0.2957,  1.0000],
         [-0.9668, -0.3335]]])
&gt;&gt;&gt; A_U
tensor([[[ 2.1962,  1.0881],
         [ 0.0000, -0.8681]],

        [[-1.0947,  0.3736],
         [ 0.0000,  0.5718]]])
&gt;&gt;&gt; A_ = torch.bmm(P, torch.bmm(A_L, A_U))
&gt;&gt;&gt; torch.norm(A_ - A)
tensor(2.9802e-08)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.lu_unpack.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.lu_unpack.html</a>
  </p>
</div>
