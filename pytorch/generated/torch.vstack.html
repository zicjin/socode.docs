<h1 id="torch-vstack">torch.vstack</h1> <dl class="function"> <dt id="torch.vstack">
<code>torch.vstack(tensors, *, out=None) → Tensor</code> </dt> <dd>
<p>Stack tensors in sequence vertically (row wise).</p> <p>This is equivalent to concatenation along the first axis after all 1-D tensors have been reshaped by <a class="reference internal" href="torch.atleast_2d#torch.atleast_2d" title="torch.atleast_2d"><code>torch.atleast_2d()</code></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>tensors</strong> (<em>sequence of Tensors</em>) – sequence of tensors to concatenate</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.tensor([1, 2, 3])
&gt;&gt;&gt; b = torch.tensor([4, 5, 6])
&gt;&gt;&gt; torch.vstack((a,b))
tensor([[1, 2, 3],
        [4, 5, 6]])
&gt;&gt;&gt; a = torch.tensor([[1],[2],[3]])
&gt;&gt;&gt; b = torch.tensor([[4],[5],[6]])
&gt;&gt;&gt; torch.vstack((a,b))
tensor([[1],
        [2],
        [3],
        [4],
        [5],
        [6]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.vstack.html" class="_attribution-link" target="_blank">https://pytorch.org/docs/1.8.0/generated/torch.vstack.html</a>
  </p>
</div>
